{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to guice-persist-orient \u00b6 Guice integration for OrientDB . Release notes - Support - License Main features \u00b6 Integration through guice-persist (UnitOfWork, PersistService, @Transactional) Support for document , object and graph databases Database types support according to classpath (object and graph db support activated by adding jars to classpath) All three database types may be used in single transaction (changes will be visible between different apis) Hooks for schema migration and data initialization extensions Extension for orient object to scheme mapper with plugins support Auto mapping entities in package to db scheme or using classpath scanning to map annotated entities Auto db creation (for memory, local and plocal) Different db users may be used (for example, for schema initialization or to use orient security model), including support for user change inside transaction Support method retry on ONeedRetryException Spring-data like repositories with advanced features (e.g. generics usage in query). Great abilities for creating reusable parts (mixins). Support plugins. Basic crud mixins with ability to use object api for graphs Compatible with Play framework Note Orient team tries to move focus from object api (jpa-like) into document and graph apis. Library allows you to use pure document and graph apis, but also provides advanced tools to mix object and graph apis . So you can keep model as pojos and connect them with type safe (also pojo) edges. Documentation structure \u00b6 Library consists of 3 parts: Core orient integration (user guide section) Object schema mapper (mapping section) - used for schema creation from pojos during startup Repositories framework (repository section) - spring-data like approach of query definitions with annotations Start reading from getting started guide for introduction. All core apis are described on API page.","title":"Home"},{"location":"#welcome-to-guice-persist-orient","text":"Guice integration for OrientDB . Release notes - Support - License","title":"Welcome to guice-persist-orient"},{"location":"#main-features","text":"Integration through guice-persist (UnitOfWork, PersistService, @Transactional) Support for document , object and graph databases Database types support according to classpath (object and graph db support activated by adding jars to classpath) All three database types may be used in single transaction (changes will be visible between different apis) Hooks for schema migration and data initialization extensions Extension for orient object to scheme mapper with plugins support Auto mapping entities in package to db scheme or using classpath scanning to map annotated entities Auto db creation (for memory, local and plocal) Different db users may be used (for example, for schema initialization or to use orient security model), including support for user change inside transaction Support method retry on ONeedRetryException Spring-data like repositories with advanced features (e.g. generics usage in query). Great abilities for creating reusable parts (mixins). Support plugins. Basic crud mixins with ability to use object api for graphs Compatible with Play framework Note Orient team tries to move focus from object api (jpa-like) into document and graph apis. Library allows you to use pure document and graph apis, but also provides advanced tools to mix object and graph apis . So you can keep model as pojos and connect them with type safe (also pojo) edges.","title":"Main features"},{"location":"#documentation-structure","text":"Library consists of 3 parts: Core orient integration (user guide section) Object schema mapper (mapping section) - used for schema creation from pojos during startup Repositories framework (repository section) - spring-data like approach of query definitions with annotations Start reading from getting started guide for introduction. All core apis are described on API page.","title":"Documentation structure"},{"location":"api/","text":"Api reference \u00b6 Page describes core api classes. It does not cover object mapping or repositories . Core api classes are: TransactionManager transaction (unit of work) manager Provider<connection type> provides thread bound connection object inside unit of work TxTemplate<connection type> transactional template simplifies transaction handling (used internally by @Transactional annotation) SpecificTxTemplate<connection type> special version of tx template with connection object passing to callback UserManager allows changing user outside or inside transaction DatabaseManager is responsible for lifecycle and pools initialization, may be useful only for loaded types check PersistentContext combines all most used apis for simplified usage (no need to remember everything, just one class). It's not used internally and exist just for public usage. Could be replaced (or extended). Core annotations: @Transactional - defines transaction scope @TxType - used with transaction annotation to specify transaction type @Retry - catches and retries methods failed with orient ONeedRetryExcepion Transaction manager \u00b6 Unit of work manager. Used to start/stop/rollback transaction. Used internally by all other tx api. In most cases, it shouldn't be used directly for transaction definition to avoid try-catch code and avoid possibility of not closing transaction. Use TxTemplate or SpecificTxTemplate for manual transaction execution. The most useful method is current transaction check: transactionManager . isTransactionActive () Default transaction manager implementation may be substituted in guice module: bind ( TransactionalManager . class ). to ( MyTransactionalManager . class ) When @Transactional annotation used, transaction type may be defined with @TxType annotation (but in most cases it is not required). Connection provider \u00b6 Connection could be acquired only inside transaction (unit of work). Possible connection objects: Provider<OObjectDatabaseTx> for object database connection Provider<ODatabaseDocumentTx> for document database connection Provider<OrientBaseGraph> for graph database connection (transactional or not) Provider<OrientGraph> for transactional graph database connection (will fail if notx transaction type) Provider<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note You can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Connection provider logic is implemented in pools ( PoolManager ). Pool is registered for each connection type (document, object, graph). Connection instance is thread bound, so you may be sure that every time provider.get() returns same connection object instance (within transaction). Transaction templates \u00b6 Transaction template abstract work with transaction manager (begin/commit/rollback staff). TxTemplate is the core transaction abstraction, used by all other api ( @Transactional annotation, SpecificTxTemplate ). Sample usage: @Inject TxTemplate < OObjectDatabaseTx > template ; ... template . doInTransaction ( new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); Custom transaction config: template . doInTransaction ( new TxConfig ( OTransaction . TXTYPE . NOTX ), new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); If template is used inside transaction, it's config is ignored. SpecificTxTemplate is TxTemplate but with connection object in callback (to avoid calling connection provider inside callback). For example: @Inject SpecificTxTemplate < OObjectDatabaseTx > specificTxTemplate ; ... specificTxTemplate . doInTransaction ( new SpecificTxAction < Object , OObjectDatabaseTx >() { @Override public Object execute ( OObjectDatabaseTx db ) throws Throwable { // something return null ; } }) It also may be called with custom transaction config. TxConfig may also configure exception types which will not prevent commit or which should trigger rollback (see guice-persist @Transactional annotation javadoc for more details). User manager \u00b6 UserManager allows you to change connection user. Change may be performed outside of transaction (to affect multiple transactions) or inside transaction (e.g. to check orient security). To change user for multiple transactions: userManager . executeWithUser ( ' user ' , ' password ' , new SpecificUserAction < Void >() { @Override public Void execute () throws Throwable { // do work } }) SpecificUserAction defines scope of user overriding. This will not implicitly start transaction, but simply binds different user to current thread. Overriding may be used in scheme initialization to use more powerful user or to use orient security model (in this case overriding may be done, for example in servlet filter). Nested user override is not allowed (to avoid confusion). But you can use user overriding inside transaction. Transaction user \u00b6 To change user inside transaction: userManager . executeWithTxUser ( ' user ' , new SpecificUserAction < Void >() { @Override public Void execute () throws Throwable { // do work } }) Must be called inside transaction. Changes user inside current connection using ODatabase.setUser(user) api. This change will affect security checks (probably the most common use case). Nested user override is not allowed (for simplicity). Note PersistentContext provides shortcut only for changing user inside transaction. Database manager \u00b6 Database manager is responsible for lifecycle (start/stop) and pools management. The only useful methods: @Inject DatabaseManager dbManager ; ... // check if database type supported dbManager . isTypeSupported ( DbType . OBJECT ) // all supported types dbManager . getSupportedTypes () Database types support is driven by classpath (e.g. if orient-graph dependency is not available, no graph db support will be in runtime).","title":"API"},{"location":"api/#api-reference","text":"Page describes core api classes. It does not cover object mapping or repositories . Core api classes are: TransactionManager transaction (unit of work) manager Provider<connection type> provides thread bound connection object inside unit of work TxTemplate<connection type> transactional template simplifies transaction handling (used internally by @Transactional annotation) SpecificTxTemplate<connection type> special version of tx template with connection object passing to callback UserManager allows changing user outside or inside transaction DatabaseManager is responsible for lifecycle and pools initialization, may be useful only for loaded types check PersistentContext combines all most used apis for simplified usage (no need to remember everything, just one class). It's not used internally and exist just for public usage. Could be replaced (or extended). Core annotations: @Transactional - defines transaction scope @TxType - used with transaction annotation to specify transaction type @Retry - catches and retries methods failed with orient ONeedRetryExcepion","title":"Api reference"},{"location":"api/#transaction-manager","text":"Unit of work manager. Used to start/stop/rollback transaction. Used internally by all other tx api. In most cases, it shouldn't be used directly for transaction definition to avoid try-catch code and avoid possibility of not closing transaction. Use TxTemplate or SpecificTxTemplate for manual transaction execution. The most useful method is current transaction check: transactionManager . isTransactionActive () Default transaction manager implementation may be substituted in guice module: bind ( TransactionalManager . class ). to ( MyTransactionalManager . class ) When @Transactional annotation used, transaction type may be defined with @TxType annotation (but in most cases it is not required).","title":"Transaction manager"},{"location":"api/#connection-provider","text":"Connection could be acquired only inside transaction (unit of work). Possible connection objects: Provider<OObjectDatabaseTx> for object database connection Provider<ODatabaseDocumentTx> for document database connection Provider<OrientBaseGraph> for graph database connection (transactional or not) Provider<OrientGraph> for transactional graph database connection (will fail if notx transaction type) Provider<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note You can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Connection provider logic is implemented in pools ( PoolManager ). Pool is registered for each connection type (document, object, graph). Connection instance is thread bound, so you may be sure that every time provider.get() returns same connection object instance (within transaction).","title":"Connection provider"},{"location":"api/#transaction-templates","text":"Transaction template abstract work with transaction manager (begin/commit/rollback staff). TxTemplate is the core transaction abstraction, used by all other api ( @Transactional annotation, SpecificTxTemplate ). Sample usage: @Inject TxTemplate < OObjectDatabaseTx > template ; ... template . doInTransaction ( new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); Custom transaction config: template . doInTransaction ( new TxConfig ( OTransaction . TXTYPE . NOTX ), new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); If template is used inside transaction, it's config is ignored. SpecificTxTemplate is TxTemplate but with connection object in callback (to avoid calling connection provider inside callback). For example: @Inject SpecificTxTemplate < OObjectDatabaseTx > specificTxTemplate ; ... specificTxTemplate . doInTransaction ( new SpecificTxAction < Object , OObjectDatabaseTx >() { @Override public Object execute ( OObjectDatabaseTx db ) throws Throwable { // something return null ; } }) It also may be called with custom transaction config. TxConfig may also configure exception types which will not prevent commit or which should trigger rollback (see guice-persist @Transactional annotation javadoc for more details).","title":"Transaction templates"},{"location":"api/#user-manager","text":"UserManager allows you to change connection user. Change may be performed outside of transaction (to affect multiple transactions) or inside transaction (e.g. to check orient security). To change user for multiple transactions: userManager . executeWithUser ( ' user ' , ' password ' , new SpecificUserAction < Void >() { @Override public Void execute () throws Throwable { // do work } }) SpecificUserAction defines scope of user overriding. This will not implicitly start transaction, but simply binds different user to current thread. Overriding may be used in scheme initialization to use more powerful user or to use orient security model (in this case overriding may be done, for example in servlet filter). Nested user override is not allowed (to avoid confusion). But you can use user overriding inside transaction.","title":"User manager"},{"location":"api/#transaction-user","text":"To change user inside transaction: userManager . executeWithTxUser ( ' user ' , new SpecificUserAction < Void >() { @Override public Void execute () throws Throwable { // do work } }) Must be called inside transaction. Changes user inside current connection using ODatabase.setUser(user) api. This change will affect security checks (probably the most common use case). Nested user override is not allowed (for simplicity). Note PersistentContext provides shortcut only for changing user inside transaction.","title":"Transaction user"},{"location":"api/#database-manager","text":"Database manager is responsible for lifecycle (start/stop) and pools management. The only useful methods: @Inject DatabaseManager dbManager ; ... // check if database type supported dbManager . isTypeSupported ( DbType . OBJECT ) // all supported types dbManager . getSupportedTypes () Database types support is driven by classpath (e.g. if orient-graph dependency is not available, no graph db support will be in runtime).","title":"Database manager"},{"location":"getting-started/","text":"Getting started \u00b6 Installation \u00b6 Available from maven central and bintray jcenter Maven: <dependency> <groupId> ru.vyarus </groupId> <artifactId> guice-persist-orient </artifactId> <version> 3.3.2 </version> <exclusions> <exclusion> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-graphdb </artifactId> </exclusion> <exclusion> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-object </artifactId> </exclusion> </exclusions> </dependency> Gradle: compile ( 'ru.vyarus:guice-persist-orient:3.3.2' ){ exclude module: 'orientdb-graphdb' exclude module: 'orientdb-object' } Tip Remove exclusions to enable object and graph db support. Important It's very important for object db to use exact javassist version it depends on. If other libraries in your classpath use javassist , check that newer or older version not appear in classpath. Usage \u00b6 Install guice module \u00b6 install ( new OrientModule ( url , user , password )); See orient documentation for supported db types. In short: memory:dbname to use in-memory database plocal:dbname to use embedded database (no server required, local fs folder will be used); db name must be local fs path remote:dbname to use remote db (you need to start server to use it) By default use admin/admin user. Note Auto database creation for local types (all except 'remote') is enabled by default, but you can switch it off . Lifecycle \u00b6 You need to manually start/stop persist service in your code (because only you can control application lifecycle). On start connection pools will be initialized, database created (if required) and scheme/data initializers called. Stop will shutdown all connection pools. @Singleton public class MyLifecycle { @Inject private PersistService orientService ; public void start (){ orientService . start (); } public void stop (){ orientService . stop (); } } Assuming start and stop methods are called on application startup/shutdown. Connections \u00b6 Document is the core connection type. Object and graph apis use document connection internally. Connection object mainly defines the result of queries: document connection will always return ODocument object connection returns mapped pojos (actually proxies) or ODocument for fields selections and graph api returns Vertex and Edge types. And of course connections provide specific apis for types. You can use any connections within single transaction and changes made in one connection type will be visible in other connections. This allows you, for example to update data using object api and create relations using graph api. To access connection object inside transaction use PersistentContext generified with the type of required connection. PersistentContext<OObjectDatabaseTx> for object database connection PersistentContext<ODatabaseDocumentTx> for document database connection PersistentContext<OrientBaseGraph> for graph database connection (transactional or not) PersistentContext<OrientGraph> for transactional graph database connection (will fail if notx transaction type) PersistentContext<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note you can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Note PersistentContext methods are shortcuts for low level api (simplifies usage). You can extend it to add more shortcut methods or make your own: it is not used internally and exists only for public usage. For example public class MyService { @Inject private PersistenceContext < OObjectDatabaseTx > context ; public List < Model > findByName ( final String name ) { // manual transaction declaration return context . doInTransaction (( db ) -> // pure orient api db . query ( new OSQLSynchQuery < Model >( \"select from Model where name=?\" ), name ) ); } } Alternatively, you can directly inject connections: @Inject private Provider < OObjectDatabaseTx > db ; But note that it would not work without external transaction. Transactions \u00b6 There are 3 ways to declare transaction : @Transactional annotation on guice bean or single method (additional @TxType annotation allows to define different transaction type for specific unit of work) Inject PersistentContext bean into your service and use its methods Using TransactionManager begin() and end() methods (low level trasaction control). First two options are better, because they automatically manage rollbacks and avoid not closed (forgot to call end) transactions. For example, to declare transaction using annotation: @Transactional public class MyService { public void doSomething () {...} } Or public class MyService { @Transactional public void doSomething () {...} } Warning Private methods can't be annotated with @Transactional : method must be at least package-private. Transaction scopes could intersect: e.g. if transactional method calls bean, also annotated as transactional, then only root transaction scope will work (no sub-transaction or anything like this). Tip If you need to execute without transaction, you still need to declare it @Transactional @TxType ( OTransaction . TXTYPE . NOTX ) public void method () This is required, for example, for schema updates Note in contrast to spring default proxies, in guice when you call bean method inside the same bean, annotation interceptor will still work. So it's possible to define few units of work withing single bean using annotations: public void nonTxMethod (){ doTx1 (); doTx2 (); } @Transactional void doTx1 () {..} @Transactional void doTx2 () {..} Warning When you get error like Database instance is not set in current thread. Assure to set it with: ODatabaseRecordThreadLocal.instance().set(db) It almost certainly means that you perform transactional operation outside of transaction. Simply enlarge transaction scope. When you inside transaction, activateOnCurrentThread() is called each time you obtain connection from raw connection provider or PersistentContext and you will always have correctly bound connection. For example, even document creation ( new ODocument() ) must be performed inside transaction. Schema initialization \u00b6 In order to work with database, you obviously need to initialize it's schema first. public class MySchemeInitializer implements SchemeInitializer { @Inject private Provider < OObjectDatabaseTx > provider ; public void initialize () { final OObjectDatabaseTx db = provider . get (); if ( db . getMetadata (). getSchema (). existsClass ( \"Account\" )) { // schema already created - do nothing return ; } OClass account = db . getMetadata (). getSchema (). createClass ( \"Account\" ); account . createProperty ( \"id\" , OType . Integer ); account . createProperty ( \"birthDate\" , OType . Date ); //or using sql statements db . command ( new OCommandSQL ( \"CREATE CLASS Account\" )). execute (); } } To do it register implementation of ru.vyarus.guice.persist.orient.db.scheme.SchemeInitializer in guice module: bind ( SchemeInitializer . class ). to ( MySchemeInitializer . class ); Initializer is called without transaction (NOTX transaction type) as orient requires database updates to be performed without transaction. Object scheme mapping \u00b6 If you are using object api, then you can create schema directly from your model objects. In this case you dont need to implement your own SchemeInitializer , instead register module: install ( new AutoScanSchemeModule ( \"my.model.root.package\" )); Module will find all classes, annotated with @Persistent using classpath scan and register them in orient. For example: @Persistent public class Account { @Id private String id ; @Version private Long version ; private String myProp ; // getters and setters } Tip If you want to use graph api with objects then annotate your class as @VertexType or @EdgeType in order to correct create graph schema from object. More about object scheme mapping . Data initialization \u00b6 You may need to initialize some sample data before start (e.g.for testing) or perform some data updates. Implement ru.vyarus.guice.persist.orient.db.data.DataInitializer : public class MyDataInitializer implements DataInitializer { @Inject private Provider < OObjectDatabaseTx > provider ; @Override @Transactional void initializeData () { final OObjectDatabaseTx db = provider . get (); // init only if database is empty if ( db . getMetadata (). getSchema (). getClass ( Account . class ). count () == 0 ) { db . save ( new Account ( \"something 1\" )); db . save ( new Account ( \"something 2\" )); } } } Repositories \u00b6 You can also use interfaces for queries declaration (very like spring-data). Register repositories module: install ( new RepositoryModule ()); Now you can declare: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface AccountRepository { @Query ( \"select from Account\" ) List < Account > selectAll (); @Query ( \"update Account set name = ? where name = ?\" ) int updateName ( String newName , String oldName ); @Query ( \"insert into Account (name) values(:name)\" ) Account create ( @Param ( \"name\" ) String name ); } Later this repository could be injected as normal guice bean: @Transactonal public class MyService { @Inject private AccountRepository repo ; public void doSomething () { List < Account > all = repo . selectAll (); } } Or you can use repository methods directly in other beans: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class MyDao { @Query ( \"select from Account\" ) public abstract List < Account > selectAll (); // normal method public void doSomething () { List < Account > all = selectAll (); ... } } Tip IDE could warn you about @ProvidedBy(DynamicSingletonProvider.class) , but it's the only way to avoid additional (direct) registrations. If warning is annoying for you, you can register beans manually instead: bind ( AccountRepository . class ). to ( DynamicClassGenerator . generate ( MyInterfaceRepository . class )). in ( Singleton . class ) Note Guice aop will work on repositories (in fact it's implemented using aop), so you may use any other aop-driven annotations there. More about repositories Summary \u00b6 If you want to use orient with object mappings, then guice initialization will look like: public class MyModule extends AbstractModule { @Override protected void configure () { install ( new OrientModule ( \"memory:test\" , \"admin\" , \"admin\" )); install ( new AutoScanSchemeModule ( \"my.model.root.package\" )); install ( new RepositoryModule ()); } } And you will need to start and shutdown persistence support: @Inject private PersistService orientService ; // called manually orientService . start (); ... // called manually before shutdown orientService . stop ();","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/#installation","text":"Available from maven central and bintray jcenter Maven: <dependency> <groupId> ru.vyarus </groupId> <artifactId> guice-persist-orient </artifactId> <version> 3.3.2 </version> <exclusions> <exclusion> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-graphdb </artifactId> </exclusion> <exclusion> <groupId> com.orientechnologies </groupId> <artifactId> orientdb-object </artifactId> </exclusion> </exclusions> </dependency> Gradle: compile ( 'ru.vyarus:guice-persist-orient:3.3.2' ){ exclude module: 'orientdb-graphdb' exclude module: 'orientdb-object' } Tip Remove exclusions to enable object and graph db support. Important It's very important for object db to use exact javassist version it depends on. If other libraries in your classpath use javassist , check that newer or older version not appear in classpath.","title":"Installation"},{"location":"getting-started/#usage","text":"","title":"Usage"},{"location":"getting-started/#install-guice-module","text":"install ( new OrientModule ( url , user , password )); See orient documentation for supported db types. In short: memory:dbname to use in-memory database plocal:dbname to use embedded database (no server required, local fs folder will be used); db name must be local fs path remote:dbname to use remote db (you need to start server to use it) By default use admin/admin user. Note Auto database creation for local types (all except 'remote') is enabled by default, but you can switch it off .","title":"Install guice module"},{"location":"getting-started/#lifecycle","text":"You need to manually start/stop persist service in your code (because only you can control application lifecycle). On start connection pools will be initialized, database created (if required) and scheme/data initializers called. Stop will shutdown all connection pools. @Singleton public class MyLifecycle { @Inject private PersistService orientService ; public void start (){ orientService . start (); } public void stop (){ orientService . stop (); } } Assuming start and stop methods are called on application startup/shutdown.","title":"Lifecycle"},{"location":"getting-started/#connections","text":"Document is the core connection type. Object and graph apis use document connection internally. Connection object mainly defines the result of queries: document connection will always return ODocument object connection returns mapped pojos (actually proxies) or ODocument for fields selections and graph api returns Vertex and Edge types. And of course connections provide specific apis for types. You can use any connections within single transaction and changes made in one connection type will be visible in other connections. This allows you, for example to update data using object api and create relations using graph api. To access connection object inside transaction use PersistentContext generified with the type of required connection. PersistentContext<OObjectDatabaseTx> for object database connection PersistentContext<ODatabaseDocumentTx> for document database connection PersistentContext<OrientBaseGraph> for graph database connection (transactional or not) PersistentContext<OrientGraph> for transactional graph database connection (will fail if notx transaction type) PersistentContext<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note you can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Note PersistentContext methods are shortcuts for low level api (simplifies usage). You can extend it to add more shortcut methods or make your own: it is not used internally and exists only for public usage. For example public class MyService { @Inject private PersistenceContext < OObjectDatabaseTx > context ; public List < Model > findByName ( final String name ) { // manual transaction declaration return context . doInTransaction (( db ) -> // pure orient api db . query ( new OSQLSynchQuery < Model >( \"select from Model where name=?\" ), name ) ); } } Alternatively, you can directly inject connections: @Inject private Provider < OObjectDatabaseTx > db ; But note that it would not work without external transaction.","title":"Connections"},{"location":"getting-started/#transactions","text":"There are 3 ways to declare transaction : @Transactional annotation on guice bean or single method (additional @TxType annotation allows to define different transaction type for specific unit of work) Inject PersistentContext bean into your service and use its methods Using TransactionManager begin() and end() methods (low level trasaction control). First two options are better, because they automatically manage rollbacks and avoid not closed (forgot to call end) transactions. For example, to declare transaction using annotation: @Transactional public class MyService { public void doSomething () {...} } Or public class MyService { @Transactional public void doSomething () {...} } Warning Private methods can't be annotated with @Transactional : method must be at least package-private. Transaction scopes could intersect: e.g. if transactional method calls bean, also annotated as transactional, then only root transaction scope will work (no sub-transaction or anything like this). Tip If you need to execute without transaction, you still need to declare it @Transactional @TxType ( OTransaction . TXTYPE . NOTX ) public void method () This is required, for example, for schema updates Note in contrast to spring default proxies, in guice when you call bean method inside the same bean, annotation interceptor will still work. So it's possible to define few units of work withing single bean using annotations: public void nonTxMethod (){ doTx1 (); doTx2 (); } @Transactional void doTx1 () {..} @Transactional void doTx2 () {..} Warning When you get error like Database instance is not set in current thread. Assure to set it with: ODatabaseRecordThreadLocal.instance().set(db) It almost certainly means that you perform transactional operation outside of transaction. Simply enlarge transaction scope. When you inside transaction, activateOnCurrentThread() is called each time you obtain connection from raw connection provider or PersistentContext and you will always have correctly bound connection. For example, even document creation ( new ODocument() ) must be performed inside transaction.","title":"Transactions"},{"location":"getting-started/#schema-initialization","text":"In order to work with database, you obviously need to initialize it's schema first. public class MySchemeInitializer implements SchemeInitializer { @Inject private Provider < OObjectDatabaseTx > provider ; public void initialize () { final OObjectDatabaseTx db = provider . get (); if ( db . getMetadata (). getSchema (). existsClass ( \"Account\" )) { // schema already created - do nothing return ; } OClass account = db . getMetadata (). getSchema (). createClass ( \"Account\" ); account . createProperty ( \"id\" , OType . Integer ); account . createProperty ( \"birthDate\" , OType . Date ); //or using sql statements db . command ( new OCommandSQL ( \"CREATE CLASS Account\" )). execute (); } } To do it register implementation of ru.vyarus.guice.persist.orient.db.scheme.SchemeInitializer in guice module: bind ( SchemeInitializer . class ). to ( MySchemeInitializer . class ); Initializer is called without transaction (NOTX transaction type) as orient requires database updates to be performed without transaction.","title":"Schema initialization"},{"location":"getting-started/#object-scheme-mapping","text":"If you are using object api, then you can create schema directly from your model objects. In this case you dont need to implement your own SchemeInitializer , instead register module: install ( new AutoScanSchemeModule ( \"my.model.root.package\" )); Module will find all classes, annotated with @Persistent using classpath scan and register them in orient. For example: @Persistent public class Account { @Id private String id ; @Version private Long version ; private String myProp ; // getters and setters } Tip If you want to use graph api with objects then annotate your class as @VertexType or @EdgeType in order to correct create graph schema from object. More about object scheme mapping .","title":"Object scheme mapping"},{"location":"getting-started/#data-initialization","text":"You may need to initialize some sample data before start (e.g.for testing) or perform some data updates. Implement ru.vyarus.guice.persist.orient.db.data.DataInitializer : public class MyDataInitializer implements DataInitializer { @Inject private Provider < OObjectDatabaseTx > provider ; @Override @Transactional void initializeData () { final OObjectDatabaseTx db = provider . get (); // init only if database is empty if ( db . getMetadata (). getSchema (). getClass ( Account . class ). count () == 0 ) { db . save ( new Account ( \"something 1\" )); db . save ( new Account ( \"something 2\" )); } } }","title":"Data initialization"},{"location":"getting-started/#repositories","text":"You can also use interfaces for queries declaration (very like spring-data). Register repositories module: install ( new RepositoryModule ()); Now you can declare: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface AccountRepository { @Query ( \"select from Account\" ) List < Account > selectAll (); @Query ( \"update Account set name = ? where name = ?\" ) int updateName ( String newName , String oldName ); @Query ( \"insert into Account (name) values(:name)\" ) Account create ( @Param ( \"name\" ) String name ); } Later this repository could be injected as normal guice bean: @Transactonal public class MyService { @Inject private AccountRepository repo ; public void doSomething () { List < Account > all = repo . selectAll (); } } Or you can use repository methods directly in other beans: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class MyDao { @Query ( \"select from Account\" ) public abstract List < Account > selectAll (); // normal method public void doSomething () { List < Account > all = selectAll (); ... } } Tip IDE could warn you about @ProvidedBy(DynamicSingletonProvider.class) , but it's the only way to avoid additional (direct) registrations. If warning is annoying for you, you can register beans manually instead: bind ( AccountRepository . class ). to ( DynamicClassGenerator . generate ( MyInterfaceRepository . class )). in ( Singleton . class ) Note Guice aop will work on repositories (in fact it's implemented using aop), so you may use any other aop-driven annotations there. More about repositories","title":"Repositories"},{"location":"getting-started/#summary","text":"If you want to use orient with object mappings, then guice initialization will look like: public class MyModule extends AbstractModule { @Override protected void configure () { install ( new OrientModule ( \"memory:test\" , \"admin\" , \"admin\" )); install ( new AutoScanSchemeModule ( \"my.model.root.package\" )); install ( new RepositoryModule ()); } } And you will need to start and shutdown persistence support: @Inject private PersistService orientService ; // called manually orientService . start (); ... // called manually before shutdown orientService . stop ();","title":"Summary"},{"location":"about/compatibility/","text":"OrientDB compatibility \u00b6 OrientDB Guice guice-persist-orient 2.2 4.2.0 3.3.2 2.1 4.1.0 3.2.0 2.0 4.0.0 3.1.1 1.0 4.0.0 2.1.0","title":"Compatibility"},{"location":"about/compatibility/#orientdb-compatibility","text":"OrientDB Guice guice-persist-orient 2.2 4.2.0 3.3.2 2.1 4.1.0 3.2.0 2.0 4.0.0 3.1.1 1.0 4.0.0 2.1.0","title":"OrientDB compatibility"},{"location":"about/history/","text":"3.3.2 (2018-04-02) \u00b6 Guice 4.2.0 compatibility 3.3.1 (2018-01-17) \u00b6 Fix ignoreNullValues flag support for @Index and @CompositeIndex scheme extensions (#16) (breaking) since orient 2.2 ignoreNullValues is false by default, but @Index and @CompositeIndex annotations use ignoreNullValues = true by default and it was not applied properly before. Now flag will apply properly, which may change existing indexes. One consequence I know is composite index with ignoreNullValues = true is not used for single field searches (don't know why). 3.3.0 (2017-11-07) \u00b6 Update to orient 2.2 Support custom types installation with new method: OrientModule#withCustomTypes(OObjectSerializer...) (#14) Support external connection (thread bound) re-use: when transaction started with TxConfig.external() thread bound connection used instead of new connection. Commits and rollbacks are not applied automatically: supposed that manual connection is completely managed externally. Useful in case when already existing connection must be (re)used in guice. (breaking) custom TransactionManager and/or PoolManager implementations must be updated to support external transactions New service RecordConverter may be used directly to: convert ODocument to object or vertex apply default repository method converter (e.g. apply projection) @Listen parameter extension changes: (breaking) no longer could be used with @Query (because it does not work properly for remote connection and not guaranteed by the documentation) wraps provided listener with an external transaction (thread bound connection (used by orient) could be used in guice) AsyncQuery changes: custom AsyncQueryListener interface can be used instead of OCommandResultListener to apply automatic result conversion (with RecordConverter to mimic the same behaviour as for usual method result) new blocking attribute to switch execution into non blocking mode (OSQLNonBlockingQuery). Non blocking methods may return Future to monitor async execution (but not able to cancel!). exception appeared inside async listener is intercepted and logged but not propagated: only false returned to stop query processing. This is required for proper orient connection handling (it does not expect exceptions in some modes) Add @LiveQuery repository extension (live queries support) required orient OLiveResultListener parameter must be used with @Listen annotation custom LiveQueryListener interface can be used instead of OLiveResultListener to apply automatic result conversion (with RecordConverter to mimic the same behaviour as for usual method result). Support repository result projection on collections (e.g. @Query(\"select name from Model\") List\\ select()). 3.2.0 (2016-09-25) \u00b6 Update to orient 2.1 Update to guice 4.1 Avoid deprecated OCommandRequest api usage (deprecated in 2.1): @FetchPlan, @Limit and @Timeout extensions now modifies query instead of using OCommandRequest setters (behavior change) @EdgeType and @VertexType extensions now assign superclass directly to annotated type (or not if hierarchy already contains required type) Call activateOnCurrentThread() in pools for each connection obtain (e.g. context.getConnection()) to guarantee proper db instance bound to thread Fix guice circular proxy (between transaction manager and pools) Fix child injector and private modules support for RepositoryModule (#7) Fix playframework compatibility (#10) 3.1.1 (2015-08-16) \u00b6 Improve graph connection recognition on repository methods: recognize all graph types implementing Vertex or Edge (e.g. OrientVertex, OrientEdge) 3.1.0 (2015-07-04) \u00b6 Add @RidElVar parameter extension to bind rid directly into query from any source (string, object, document, vertex or collections). Add @CaseInsensitive scheme field extension: sets collate ci for case insensitive fields comparison in queries. Also should be used for creation of ci indexes. Add ignoreNullValues option support for @Index and @CompositeIndex scheme extensions Add @FulltextIndex scheme field extension for fulltext index definitions Add @LuceneIndex and @CompositeLuceneIndex scheme extensions for fulltext lucene index definitions Fix modules usage in child injector Improve connection hint support in repository annotations: now hint is always used in priority, which allows to write more complex result converters Add ObjectVertexCrud mixin to correctly work with vertexes from object api Add EdgesSupport and EdgeTypeSupport mixins to simplify work with edges using object api Fix temporal id problem for detached objects (affects ObjectCrud, ObjectVertexCrud and @DetachResult) ObjectCrud: add getAllAsList, objectToDocument and documentToObject methods 3.0.2 (2015-05-16) \u00b6 Orient 2.0.9 compatibility: removed @LockStrategy extension, because lock setter removed from OCommandRequest (use sql LOCK statement instead) 3.0.1 (2015-05-05) \u00b6 Fix stale connections in pools Fix sometimes redundant connection in db auto creation check Fix schema extensions for remote connection (more often schema synchronization) 3.0.0 (2015-03-14) \u00b6 Orient 2 compatibility DocumentPool use OPartitionedDatabasePool instead of deprecated ODatabaseDocumentPool (breaking) Default pools implementation now rely on document pool only (no more separate transactions for each type). This allows using all connection types in one transaction and all changes will be visible to each type. (breaking) Connection initialization moved from DatabaseManager to pool implementation (graph and object connections update scheme on first connection). Now each pool did db connection on startup to check connection and let orient properly update scheme on start. (breaking) TxTemplate and SpecificTxTemplate now propagate only runtime exceptions and wrap checked exceptions into runtime. This simplifies general usage (most orient exceptions are runtime) ObjectCrudMixin: added multiple detachAll methods (in orient 2 object proxies doesn't work outside of transaction, so detaching is more important) DocumentCrudMixin: added create method to create document inside of transaction (in orient 2 it's now impossible to create document outside of transaction, but document changes doesn't require ongoing transaction) Add PersistentContext class, which combines connection provider, both templates and provide access to TransactionManager. It should be used instead of low level staff (simplifies usage) Remove deprecated finders auto scanning (breaking) Finders rewritten to extensions based architecture. Finder module renamed to repository to follow spring-data style (as well known and very similar realization). Not owned annotations (@Named, @Finder, @FirstResult, @MaxResults) replaced with spring-data like or orient specific annotations (@Param, @Query, @Function, @Skip, @Limit). Many annotations and classes renamed due to module rename. Many new repository features Ability to change user inside transaction (for example for security checks). Retry annotation to catch ONeedRetryException and re-execute method. (breaking) schemeMappingPackage option removed from OrientModule. Shortcut modules now must be used together with OrientModule and not substitute it. Modules renamed to AutoScanSchemeModule and PackageSchemeModule. Model class to scheme mapper, using orient default mapper, but with extensions support (custom annotations). AbstractObjectInitializer now generic enough to use for custom classpath filtering method. 2.1.0 (2015-01-06) \u00b6 Finders now managed by guice and any additional aop could be applied. Abstract beans could define finder methods. (integration implemented in external library ) Finders auto scan api deprecated: now finder bean could be marked with @ProvidedBy and rely on guice JIT resolution Fix transactional aop warnings on jdk8 Fix finder descriptors cache Add ability to disable finder descriptors cache using property and method to clear current cache 2.0.2 (2014-11-26) \u00b6 Update orient (1.7.9 > 1.7.10 ( changes )) Fix single value vertex return from finder (projection should not occur) Add explicit scheme synchronization for AutoScanSchemeInitializer and PackageSchemeInitializer (useful for dynamic environments, like tests) 2.0.1 (2014-11-19) \u00b6 Generics resolution extracted to separate lib generics-resolver 2.0.0 (2014-11-05) \u00b6 Support different users (for example, to init schema with more powerful user and to use orient security model). Breaks pools api compatibility AutoScanFinderModule accept multiple packages for scanning Add document and vertex projection for single field (works for plain and array result): useful for count (or other aggregation functions) or selecting single field Support inheritance for finder beans and interfaces (mixins) and generics recognition through all hierarchy Support generic type query placeholders (finder class generic used as query placeholder) Add delegate finders (annotated interface method delegates execution to guice bean method) Add crud mixins for object and document finders: DocumentCrudMixin, ObjectCrudMixin Add pagination mixin for object and document finders: PaginationMixin 1.1.1 (2014-10-01) \u00b6 Fix finder behaviour: empty collection conversion to single element 1.1.0 (2014-09-27) \u00b6 Fix finder module available db types detection Add query placeholders support for finders Update orient (1.7.8 > 1.7.9) - important hotfix Add Optional support as finder return type (jdk or guava Optional) Add orient module option to disable database auto creation Update guice (4.beta4 -> 4.beta5) 1.0.3 (2014-09-15) \u00b6 Fix remote connection support (avoid database creation) 1.0.2 (2014-08-16) \u00b6 Fix pmd/checkstyle warnings 1.0.1 (2014-08-05) \u00b6 Fix generated pom 1.0.0 (2014-08-05) \u00b6 Added dynamic finders (as separate module) Module configuration moved from constructor to chained methods Default object scheme initializers now support graph compatible scheme creation Remove dependency on reflections library Important bugs fixed as a result of better tests coverage 0.9.0 (2014-07-29) \u00b6 Initial release","title":"Release notes"},{"location":"about/history/#332-2018-04-02","text":"Guice 4.2.0 compatibility","title":"3.3.2 (2018-04-02)"},{"location":"about/history/#331-2018-01-17","text":"Fix ignoreNullValues flag support for @Index and @CompositeIndex scheme extensions (#16) (breaking) since orient 2.2 ignoreNullValues is false by default, but @Index and @CompositeIndex annotations use ignoreNullValues = true by default and it was not applied properly before. Now flag will apply properly, which may change existing indexes. One consequence I know is composite index with ignoreNullValues = true is not used for single field searches (don't know why).","title":"3.3.1 (2018-01-17)"},{"location":"about/history/#330-2017-11-07","text":"Update to orient 2.2 Support custom types installation with new method: OrientModule#withCustomTypes(OObjectSerializer...) (#14) Support external connection (thread bound) re-use: when transaction started with TxConfig.external() thread bound connection used instead of new connection. Commits and rollbacks are not applied automatically: supposed that manual connection is completely managed externally. Useful in case when already existing connection must be (re)used in guice. (breaking) custom TransactionManager and/or PoolManager implementations must be updated to support external transactions New service RecordConverter may be used directly to: convert ODocument to object or vertex apply default repository method converter (e.g. apply projection) @Listen parameter extension changes: (breaking) no longer could be used with @Query (because it does not work properly for remote connection and not guaranteed by the documentation) wraps provided listener with an external transaction (thread bound connection (used by orient) could be used in guice) AsyncQuery changes: custom AsyncQueryListener interface can be used instead of OCommandResultListener to apply automatic result conversion (with RecordConverter to mimic the same behaviour as for usual method result) new blocking attribute to switch execution into non blocking mode (OSQLNonBlockingQuery). Non blocking methods may return Future to monitor async execution (but not able to cancel!). exception appeared inside async listener is intercepted and logged but not propagated: only false returned to stop query processing. This is required for proper orient connection handling (it does not expect exceptions in some modes) Add @LiveQuery repository extension (live queries support) required orient OLiveResultListener parameter must be used with @Listen annotation custom LiveQueryListener interface can be used instead of OLiveResultListener to apply automatic result conversion (with RecordConverter to mimic the same behaviour as for usual method result). Support repository result projection on collections (e.g. @Query(\"select name from Model\") List\\ select()).","title":"3.3.0 (2017-11-07)"},{"location":"about/history/#320-2016-09-25","text":"Update to orient 2.1 Update to guice 4.1 Avoid deprecated OCommandRequest api usage (deprecated in 2.1): @FetchPlan, @Limit and @Timeout extensions now modifies query instead of using OCommandRequest setters (behavior change) @EdgeType and @VertexType extensions now assign superclass directly to annotated type (or not if hierarchy already contains required type) Call activateOnCurrentThread() in pools for each connection obtain (e.g. context.getConnection()) to guarantee proper db instance bound to thread Fix guice circular proxy (between transaction manager and pools) Fix child injector and private modules support for RepositoryModule (#7) Fix playframework compatibility (#10)","title":"3.2.0 (2016-09-25)"},{"location":"about/history/#311-2015-08-16","text":"Improve graph connection recognition on repository methods: recognize all graph types implementing Vertex or Edge (e.g. OrientVertex, OrientEdge)","title":"3.1.1 (2015-08-16)"},{"location":"about/history/#310-2015-07-04","text":"Add @RidElVar parameter extension to bind rid directly into query from any source (string, object, document, vertex or collections). Add @CaseInsensitive scheme field extension: sets collate ci for case insensitive fields comparison in queries. Also should be used for creation of ci indexes. Add ignoreNullValues option support for @Index and @CompositeIndex scheme extensions Add @FulltextIndex scheme field extension for fulltext index definitions Add @LuceneIndex and @CompositeLuceneIndex scheme extensions for fulltext lucene index definitions Fix modules usage in child injector Improve connection hint support in repository annotations: now hint is always used in priority, which allows to write more complex result converters Add ObjectVertexCrud mixin to correctly work with vertexes from object api Add EdgesSupport and EdgeTypeSupport mixins to simplify work with edges using object api Fix temporal id problem for detached objects (affects ObjectCrud, ObjectVertexCrud and @DetachResult) ObjectCrud: add getAllAsList, objectToDocument and documentToObject methods","title":"3.1.0 (2015-07-04)"},{"location":"about/history/#302-2015-05-16","text":"Orient 2.0.9 compatibility: removed @LockStrategy extension, because lock setter removed from OCommandRequest (use sql LOCK statement instead)","title":"3.0.2 (2015-05-16)"},{"location":"about/history/#301-2015-05-05","text":"Fix stale connections in pools Fix sometimes redundant connection in db auto creation check Fix schema extensions for remote connection (more often schema synchronization)","title":"3.0.1 (2015-05-05)"},{"location":"about/history/#300-2015-03-14","text":"Orient 2 compatibility DocumentPool use OPartitionedDatabasePool instead of deprecated ODatabaseDocumentPool (breaking) Default pools implementation now rely on document pool only (no more separate transactions for each type). This allows using all connection types in one transaction and all changes will be visible to each type. (breaking) Connection initialization moved from DatabaseManager to pool implementation (graph and object connections update scheme on first connection). Now each pool did db connection on startup to check connection and let orient properly update scheme on start. (breaking) TxTemplate and SpecificTxTemplate now propagate only runtime exceptions and wrap checked exceptions into runtime. This simplifies general usage (most orient exceptions are runtime) ObjectCrudMixin: added multiple detachAll methods (in orient 2 object proxies doesn't work outside of transaction, so detaching is more important) DocumentCrudMixin: added create method to create document inside of transaction (in orient 2 it's now impossible to create document outside of transaction, but document changes doesn't require ongoing transaction) Add PersistentContext class, which combines connection provider, both templates and provide access to TransactionManager. It should be used instead of low level staff (simplifies usage) Remove deprecated finders auto scanning (breaking) Finders rewritten to extensions based architecture. Finder module renamed to repository to follow spring-data style (as well known and very similar realization). Not owned annotations (@Named, @Finder, @FirstResult, @MaxResults) replaced with spring-data like or orient specific annotations (@Param, @Query, @Function, @Skip, @Limit). Many annotations and classes renamed due to module rename. Many new repository features Ability to change user inside transaction (for example for security checks). Retry annotation to catch ONeedRetryException and re-execute method. (breaking) schemeMappingPackage option removed from OrientModule. Shortcut modules now must be used together with OrientModule and not substitute it. Modules renamed to AutoScanSchemeModule and PackageSchemeModule. Model class to scheme mapper, using orient default mapper, but with extensions support (custom annotations). AbstractObjectInitializer now generic enough to use for custom classpath filtering method.","title":"3.0.0 (2015-03-14)"},{"location":"about/history/#210-2015-01-06","text":"Finders now managed by guice and any additional aop could be applied. Abstract beans could define finder methods. (integration implemented in external library ) Finders auto scan api deprecated: now finder bean could be marked with @ProvidedBy and rely on guice JIT resolution Fix transactional aop warnings on jdk8 Fix finder descriptors cache Add ability to disable finder descriptors cache using property and method to clear current cache","title":"2.1.0 (2015-01-06)"},{"location":"about/history/#202-2014-11-26","text":"Update orient (1.7.9 > 1.7.10 ( changes )) Fix single value vertex return from finder (projection should not occur) Add explicit scheme synchronization for AutoScanSchemeInitializer and PackageSchemeInitializer (useful for dynamic environments, like tests)","title":"2.0.2 (2014-11-26)"},{"location":"about/history/#201-2014-11-19","text":"Generics resolution extracted to separate lib generics-resolver","title":"2.0.1 (2014-11-19)"},{"location":"about/history/#200-2014-11-05","text":"Support different users (for example, to init schema with more powerful user and to use orient security model). Breaks pools api compatibility AutoScanFinderModule accept multiple packages for scanning Add document and vertex projection for single field (works for plain and array result): useful for count (or other aggregation functions) or selecting single field Support inheritance for finder beans and interfaces (mixins) and generics recognition through all hierarchy Support generic type query placeholders (finder class generic used as query placeholder) Add delegate finders (annotated interface method delegates execution to guice bean method) Add crud mixins for object and document finders: DocumentCrudMixin, ObjectCrudMixin Add pagination mixin for object and document finders: PaginationMixin","title":"2.0.0 (2014-11-05)"},{"location":"about/history/#111-2014-10-01","text":"Fix finder behaviour: empty collection conversion to single element","title":"1.1.1 (2014-10-01)"},{"location":"about/history/#110-2014-09-27","text":"Fix finder module available db types detection Add query placeholders support for finders Update orient (1.7.8 > 1.7.9) - important hotfix Add Optional support as finder return type (jdk or guava Optional) Add orient module option to disable database auto creation Update guice (4.beta4 -> 4.beta5)","title":"1.1.0 (2014-09-27)"},{"location":"about/history/#103-2014-09-15","text":"Fix remote connection support (avoid database creation)","title":"1.0.3 (2014-09-15)"},{"location":"about/history/#102-2014-08-16","text":"Fix pmd/checkstyle warnings","title":"1.0.2 (2014-08-16)"},{"location":"about/history/#101-2014-08-05","text":"Fix generated pom","title":"1.0.1 (2014-08-05)"},{"location":"about/history/#100-2014-08-05","text":"Added dynamic finders (as separate module) Module configuration moved from constructor to chained methods Default object scheme initializers now support graph compatible scheme creation Remove dependency on reflections library Important bugs fixed as a result of better tests coverage","title":"1.0.0 (2014-08-05)"},{"location":"about/history/#090-2014-07-29","text":"Initial release","title":"0.9.0 (2014-07-29)"},{"location":"about/license/","text":"The MIT License (MIT) Copyright \u00a9 2014-2018, Vyacheslav Rusakov Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"about/support/","text":"Support \u00b6 Gitter - chat Github issues - problems / enhancements","title":"Support"},{"location":"about/support/#support","text":"Gitter - chat Github issues - problems / enhancements","title":"Support"},{"location":"guide/cache/","text":"Cache \u00b6 Three caches used: Scheme object mapping cache Repository descriptors Generics cache Scheme object mapping cache \u00b6 When predefined PackageSchemeModule or AutoScanSchemeModule object mapping modules used or ObjectSchemeInitializer used directly, mapped objects are cached. The is required to avoid redundant computations for registering same types: if models use some base class, then base class would be registered multiple times (for each entity) without cache. Normally, cache should not cause problems, because scheme is initialized on application start and doesn't changed anymore. Cache may be cleared at any time: @Inject ObjectSchemeInitializer initializer; ... initializer.clearModelCache(); Repository descriptors \u00b6 Repository descriptors computed on first repository method execution and cached to speed up future method executions. If you use JRebel or other class reloading tool (maybe some other reason) you will need to disable descriptors caching. To do it set system property or environment variable: ru.vyarus.guice.persist.orient.repository.core.MethodDescriptorFactory.cache=false Or from code: MethodDescriptorFactory . disableCache (); Also you can clear cache manually (on instance): @Inject MethodDescriptorFactory factory ; ... factory . clearCache () Note Disabling descriptors case, also disables generics resolution cache. Generics cache \u00b6 External library used for generics resolution: generics-resolver . It maintains resolved class generics cache (to avoid resolution for same classes). Note Disabling descriptors cache will disable generics cache, so usually you don't need to know about it.","title":"Cache"},{"location":"guide/cache/#cache","text":"Three caches used: Scheme object mapping cache Repository descriptors Generics cache","title":"Cache"},{"location":"guide/cache/#scheme-object-mapping-cache","text":"When predefined PackageSchemeModule or AutoScanSchemeModule object mapping modules used or ObjectSchemeInitializer used directly, mapped objects are cached. The is required to avoid redundant computations for registering same types: if models use some base class, then base class would be registered multiple times (for each entity) without cache. Normally, cache should not cause problems, because scheme is initialized on application start and doesn't changed anymore. Cache may be cleared at any time: @Inject ObjectSchemeInitializer initializer; ... initializer.clearModelCache();","title":"Scheme object mapping cache"},{"location":"guide/cache/#repository-descriptors","text":"Repository descriptors computed on first repository method execution and cached to speed up future method executions. If you use JRebel or other class reloading tool (maybe some other reason) you will need to disable descriptors caching. To do it set system property or environment variable: ru.vyarus.guice.persist.orient.repository.core.MethodDescriptorFactory.cache=false Or from code: MethodDescriptorFactory . disableCache (); Also you can clear cache manually (on instance): @Inject MethodDescriptorFactory factory ; ... factory . clearCache () Note Disabling descriptors case, also disables generics resolution cache.","title":"Repository descriptors"},{"location":"guide/cache/#generics-cache","text":"External library used for generics resolution: generics-resolver . It maintains resolved class generics cache (to avoid resolution for same classes). Note Disabling descriptors cache will disable generics cache, so usually you don't need to know about it.","title":"Generics cache"},{"location":"guide/configuration/","text":"Configuration \u00b6 Core orient integration is provided by OrientModule : install ( new OrientModule ( url , user , password )); See orient documentation for supported db types. In short: 'memory:dbname' to use in-memory database 'plocal:dbname' to use embedded database (no server required, local fs folder will be used); db name must be local fs path 'remote:dbname' to use remote db (you need to start server to use it) By default use admin/admin user. Auto database creation \u00b6 Auto database creation for local types (all except 'remote') is enabled by default, but you can switch it off. Auto creation is nice for playing/developing/testing phase, but most likely will not be useful for production. install ( new OrientModule ( url , user , password ) . autoCreateLocalDatabase ( false )); Default transaction type \u00b6 Default transactions configuration may be specified as additional module parameter. By default, OPTIMISTIC transactions used (use optimistic locking based on object version, same way as hibernate optimistic locking). NOTX mode disables transactions. For example, to switch off transactions use: install ( new OrientModule ( url , user , password ) . defaultTransactionConfig ( new TxConfig ( OTransaction . TXTYPE . NOTX )); Custom orient types \u00b6 You may need to use orient custom types (custom converter to/from object, used only in object connection ). To register custom type: install ( new OrientModule ( url , user , password ) . withCustomTypes ( MyTypeSerializer . class )); where MyTypeSerializer implements OObjectSerializer Serializers are assumed to be guice beans: declare it in guice module if required, otherwise guice JIT will be used to obtain converter instance. Custom converters are collected using guice multibinder feature, so you can also install custom converter by using multibinder directly: Multibinder . newSetBinder ( binder (), OObjectSerializer . class ) . addBinding (). to ( serializerClass ); Scheme initialization \u00b6 To initialize (or migrate) scheme register implementation of ru . vyarus . guice . persist . orient . db . scheme . SchemeInitializer Example: install ( new OrientModule ( url , user , password )); bind ( SchemeInitializer . class ). to ( MySchemeInitializer . class ); Scheme initializer is called in NOTX unit of work (orient requires database scheme updates to be performed without transaction). By default, no-op implementation enabled. Object scheme mapping \u00b6 If you use object api you can use provided object scheme mapper to create (or update) database from pojo beans (JPA like). Tip it is also able to mix object mapping with graph types, so you can mix object and graph apis (see @EdgeType and @VertexType ). See object scheme mapper guide for details. Note Custom migration annotations could be easily added . Data initialization \u00b6 To initialize (or migrate) data register implementation of ru . vyarus . guice . persist . orient . db . data . DataInitializer By default, no-op implementation enabled. Example: bind ( DataInitializer . class ). to ( YourDataInitializerImpl . class ); Initializer is called WITHOUT predefined unit of work, because of different possible requirements. You should define unit of work (maybe more than one) yourself (with annotation or manual). Lifecycle \u00b6 You need to manually start/stop persist service in your code (because only you can control application lifecycle). On start connection pools will be initialized, database created (if required) and scheme/data initializers called. Stop will shutdown all connection pools. @Inject PersistService orientService public void onAppStartup (){ orientService . start () } public void onAppShutdown (){ orientService . stop () } Orient configuration \u00b6 Configuration could be done on instance: db . getStorage (). getConfiguration () Or globally: OGlobalConfiguration . MVRBTREE_NODE_PAGE_SIZE . setValue ( 2048 ); Read about all configuration options","title":"Configuration"},{"location":"guide/configuration/#configuration","text":"Core orient integration is provided by OrientModule : install ( new OrientModule ( url , user , password )); See orient documentation for supported db types. In short: 'memory:dbname' to use in-memory database 'plocal:dbname' to use embedded database (no server required, local fs folder will be used); db name must be local fs path 'remote:dbname' to use remote db (you need to start server to use it) By default use admin/admin user.","title":"Configuration"},{"location":"guide/configuration/#auto-database-creation","text":"Auto database creation for local types (all except 'remote') is enabled by default, but you can switch it off. Auto creation is nice for playing/developing/testing phase, but most likely will not be useful for production. install ( new OrientModule ( url , user , password ) . autoCreateLocalDatabase ( false ));","title":"Auto database creation"},{"location":"guide/configuration/#default-transaction-type","text":"Default transactions configuration may be specified as additional module parameter. By default, OPTIMISTIC transactions used (use optimistic locking based on object version, same way as hibernate optimistic locking). NOTX mode disables transactions. For example, to switch off transactions use: install ( new OrientModule ( url , user , password ) . defaultTransactionConfig ( new TxConfig ( OTransaction . TXTYPE . NOTX ));","title":"Default transaction type"},{"location":"guide/configuration/#custom-orient-types","text":"You may need to use orient custom types (custom converter to/from object, used only in object connection ). To register custom type: install ( new OrientModule ( url , user , password ) . withCustomTypes ( MyTypeSerializer . class )); where MyTypeSerializer implements OObjectSerializer Serializers are assumed to be guice beans: declare it in guice module if required, otherwise guice JIT will be used to obtain converter instance. Custom converters are collected using guice multibinder feature, so you can also install custom converter by using multibinder directly: Multibinder . newSetBinder ( binder (), OObjectSerializer . class ) . addBinding (). to ( serializerClass );","title":"Custom orient types"},{"location":"guide/configuration/#scheme-initialization","text":"To initialize (or migrate) scheme register implementation of ru . vyarus . guice . persist . orient . db . scheme . SchemeInitializer Example: install ( new OrientModule ( url , user , password )); bind ( SchemeInitializer . class ). to ( MySchemeInitializer . class ); Scheme initializer is called in NOTX unit of work (orient requires database scheme updates to be performed without transaction). By default, no-op implementation enabled.","title":"Scheme initialization"},{"location":"guide/configuration/#object-scheme-mapping","text":"If you use object api you can use provided object scheme mapper to create (or update) database from pojo beans (JPA like). Tip it is also able to mix object mapping with graph types, so you can mix object and graph apis (see @EdgeType and @VertexType ). See object scheme mapper guide for details. Note Custom migration annotations could be easily added .","title":"Object scheme mapping"},{"location":"guide/configuration/#data-initialization","text":"To initialize (or migrate) data register implementation of ru . vyarus . guice . persist . orient . db . data . DataInitializer By default, no-op implementation enabled. Example: bind ( DataInitializer . class ). to ( YourDataInitializerImpl . class ); Initializer is called WITHOUT predefined unit of work, because of different possible requirements. You should define unit of work (maybe more than one) yourself (with annotation or manual).","title":"Data initialization"},{"location":"guide/configuration/#lifecycle","text":"You need to manually start/stop persist service in your code (because only you can control application lifecycle). On start connection pools will be initialized, database created (if required) and scheme/data initializers called. Stop will shutdown all connection pools. @Inject PersistService orientService public void onAppStartup (){ orientService . start () } public void onAppShutdown (){ orientService . stop () }","title":"Lifecycle"},{"location":"guide/configuration/#orient-configuration","text":"Configuration could be done on instance: db . getStorage (). getConfiguration () Or globally: OGlobalConfiguration . MVRBTREE_NODE_PAGE_SIZE . setValue ( 2048 ); Read about all configuration options","title":"Orient configuration"},{"location":"guide/connections/","text":"Connections \u00b6 Document is the core connection type. Object and graph apis use document connection internally. Connection object mainly defines the result of queries: document connection will always return ODocument object connection returns mapped pojos (actually proxies) or ODocument for fields selections and graph api returns Vertex and Edge types. And of course connections provide specific apis for types. You can use any connections within single transaction and changes made in one connection type will be visible in other connections. This allows you, for example to update data using object api and create relations using graph api. To access connection object inside transaction use PersistentContext generified with the type of required connection. PersistentContext<OObjectDatabaseTx> for object database connection PersistentContext<ODatabaseDocumentTx> for document database connection PersistentContext<OrientBaseGraph> for graph database connection (transactional or not) PersistentContext<OrientGraph> for transactional graph database connection (will fail if notx transaction type) PersistentContext<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note You can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Note PersistentContext methods are shortcuts for low level api (simplifies usage). You can extend it to add more shortcut methods or make your own: it is not used internally and exists only for public usage. For example public class MyService { @Inject private PersistenceContext < OObjectDatabaseTx > context ; public List < Model > findByName ( final String name ) { // manual transaction declaration return context . doInTransaction (( db ) -> // pure orient api db . query ( new OSQLSynchQuery < Model >( \"select from Model where name=?\" ), name ) ); } } Alternatively, you can directly inject connections: @Inject private Provider < OObjectDatabaseTx > db ; But note that it would not work without external transaction. Pools \u00b6 Each connection type is managed with its own PoolManager . Default pool implementations: DocumentPool ObjectPool GraphPool Pools are registered in OrientModule 's configurePools() method. You can override it to register your own pool implementations. Custom pools registration example: public class MyOrientModule extends OrientModule { @Override protected void configurePools () { bindPool ( ODatabaseDocumentTx . class , DocumentPool . class ); bindPool ( OObjectDatabaseTx . class , ObjectPool . class ); bindPool ( OrientGraph . class , MyCustomGraphPool . class ); // note that for graph few entities could be provided: OrientGraph, OrientGraphNoTx, OrientBaseGraph. // default implementation registers additional providers to handle all cases // see ru.vyarus.guice.persist.orient.support.pool.GraphPoolBinder } } Default pool implementation maintains only pool for documents (using OPartitionedDatabasePoolFactory ). Other pools use document connection to construct object and graph connection objects. This merges different connections transactions (change in one connection type will be visible in all others). OGlobalConfiguration.DB_POOL_MAX used as max pools size (for OPartitionedDatabasePoolFactory). Important Connection may be acquired from pool only inside unit of work. Connection object is bound to thread local inside pool, returning always the same instance during transaction. Actual orient transaction is started only when connection object is obtained from pool. Pools interactions \u00b6 Before v3, each pool manage its own connection, as a result transactions were different for all connection types and changes were not visible between them. Such behavior is still possible: write new pool implementations and register them in OrientModule. TransactionManager supports multiple transactions out of the box (legacy behavior). Note PoolManager 's commit or rollback methods will be called on each transaction end, even if no connection where obtained from this pool. Pool must control such situation. When explicit rollback called, transaction manager will call rollback on each pool. When exception occurred on commit, other pools will be still committed and rollback called only on failed pool. But other pools will receive rollback call after commit and must ignore it. If you really want to use multi-transactional approach look sources for 2.x brach.","title":"Connections"},{"location":"guide/connections/#connections","text":"Document is the core connection type. Object and graph apis use document connection internally. Connection object mainly defines the result of queries: document connection will always return ODocument object connection returns mapped pojos (actually proxies) or ODocument for fields selections and graph api returns Vertex and Edge types. And of course connections provide specific apis for types. You can use any connections within single transaction and changes made in one connection type will be visible in other connections. This allows you, for example to update data using object api and create relations using graph api. To access connection object inside transaction use PersistentContext generified with the type of required connection. PersistentContext<OObjectDatabaseTx> for object database connection PersistentContext<ODatabaseDocumentTx> for document database connection PersistentContext<OrientBaseGraph> for graph database connection (transactional or not) PersistentContext<OrientGraph> for transactional graph database connection (will fail if notx transaction type) PersistentContext<OrientGraphNoTx> for non transactional graph database connection (will provide only for notx transaction type, otherwise fail) Note You can't use both OrientGraph and OrientGraphNoTx in the same transaction (type must be used according to transaction type). OrientBaseGraph may be used in places where both types are possible (its the base class for both). Note PersistentContext methods are shortcuts for low level api (simplifies usage). You can extend it to add more shortcut methods or make your own: it is not used internally and exists only for public usage. For example public class MyService { @Inject private PersistenceContext < OObjectDatabaseTx > context ; public List < Model > findByName ( final String name ) { // manual transaction declaration return context . doInTransaction (( db ) -> // pure orient api db . query ( new OSQLSynchQuery < Model >( \"select from Model where name=?\" ), name ) ); } } Alternatively, you can directly inject connections: @Inject private Provider < OObjectDatabaseTx > db ; But note that it would not work without external transaction.","title":"Connections"},{"location":"guide/connections/#pools","text":"Each connection type is managed with its own PoolManager . Default pool implementations: DocumentPool ObjectPool GraphPool Pools are registered in OrientModule 's configurePools() method. You can override it to register your own pool implementations. Custom pools registration example: public class MyOrientModule extends OrientModule { @Override protected void configurePools () { bindPool ( ODatabaseDocumentTx . class , DocumentPool . class ); bindPool ( OObjectDatabaseTx . class , ObjectPool . class ); bindPool ( OrientGraph . class , MyCustomGraphPool . class ); // note that for graph few entities could be provided: OrientGraph, OrientGraphNoTx, OrientBaseGraph. // default implementation registers additional providers to handle all cases // see ru.vyarus.guice.persist.orient.support.pool.GraphPoolBinder } } Default pool implementation maintains only pool for documents (using OPartitionedDatabasePoolFactory ). Other pools use document connection to construct object and graph connection objects. This merges different connections transactions (change in one connection type will be visible in all others). OGlobalConfiguration.DB_POOL_MAX used as max pools size (for OPartitionedDatabasePoolFactory). Important Connection may be acquired from pool only inside unit of work. Connection object is bound to thread local inside pool, returning always the same instance during transaction. Actual orient transaction is started only when connection object is obtained from pool.","title":"Pools"},{"location":"guide/connections/#pools-interactions","text":"Before v3, each pool manage its own connection, as a result transactions were different for all connection types and changes were not visible between them. Such behavior is still possible: write new pool implementations and register them in OrientModule. TransactionManager supports multiple transactions out of the box (legacy behavior). Note PoolManager 's commit or rollback methods will be called on each transaction end, even if no connection where obtained from this pool. Pool must control such situation. When explicit rollback called, transaction manager will call rollback on each pool. When exception occurred on commit, other pools will be still committed and rollback called only on failed pool. But other pools will receive rollback call after commit and must ignore it. If you really want to use multi-transactional approach look sources for 2.x brach.","title":"Pools interactions"},{"location":"guide/transactions/","text":"Transactions \u00b6 Unit of work (transaction) \u00b6 Unit of work defines transaction scope. Actual orient transaction will start only on first connection acquire (so basically, unit of work may not contain actual orient transaction, but for simplicity both may be considered equal). Unit of work may be defined by: @Transactional annotation on guice bean or single method (additional @TxType annotation allows to define different transaction type for specific unit of work) Inject PersistentContext bean into your service and use its methods Using TransactionManager begin() and end() methods. First two options are better, because they automatically manage rollbacks and avoid not closed (forgot to call end) transactions. Important Orient 2 is more strict about transactions: now ODocument could be created only inside transaction and object proxy can't be used outside of transaction. Warning When you get error like Database instance is not set in current thread. Assure to set it with: ODatabaseRecordThreadLocal.instance().set(db) It almost certainly means that you perform transactional operation outside of transaction. Simply enlarge transaction scope. When you inside transaction, activateOnCurrentThread() is called each time you obtain connection from raw connection provider or PersistentContext and you will always have correctly bound connection. For example, even document creation ( new ODocument() ) must be performed inside transaction. Examples \u00b6 Defining transaction for all methods in bean (both method1 and method2 will be executed in transaction): @Transactional public class MyBean { public void method1 () ... public void method2 () ... } Defining no tx transaction on method: @Transactional @TxType ( OTransaction . TXTYPE . NOTX ) public void method () Notx usually used for scheme updates, but in some cases may be used to speed up execution (but in most cases its better to use transaction for consistency). Using PersistentContext : @Inject PersistentContext < OObjectDatabaseTx > context ; ... context . doInTransaction ( new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); Using TransactionManager : @Inject TransactionManager manager ; ... manager . begin (); try { // do something manager . end (); } catch ( Exception ex ) { manager . rollback () } Note In contrast to spring default proxies, in guice when you call bean method inside the same bean, annotation interceptor will still work. So it's possible to define few units of work withing single bean using annotations: public void nonTxMethod (){ doTx1 (); doTx2 (); } // methods can't be private (should be at least package private) @Transactional void doTx1 () {..} @Transactional void doTx2 () {..} External transaction \u00b6 In some rear cases it is required to use already created database object (use thread-bound connection inside guice). This is possible by using special TxConfig.external() config. // transaction opened manually ODatabaseDocumentTx db = new ODatabaseDocumentTx (); // database object must be bound on current thread (orient did this automatically // in most cases, so direct call is not required) db . activateOnCurrentThread (); // context is PersistentContext, but TxTemplate may be called directly context . doInTransaction ( TxConfig . external (), () -> { // here we can use external transaction }) // connection closed manually db . close (); Important In contrast to normal transaction, guice will not manage commits and rollbacks: it is assumed that connection lifecycle is correctly managed manually. There are intentionally no shortcuts for starting external unit of work because its not supposed to be used often and must be applied only in cases where other behaviour is impossible. Retry \u00b6 Due to orient implementation specifics, you may face OConcurrentModificationException . Such exception would be ok for optimistic locking check on object save (object contains version and if db version is different then your object considered stale, and you cant save it). But, for example, even query like this may fail: update Model set name = 'updated' In concurrent environment this query also may cause OConcurrentModificationException (other transaction changed object version in between of model update: action must be repeated). There is a special base class for such exceptions: ONeedRetryException . So by design some operations may fail initially, but succeed on repeated execution. To fix such places you can use @Retry annotation. It catches exception and if its ONeedRetryException (or any cause is retry exception) it will repeat method execution. @Retry ( 100 ) @Transactional public void update () Important Annotation must be defined outside of transaction, because retry exception is casted on commit and it's impossible to catch it inside transaction. If @Retry annotated method will be executed under transaction, it will fail (catches redundant definition). So be careful using it: be sure not to use annotated methods in transaction. @Retry may be used with @Transactional on the same method (retry applied before). In some cases using script instead of query solves concurrent update problem (even without retry): begin update Model set name='updated' commit Anyway, always write concurrent tests to be sure.","title":"Transactions"},{"location":"guide/transactions/#transactions","text":"","title":"Transactions"},{"location":"guide/transactions/#unit-of-work-transaction","text":"Unit of work defines transaction scope. Actual orient transaction will start only on first connection acquire (so basically, unit of work may not contain actual orient transaction, but for simplicity both may be considered equal). Unit of work may be defined by: @Transactional annotation on guice bean or single method (additional @TxType annotation allows to define different transaction type for specific unit of work) Inject PersistentContext bean into your service and use its methods Using TransactionManager begin() and end() methods. First two options are better, because they automatically manage rollbacks and avoid not closed (forgot to call end) transactions. Important Orient 2 is more strict about transactions: now ODocument could be created only inside transaction and object proxy can't be used outside of transaction. Warning When you get error like Database instance is not set in current thread. Assure to set it with: ODatabaseRecordThreadLocal.instance().set(db) It almost certainly means that you perform transactional operation outside of transaction. Simply enlarge transaction scope. When you inside transaction, activateOnCurrentThread() is called each time you obtain connection from raw connection provider or PersistentContext and you will always have correctly bound connection. For example, even document creation ( new ODocument() ) must be performed inside transaction.","title":"Unit of work (transaction)"},{"location":"guide/transactions/#examples","text":"Defining transaction for all methods in bean (both method1 and method2 will be executed in transaction): @Transactional public class MyBean { public void method1 () ... public void method2 () ... } Defining no tx transaction on method: @Transactional @TxType ( OTransaction . TXTYPE . NOTX ) public void method () Notx usually used for scheme updates, but in some cases may be used to speed up execution (but in most cases its better to use transaction for consistency). Using PersistentContext : @Inject PersistentContext < OObjectDatabaseTx > context ; ... context . doInTransaction ( new TxAction < Void >() { @Override public Void execute () throws Throwable { // something return null ; } }); Using TransactionManager : @Inject TransactionManager manager ; ... manager . begin (); try { // do something manager . end (); } catch ( Exception ex ) { manager . rollback () } Note In contrast to spring default proxies, in guice when you call bean method inside the same bean, annotation interceptor will still work. So it's possible to define few units of work withing single bean using annotations: public void nonTxMethod (){ doTx1 (); doTx2 (); } // methods can't be private (should be at least package private) @Transactional void doTx1 () {..} @Transactional void doTx2 () {..}","title":"Examples"},{"location":"guide/transactions/#external-transaction","text":"In some rear cases it is required to use already created database object (use thread-bound connection inside guice). This is possible by using special TxConfig.external() config. // transaction opened manually ODatabaseDocumentTx db = new ODatabaseDocumentTx (); // database object must be bound on current thread (orient did this automatically // in most cases, so direct call is not required) db . activateOnCurrentThread (); // context is PersistentContext, but TxTemplate may be called directly context . doInTransaction ( TxConfig . external (), () -> { // here we can use external transaction }) // connection closed manually db . close (); Important In contrast to normal transaction, guice will not manage commits and rollbacks: it is assumed that connection lifecycle is correctly managed manually. There are intentionally no shortcuts for starting external unit of work because its not supposed to be used often and must be applied only in cases where other behaviour is impossible.","title":"External transaction"},{"location":"guide/transactions/#retry","text":"Due to orient implementation specifics, you may face OConcurrentModificationException . Such exception would be ok for optimistic locking check on object save (object contains version and if db version is different then your object considered stale, and you cant save it). But, for example, even query like this may fail: update Model set name = 'updated' In concurrent environment this query also may cause OConcurrentModificationException (other transaction changed object version in between of model update: action must be repeated). There is a special base class for such exceptions: ONeedRetryException . So by design some operations may fail initially, but succeed on repeated execution. To fix such places you can use @Retry annotation. It catches exception and if its ONeedRetryException (or any cause is retry exception) it will repeat method execution. @Retry ( 100 ) @Transactional public void update () Important Annotation must be defined outside of transaction, because retry exception is casted on commit and it's impossible to catch it inside transaction. If @Retry annotated method will be executed under transaction, it will fail (catches redundant definition). So be careful using it: be sure not to use annotated methods in transaction. @Retry may be used with @Transactional on the same method (retry applied before). In some cases using script instead of query solves concurrent update problem (even without retry): begin update Model set name='updated' commit Anyway, always write concurrent tests to be sure.","title":"Retry"},{"location":"mapping/objectscheme/","text":"Object scheme mapping \u00b6 Default orient mapping is limited in some cases, and that's why custom mapper implementation provided (extending default mapper). Note This is development time solution to quickly update scheme. Its usage in production is obviously limited. Default object scheme mapping \u00b6 See orient object mapping documentation for object mapping ( and general object database page ). Orient ignore package, so class may be moved between packages If model class extends some other class it will be also registered as separate scheme class. When entity field removed, orient will hold all data already stored in records of that field When entity field type changes, orient WILL NOT migrate automatically (you need to handle it manually, using custom scheme initializer or through orient studio ). When class renamed orient will register it as new entity and you will have to manually migrate all data (it's possible to use sql commands to rename entity in scheme) To use entity within optimistic transaction, it must have version field (annotated with @Version ). You should add field manually or extend all entities from provided base class: VersionedEntity JPA annotations can be used to define cascades JPA @Id annotation may be used to bind object id (String or Object to bind as RID) Most useful are id and version mapping: @Id private String id ; @Version private Long version ; Version property is required for optimistic transactions (enabled by default). Graph types \u00b6 Graph types are usual types with just one difference: its root class must extend V or E (for vertex or edge). You may register scheme class (even with default orient mapper) and later make it as extends V and it will be valid vertex type, usable for graph api. Extended mapper support this case with @EdgeType and @VertexType annotations. Setup \u00b6 Mapper is registered as scheme initializer bean, but mapper may be used directly too: ObjectSchemeInitializer . Two scheme initializer implementations provided: PackageSchemeInitializer - use all classes in package to init or update scheme (package should be specified as module constructor argument). AutoScanSchemeInitializer - search classpath for entities annotated with @Persistent annotation and use them to create/update scheme. They can be enabled by PackageSchemeModule and AutoScanSchemeModule modules. Note Modules must be registered together with main OrientModule . For example: install ( new AutoScanSchemeModule ( \"my.model.root.package\" )); Mapping annotations \u00b6 Extended mapper provides additional annotations: Class: @EdgeType - register class as edge type @VertexType - register class as vertex type @RenameFrom - renames existing scheme class before class registration @Recreate - drop and create fresh scheme on each start @CompositeIndex - creates composite index for class (index span multiple properties) @CompositeLuceneIndex - creates composite lucene index for class (index span multiple properties) @DropIndexes - drops existing indexes on start Field: @RenamePropertyFrom - renames existing scheme property before class registration @Index - creates index for annotated field @FulltextIndex - creates fulltext index for annotated field @LuceneIndex - creates lucene index for annotated field @Readonly - marks property as readonly @ONotNull - marks property as not null @Mandatory - marks property as mandatory @CaseInsensitive - marks property as case insensitive Tip New annotations could be implemented easily as plugins . All annotations are safe: they may remain in model even after performing required action (they will just do nothing). This makes possible to use them as simple migration mechanism (but its better to use something stronger for production). Important Remember that scheme created from objects maintain same hierarchy as your objects. E.g. if you use provided VersionedEntity class as base class for entities, it will be also registered in scheme (nothing bad, you may not notice it). But for graphs hierarchies its more important: both vertex and edge objects can't extend same class (root class in hierarchy must extend V or E). So if you use @VertexType or @EdgeType annotations make sure their hierarchy not intersect. See documentation: Classes Properties Indexes ( create index ) How it works \u00b6 Suppose we have model: class Model extends BaseModel When model class is registered (note that this will be performed by scheme module automatically) objectSchemeInitializer . register ( Model . class ); Its hierarchy parsed and first BaseModel class registered and then Model class. During registration initializer lookups all type and field annotations and execute them before and after orient registration. To avoid registration of same base classes many times, registered classes are cached and not processed next time. Usually, scheme initialization is performed on application startup so you should not notice cache presence. But if you need to register class one more time, you may clear cache manually: objectSchemeInitializer . clearModelCache (); ( ObjectSchemeInitializer is registered as guice bean and so available for injection)","title":"Overview"},{"location":"mapping/objectscheme/#object-scheme-mapping","text":"Default orient mapping is limited in some cases, and that's why custom mapper implementation provided (extending default mapper). Note This is development time solution to quickly update scheme. Its usage in production is obviously limited.","title":"Object scheme mapping"},{"location":"mapping/objectscheme/#default-object-scheme-mapping","text":"See orient object mapping documentation for object mapping ( and general object database page ). Orient ignore package, so class may be moved between packages If model class extends some other class it will be also registered as separate scheme class. When entity field removed, orient will hold all data already stored in records of that field When entity field type changes, orient WILL NOT migrate automatically (you need to handle it manually, using custom scheme initializer or through orient studio ). When class renamed orient will register it as new entity and you will have to manually migrate all data (it's possible to use sql commands to rename entity in scheme) To use entity within optimistic transaction, it must have version field (annotated with @Version ). You should add field manually or extend all entities from provided base class: VersionedEntity JPA annotations can be used to define cascades JPA @Id annotation may be used to bind object id (String or Object to bind as RID) Most useful are id and version mapping: @Id private String id ; @Version private Long version ; Version property is required for optimistic transactions (enabled by default).","title":"Default object scheme mapping"},{"location":"mapping/objectscheme/#graph-types","text":"Graph types are usual types with just one difference: its root class must extend V or E (for vertex or edge). You may register scheme class (even with default orient mapper) and later make it as extends V and it will be valid vertex type, usable for graph api. Extended mapper support this case with @EdgeType and @VertexType annotations.","title":"Graph types"},{"location":"mapping/objectscheme/#setup","text":"Mapper is registered as scheme initializer bean, but mapper may be used directly too: ObjectSchemeInitializer . Two scheme initializer implementations provided: PackageSchemeInitializer - use all classes in package to init or update scheme (package should be specified as module constructor argument). AutoScanSchemeInitializer - search classpath for entities annotated with @Persistent annotation and use them to create/update scheme. They can be enabled by PackageSchemeModule and AutoScanSchemeModule modules. Note Modules must be registered together with main OrientModule . For example: install ( new AutoScanSchemeModule ( \"my.model.root.package\" ));","title":"Setup"},{"location":"mapping/objectscheme/#mapping-annotations","text":"Extended mapper provides additional annotations: Class: @EdgeType - register class as edge type @VertexType - register class as vertex type @RenameFrom - renames existing scheme class before class registration @Recreate - drop and create fresh scheme on each start @CompositeIndex - creates composite index for class (index span multiple properties) @CompositeLuceneIndex - creates composite lucene index for class (index span multiple properties) @DropIndexes - drops existing indexes on start Field: @RenamePropertyFrom - renames existing scheme property before class registration @Index - creates index for annotated field @FulltextIndex - creates fulltext index for annotated field @LuceneIndex - creates lucene index for annotated field @Readonly - marks property as readonly @ONotNull - marks property as not null @Mandatory - marks property as mandatory @CaseInsensitive - marks property as case insensitive Tip New annotations could be implemented easily as plugins . All annotations are safe: they may remain in model even after performing required action (they will just do nothing). This makes possible to use them as simple migration mechanism (but its better to use something stronger for production). Important Remember that scheme created from objects maintain same hierarchy as your objects. E.g. if you use provided VersionedEntity class as base class for entities, it will be also registered in scheme (nothing bad, you may not notice it). But for graphs hierarchies its more important: both vertex and edge objects can't extend same class (root class in hierarchy must extend V or E). So if you use @VertexType or @EdgeType annotations make sure their hierarchy not intersect. See documentation: Classes Properties Indexes ( create index )","title":"Mapping annotations"},{"location":"mapping/objectscheme/#how-it-works","text":"Suppose we have model: class Model extends BaseModel When model class is registered (note that this will be performed by scheme module automatically) objectSchemeInitializer . register ( Model . class ); Its hierarchy parsed and first BaseModel class registered and then Model class. During registration initializer lookups all type and field annotations and execute them before and after orient registration. To avoid registration of same base classes many times, registered classes are cached and not processed next time. Usually, scheme initialization is performed on application startup so you should not notice cache presence. But if you need to register class one more time, you may clear cache manually: objectSchemeInitializer . clearModelCache (); ( ObjectSchemeInitializer is registered as guice bean and so available for injection)","title":"How it works"},{"location":"mapping/writing/","text":"Writing custom annotations \u00b6 Two types of extensions supported: type and field (class and property) extensions. Extensions are resolved from annotations: extension annotation must be annotated with one of: @SchemeTypeInit @SchemeFieldInit This annotation contains extension class, which is instantiated by guice. No explicit registration required for extension: it's always resolved from found annotation. Both type and field extension interfaces ( TypeExtension , FieldExtension ) contains before and after methods. Before called before registering class with orient default mechanism and after - after registration. Extensions are ordered according to @Order annotation on extension class. Consider using singleton scope extensions. If you will choose prototype scope, then single extension instance will be used for both before and after calls. But different instance will be used for different model classes. SchemeDescriptor object is passed to all extension methods and contains some basic context info. Extension may need to modify descriptor state: e.g. if extension drops existing class in before method, it must set descriptor.initialRegistartion = true . All provided annotations are extensions. Use them as examples. AbstractObjectInitializer may be used as base class for custom classpath scan model resolution strategy (instead of two provided). Example \u00b6 As an example, let's take exisitng ONotNull annotation: @Target ( FIELD ) @Retention ( RUNTIME ) @SchemeFieldInit ( NotNullFieldExtension . class ) public @interface ONotNull { boolean value () default true ; } Implementation: @Singleton public class NotNullFieldExtension implements FieldExtension < ONotNull > { private final Logger logger = LoggerFactory . getLogger ( NotNullFieldExtension . class ); @Override public void beforeRegistration ( final OObjectDatabaseTx db , final SchemeDescriptor descriptor , final Field field , final ONotNull annotation ) { // not needed } @Override public void afterRegistration ( final OObjectDatabaseTx db , final SchemeDescriptor descriptor , final Field field , final ONotNull annotation ) { final String name = field . getName (); final boolean notnull = annotation . value (); final OProperty property = db . getMetadata (). getSchema () . getClass ( descriptor . schemeClass ). getProperty ( name ); if ( property . isNotNull () != notnull ) { property . setNotNull ( notnull ); logger . debug ( \"Set {}.{} property notnull={}\" , descriptor . schemeClass , name , notnull ); } } } That's all: no explicit registrations reqired (assuming that object mapper is registered as schema initializer ). When we use annotation on bean: public class Model { @ONotNull private String foo ; } ObjectSchemeInitializer will ananlyse bean, find ONotNull annotation and detect that it's annotated with SchemeFieldInit . Specified extension class is instantiated with guice and used.","title":"Writing custom annotations"},{"location":"mapping/writing/#writing-custom-annotations","text":"Two types of extensions supported: type and field (class and property) extensions. Extensions are resolved from annotations: extension annotation must be annotated with one of: @SchemeTypeInit @SchemeFieldInit This annotation contains extension class, which is instantiated by guice. No explicit registration required for extension: it's always resolved from found annotation. Both type and field extension interfaces ( TypeExtension , FieldExtension ) contains before and after methods. Before called before registering class with orient default mechanism and after - after registration. Extensions are ordered according to @Order annotation on extension class. Consider using singleton scope extensions. If you will choose prototype scope, then single extension instance will be used for both before and after calls. But different instance will be used for different model classes. SchemeDescriptor object is passed to all extension methods and contains some basic context info. Extension may need to modify descriptor state: e.g. if extension drops existing class in before method, it must set descriptor.initialRegistartion = true . All provided annotations are extensions. Use them as examples. AbstractObjectInitializer may be used as base class for custom classpath scan model resolution strategy (instead of two provided).","title":"Writing custom annotations"},{"location":"mapping/writing/#example","text":"As an example, let's take exisitng ONotNull annotation: @Target ( FIELD ) @Retention ( RUNTIME ) @SchemeFieldInit ( NotNullFieldExtension . class ) public @interface ONotNull { boolean value () default true ; } Implementation: @Singleton public class NotNullFieldExtension implements FieldExtension < ONotNull > { private final Logger logger = LoggerFactory . getLogger ( NotNullFieldExtension . class ); @Override public void beforeRegistration ( final OObjectDatabaseTx db , final SchemeDescriptor descriptor , final Field field , final ONotNull annotation ) { // not needed } @Override public void afterRegistration ( final OObjectDatabaseTx db , final SchemeDescriptor descriptor , final Field field , final ONotNull annotation ) { final String name = field . getName (); final boolean notnull = annotation . value (); final OProperty property = db . getMetadata (). getSchema () . getClass ( descriptor . schemeClass ). getProperty ( name ); if ( property . isNotNull () != notnull ) { property . setNotNull ( notnull ); logger . debug ( \"Set {}.{} property notnull={}\" , descriptor . schemeClass , name , notnull ); } } } That's all: no explicit registrations reqired (assuming that object mapper is registered as schema initializer ). When we use annotation on bean: public class Model { @ONotNull private String foo ; } ObjectSchemeInitializer will ananlyse bean, find ONotNull annotation and detect that it's annotated with SchemeFieldInit . Specified extension class is instantiated with guice and used.","title":"Example"},{"location":"mapping/class/compositeindex/","text":"@CompositeIndex \u00b6 Scope: class Creates composite index (index span multiple properties). @CompositeIndex ( name = \"test\" , type = OClass . INDEX_TYPE . NOTUNIQUE , fields = [ \"foo\" , \"bar\" ]) public class MyModel {...} For multiple indexes creation use wrapper: @CompositeIndex.List ({ @CompositeIndex ( name = \"test\" , type = OClass . INDEX_TYPE . NOTUNIQUE , fields = [ \"foo\" , \"bar\" ]) @CompositeIndex ( name = \"test2\" , type = OClass . INDEX_TYPE . DICTIONARY , fields = [ \"foo\" , \"bar\" ]) }) public class MyModel {...} Note that index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index type is different - it will be recreated with required type. If existing index build with different fields, error will be thrown.","title":"@CompositeIndex"},{"location":"mapping/class/compositeindex/#compositeindex","text":"Scope: class Creates composite index (index span multiple properties). @CompositeIndex ( name = \"test\" , type = OClass . INDEX_TYPE . NOTUNIQUE , fields = [ \"foo\" , \"bar\" ]) public class MyModel {...} For multiple indexes creation use wrapper: @CompositeIndex.List ({ @CompositeIndex ( name = \"test\" , type = OClass . INDEX_TYPE . NOTUNIQUE , fields = [ \"foo\" , \"bar\" ]) @CompositeIndex ( name = \"test2\" , type = OClass . INDEX_TYPE . DICTIONARY , fields = [ \"foo\" , \"bar\" ]) }) public class MyModel {...} Note that index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index type is different - it will be recreated with required type. If existing index build with different fields, error will be thrown.","title":"@CompositeIndex"},{"location":"mapping/class/compositeluceneindex/","text":"@CompositeLuceneIndex \u00b6 Scope: class Creates composite lucene fulltext index (index span multiple properties). com.orientechnologies:orientdb-lucene:2.2.33 dependency must be installed to use lucene index. @CompositeLuceneIndex ( name = \"test\" , fields = [ \"foo\" , \"bar\" ], analyzer = EnglishAnalyzer ) public class MyModel {...} For multiple indexes creation use wrapper: @CompositeIndex.List ({ @CompositeLuceneIndex ( name = \"test\" , fields = [ \"foo\" , \"bar\" ]) @CompositeLuceneIndex ( name = \"test2\" , fields = [ \"foo\" , \"bar\" ], analyzer = EnglishAnalyzer ) }) public class MyModel {...} Note Index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index created with different analyzer - it will be recreated with required analyzer. If existing index build with different fields or it's not lucene index, error will be thrown.","title":"@CompositeLuceneIndex"},{"location":"mapping/class/compositeluceneindex/#compositeluceneindex","text":"Scope: class Creates composite lucene fulltext index (index span multiple properties). com.orientechnologies:orientdb-lucene:2.2.33 dependency must be installed to use lucene index. @CompositeLuceneIndex ( name = \"test\" , fields = [ \"foo\" , \"bar\" ], analyzer = EnglishAnalyzer ) public class MyModel {...} For multiple indexes creation use wrapper: @CompositeIndex.List ({ @CompositeLuceneIndex ( name = \"test\" , fields = [ \"foo\" , \"bar\" ]) @CompositeLuceneIndex ( name = \"test2\" , fields = [ \"foo\" , \"bar\" ], analyzer = EnglishAnalyzer ) }) public class MyModel {...} Note Index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index created with different analyzer - it will be recreated with required analyzer. If existing index build with different fields or it's not lucene index, error will be thrown.","title":"@CompositeLuceneIndex"},{"location":"mapping/class/dropindexes/","text":"@DropIndexes \u00b6 Scope: class Drops existing indexes . @DropIndexes ({ \"test1\" , \"test2\" }) public class MyModel {...} Important Index drop executed before registration and index creation annotations register indexes after class registration, so drop may be used to re-build index.","title":"@DropIndexes"},{"location":"mapping/class/dropindexes/#dropindexes","text":"Scope: class Drops existing indexes . @DropIndexes ({ \"test1\" , \"test2\" }) public class MyModel {...} Important Index drop executed before registration and index creation annotations register indexes after class registration, so drop may be used to re-build index.","title":"@DropIndexes"},{"location":"mapping/class/edge/","text":"@EdgeType \u00b6 Scope: class Register class as edge type . On scheme level it means root class must extend E So in simple case YourModel extends E , in hierarchy case YourModel extends YourBaseModel extends E Defined on model type: @EdgeType public class MyModel {...} If class already registered and its root type does not have assigned superclass, it would be changed to edge type, otherwise error thrown. Note Since orient 2.1 multiple inheritance is available and annotation will assign superclass directly for current class . If any class in hierarchy already extends E then nothing will be done. If any class in hierarchy extends V exception will be thrown (class can't be edge and vertex at the same time)","title":"@EdgeType"},{"location":"mapping/class/edge/#edgetype","text":"Scope: class Register class as edge type . On scheme level it means root class must extend E So in simple case YourModel extends E , in hierarchy case YourModel extends YourBaseModel extends E Defined on model type: @EdgeType public class MyModel {...} If class already registered and its root type does not have assigned superclass, it would be changed to edge type, otherwise error thrown. Note Since orient 2.1 multiple inheritance is available and annotation will assign superclass directly for current class . If any class in hierarchy already extends E then nothing will be done. If any class in hierarchy extends V exception will be thrown (class can't be edge and vertex at the same time)","title":"@EdgeType"},{"location":"mapping/class/recreate/","text":"@Recreate \u00b6 Scope: class Drop annotated class scheme definition before class registration (ofc, data also dropped). @Recreate public class MyCoolModel {...} May be used for one-time run in development environment to cleanup model scheme.","title":"@Recreate"},{"location":"mapping/class/recreate/#recreate","text":"Scope: class Drop annotated class scheme definition before class registration (ofc, data also dropped). @Recreate public class MyCoolModel {...} May be used for one-time run in development environment to cleanup model scheme.","title":"@Recreate"},{"location":"mapping/class/rename/","text":"@RenameFrom \u00b6 Scope: class Renames existing scheme class before class registration. This is important when you rename class to preserve all data under new class name. Note Orient ignores package, so changing model package doesn't need rename. Suppose your class was named MyModel and you rename it to MyCoolModel . To properly migrate data: @RenameFrom ( \"MyModel\" ) public class MyCoolModel {...} If MyModel doesn't exist in scheme, no action will be performed. If both classes exist in scheme, error will be thrown.","title":"@RenameFrom"},{"location":"mapping/class/rename/#renamefrom","text":"Scope: class Renames existing scheme class before class registration. This is important when you rename class to preserve all data under new class name. Note Orient ignores package, so changing model package doesn't need rename. Suppose your class was named MyModel and you rename it to MyCoolModel . To properly migrate data: @RenameFrom ( \"MyModel\" ) public class MyCoolModel {...} If MyModel doesn't exist in scheme, no action will be performed. If both classes exist in scheme, error will be thrown.","title":"@RenameFrom"},{"location":"mapping/class/vertex/","text":"@VertexType \u00b6 Scope: class Register class as vertex type . On scheme level it means root class must extend V So in simple case YourModel extends V , in hierarchy case YourModel extends YourBaseModel extends V Defined on model type: @VertexType public class MyModel {...} If class already registered and its root type does not have assigned superclass, it would be changed to vertex type, otherwise error thrown. Note since orient 2.1 multiple inheritance is available and annotation will assign superclass directly for current class . If any class in hierarchy already extends V then nothing will be done. If any class in hierarchy extends E exception will be thrown (class can't be edge and vertex at the same time)","title":"@VertexType"},{"location":"mapping/class/vertex/#vertextype","text":"Scope: class Register class as vertex type . On scheme level it means root class must extend V So in simple case YourModel extends V , in hierarchy case YourModel extends YourBaseModel extends V Defined on model type: @VertexType public class MyModel {...} If class already registered and its root type does not have assigned superclass, it would be changed to vertex type, otherwise error thrown. Note since orient 2.1 multiple inheritance is available and annotation will assign superclass directly for current class . If any class in hierarchy already extends V then nothing will be done. If any class in hierarchy extends E exception will be thrown (class can't be edge and vertex at the same time)","title":"@VertexType"},{"location":"mapping/property/","text":"@Index \u00b6 Scope: property Creates index for annotated field. public class MyModel { @Index ( OClass . INDEX_TYPE . NOTUNIQUE ) private String foo ; } If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" For multiple indexes creation use wrapper: public class MyModel { @Index.List ({ @Index ( value = OClass . INDEX_TYPE . NOTUNIQUE , name = \"test1\" ), @Index ( value = OClass . INDEX_TYPE . FULLTEXT , name = \"test2\" ) }) private String bar ; } In this case name is required (only one index may use default name). Note that index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index type is different - it will be recreated with required type. If existing index build with different fields, error will be thrown. Use @CaseInsensitive on properties to make index case-insensitive.","title":"@Index"},{"location":"mapping/property/#index","text":"Scope: property Creates index for annotated field. public class MyModel { @Index ( OClass . INDEX_TYPE . NOTUNIQUE ) private String foo ; } If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" For multiple indexes creation use wrapper: public class MyModel { @Index.List ({ @Index ( value = OClass . INDEX_TYPE . NOTUNIQUE , name = \"test1\" ), @Index ( value = OClass . INDEX_TYPE . FULLTEXT , name = \"test2\" ) }) private String bar ; } In this case name is required (only one index may use default name). Note that index names are global in orient, so define unique names. If index with specified name is registered, and index type is the same nothing will be done. If existing index type is different - it will be recreated with required type. If existing index build with different fields, error will be thrown. Use @CaseInsensitive on properties to make index case-insensitive.","title":"@Index"},{"location":"mapping/property/caseinsensitive/","text":"@CaseInsensitive \u00b6 Scope: property Marks property as case insensitive. Case insensitive properties ( collate ci ) are matched in case insensitive way: select from MyModel where name = 'Test' If property name is case insensitive then record with name test (for example) will be matched. public class MyModel { @CaseInsensitive private String foo ; } May be used to unset ci marker: public class MyModel { @CaseInsensitive ( false ) private String foo ; } Marking property ci also affects indexes, created on this property - they are also become ci. In orient ci marker for index and property are different, but if property is ci - index become ci and if index marked as ci then quite possible it will be used when you query by this property - so it may seem that property is ci too. Always marking property as ci (with annotation) removes confusion and grants more consistent behaviour. So when you need case-insensitive index use both annotations: public class MyModel { @CaseInsensitive @Index (...) private String foo ; }","title":"@CaseInsensitive"},{"location":"mapping/property/caseinsensitive/#caseinsensitive","text":"Scope: property Marks property as case insensitive. Case insensitive properties ( collate ci ) are matched in case insensitive way: select from MyModel where name = 'Test' If property name is case insensitive then record with name test (for example) will be matched. public class MyModel { @CaseInsensitive private String foo ; } May be used to unset ci marker: public class MyModel { @CaseInsensitive ( false ) private String foo ; } Marking property ci also affects indexes, created on this property - they are also become ci. In orient ci marker for index and property are different, but if property is ci - index become ci and if index marked as ci then quite possible it will be used when you query by this property - so it may seem that property is ci too. Always marking property as ci (with annotation) removes confusion and grants more consistent behaviour. So when you need case-insensitive index use both annotations: public class MyModel { @CaseInsensitive @Index (...) private String foo ; }","title":"@CaseInsensitive"},{"location":"mapping/property/fulltextindex/","text":"@FulltextIndex \u00b6 Scope: property Creates fulltext index for annotated field. public class MyModel { @FulltextIndex ( indexRadix = false , ignoreChars = \"'\" , separatorChars = \"!?\" , minWordLength = 5 , stopWords = [ \"of\" , \"the\" ]) private String foo ; } Note Fulltext index may be created with @Index annotation too, but this one allows to override default parameters. When no annotation parameters specified - default values will be used (default in annotation are the same as orient defaults). If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" If index with specified name is registered, and index type and parameters are the same then nothing will be done. If existing index type is different or parameters are different - it will be recreated with required type or parameters. If existing index build with different fields or type different from FULLTEXT or FULLTEXT_HASH_INDEX, error will be thrown.","title":"@FulltextIndex"},{"location":"mapping/property/fulltextindex/#fulltextindex","text":"Scope: property Creates fulltext index for annotated field. public class MyModel { @FulltextIndex ( indexRadix = false , ignoreChars = \"'\" , separatorChars = \"!?\" , minWordLength = 5 , stopWords = [ \"of\" , \"the\" ]) private String foo ; } Note Fulltext index may be created with @Index annotation too, but this one allows to override default parameters. When no annotation parameters specified - default values will be used (default in annotation are the same as orient defaults). If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" If index with specified name is registered, and index type and parameters are the same then nothing will be done. If existing index type is different or parameters are different - it will be recreated with required type or parameters. If existing index build with different fields or type different from FULLTEXT or FULLTEXT_HASH_INDEX, error will be thrown.","title":"@FulltextIndex"},{"location":"mapping/property/luceneindex/","text":"@LuceneIndex \u00b6 Scope: property Creates lucene fulltext index for annotated field. com.orientechnologies:orientdb-lucene:2.2.33 dependency must be installed to use lucene index. public class MyModel { @LuceneIndex ( EnglishAnalyzer ) private String foo ; } When analyzer is not specified default StandardAnalyzer will be used If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" If index with specified name is registered, and index type is the same then nothing will be done. If existing index type is lucene with different analyzer - it will be recreated with required analyzer. If existing index build with different fields or its not lucene index then error will be thrown.","title":"@LuceneIndex"},{"location":"mapping/property/luceneindex/#luceneindex","text":"Scope: property Creates lucene fulltext index for annotated field. com.orientechnologies:orientdb-lucene:2.2.33 dependency must be installed to use lucene index. public class MyModel { @LuceneIndex ( EnglishAnalyzer ) private String foo ; } When analyzer is not specified default StandardAnalyzer will be used If index name not defined it will be created by convention: . . For example above it will be \"MyModel.foo\" If index with specified name is registered, and index type is the same then nothing will be done. If existing index type is lucene with different analyzer - it will be recreated with required analyzer. If existing index build with different fields or its not lucene index then error will be thrown.","title":"@LuceneIndex"},{"location":"mapping/property/mandatory/","text":"@Mandatory \u00b6 Scope: property Marks property as mandatory (orient scheme marker) public class MyModel { @Mandatory private String foo ; } May be used to unset mandatory marker: public class MyModel { @Mandatory ( false ) private String foo ; }","title":"@Mandatory"},{"location":"mapping/property/mandatory/#mandatory","text":"Scope: property Marks property as mandatory (orient scheme marker) public class MyModel { @Mandatory private String foo ; } May be used to unset mandatory marker: public class MyModel { @Mandatory ( false ) private String foo ; }","title":"@Mandatory"},{"location":"mapping/property/notnull/","text":"@ONotNull \u00b6 Scope: property Marks property as not null (orient scheme marker) public class MyModel { @ONotNull private String foo ; } May be used to unset not null marker: public class MyModel { @ONotNull ( false ) private String foo ; } Annotation prefixed to avoid conflicts with javax.validation.NotNull .","title":"@ONotNull"},{"location":"mapping/property/notnull/#onotnull","text":"Scope: property Marks property as not null (orient scheme marker) public class MyModel { @ONotNull private String foo ; } May be used to unset not null marker: public class MyModel { @ONotNull ( false ) private String foo ; } Annotation prefixed to avoid conflicts with javax.validation.NotNull .","title":"@ONotNull"},{"location":"mapping/property/readonly/","text":"@Readonly \u00b6 Scope: property Marks property as readonly (orient scheme marker) public class MyModel { @Readonly private String foo ; } May be used to unset readonly marker: public class MyModel { @Readonly ( false ) private String foo ; }","title":"@Readonly"},{"location":"mapping/property/readonly/#readonly","text":"Scope: property Marks property as readonly (orient scheme marker) public class MyModel { @Readonly private String foo ; } May be used to unset readonly marker: public class MyModel { @Readonly ( false ) private String foo ; }","title":"@Readonly"},{"location":"mapping/property/renameproperty/","text":"@RenamePropertyFrom \u00b6 Scope: property Renames existing scheme property before class registration. If you rename property, orient scheme mapper simply creates new property, so if you have data in db it will not be visible for new property. public class MyModel { @RenamePropertyFrom ( \"foo\" ) private String bar ; } If specified old property does not exist, no action will be performed. If both properties exist error will be thrown.","title":"@RenameFromProperty"},{"location":"mapping/property/renameproperty/#renamepropertyfrom","text":"Scope: property Renames existing scheme property before class registration. If you rename property, orient scheme mapper simply creates new property, so if you have data in db it will not be visible for new property. public class MyModel { @RenamePropertyFrom ( \"foo\" ) private String bar ; } If specified old property does not exist, no action will be performed. If both properties exist error will be thrown.","title":"@RenamePropertyFrom"},{"location":"repository/commandinternals/","text":"Command methods implementation details \u00b6 Command method extensions applied to all command extensions ( @Query , @Function , @Script etc.) Tip Read repository internals first for better understanding Common command features \u00b6 Commands generally support: Positional parameters Named parameters Command string el variables Most commands use CommandMethodDescriptor as descriptor, except @Script which use ScriptCommandMethodDescriptor (to store script language). So when you target CommandMethodDescriptor (in generic), extension will be compatible with all command methods. All command extensions use AbstractCommandExtension as base class. It's very easy to add your own custom command annotation using it (look bundled extensions sources). Command extensions have three execution phases: SqlCommandDescriptor composition OCommandRequest composition (orient command) And command execution Amend extension shoudl implement CommandExtension insterface (to affect execution). SqlCommandDescriptor phase \u00b6 SqlCommandDescriptor contains query, prepared parameters (composed from method arguments) and el variables (also composed fro arguments). Extensions could modify query (for example, @Skip appends \"SKIP\" part to query string. Extensions could add (or modify) query parameters. And extensions could add/modify el variables. Positional parameters is a core feature (its parameters without any extension), anyway they could be modified too (for example, @DynamicParams modifies them). Named parameters covered with bundled extension @Param . It is not mandatory to use it: you can write your own extension to define named parameters. El variables defined with @ElVar extension, but again, its not mandatory - you can use your own extension to define variables. OCommandRequest phase \u00b6 First of all, el variables replaced in query, producing target query string. Then command object created using prepared query. Extensions could modify resulted command object (for example, @Timaout , @Listen ). After all command object wrapped with connection object (using selected RepositoryExecutor) and executed, using composed parameters. Command wrapping is required to bind command to specific connection type. This will affect resulting objects. Extensions lifecycle \u00b6 Create SqlCommandDescriptor Run extensions to amend descriptor Apply el vars and create OCommandRequest Run extensions to amend request object Wrap command with connection and execute with prepared parameters Command parameters context \u00b6 Command extensions use CommandParamsContext during parameters processing. Parameter extensions are called after all parameters processing (to collect all parameters, marked with the same annotation) If you need to modify positional parameters, you can obtain them through paramsContext.getOrdinals() . Usually, there is no need to modify them, because if you need special parameter handling you'll define custom annotation. If your extension defines named parameter you may register it in context: paramsContext.addNamedParam() . After registration, it will be applied automatically. You may omit registration if your parameter must be converted or something like this (in this case you'll use amend extension to manually apply parameter value). If your extension handles el variable you must declare it either as static paramsContext.addStaticElVarValue() if value is the same for all method executions, or declare it as dynamic paramsContext.addDynamicElVarValue() . In case of dynamic el var, you'll need to use amend extension to manually apply value during execution. Registration of el variables is required, because they are strictly checked and if some not declared variable found in query or declared variable not used in query error will be thrown to indicate method definition error. If you need access to method, type, know root repository type or use generics info, use paramsContext.getDescriptorContext() . Note that if parameter type is generified, you will receive resolved generic in extension. Implementing command parameter extension \u00b6 Suppose you want to implement @MyCustomParam parameter extension. Declaring annotation: @Target ( PARAMETER ) @Retention ( RUNTIME ) @MethodParam ( MyCustomParamExtension . class ) public @interface MyCustomParam { ... } If required, define extension options as annotation attributes. @MethodParam marks extension as parameter extension and it will be found and MyCustomParamExtension class obtained from guice context and executed. Now implement extension: @Singleton public class MyCustomParamExtension implements MethodParamExtension < CommandMethodDescriptor , CommandParamsContext , MyCustomParam >{ @Override public void processParameters ( final CommandMethodDescriptor descriptor , final CommandParamsContext context , final List < ParamInfo < MyCustomParam >> paramsInfo ) { ... } } This extension will be called once, during descriptor creation. Here you can validate parameters and, for example, register named parameter or el variable in paramsContext Note We declare MethodParamExtension<CommandMethodDescriptor ...> , this means extension is compatible only with command descriptor and can't be used with delegate (or some other) method extensions. Also, because @Script 's ScriptCommandMethodDescriptor extends CommandMethodDescriptor, this extension is compatible with scripts too. If you need some execution time modification, you'll need to implement amend extension interface: @Singleton public class MyCustomParamExtension implements MethodParamExtension < CommandMethodDescriptor , CommandParamsContext , MyCustomParam >, CommandExtension < CommandMethodDescriptor > { public static final String KEY = MyCustomParamExtension . class . getName (); ... @Override public void amendCommandDescriptor ( final SqlCommandDescriptor sql , final CommandMethodDescriptor descriptor , final Object instance , final Object ... arguments ) { ... } @Override public void amendCommand ( final OCommandRequest query , final CommandMethodDescriptor descriptor , final Object instance , final Object ... arguments ) { ... } By implementing CommandExtension we did our extension compatible with command methods amend extension. Now parameter extension will be registered as amend extension afeter parameters processing. Most likely you'll need some information from parameters processing method inside executino methods. If it's not a simple value (int, string etc), define your value object MyCustomParamDescriptor . Compose descriptor on processing phase and store inside main method descriptor: descriptor . extDescriptors . put ( KEY , yourCustomDescriptor ); Now in execution method you can obtain it and use: MyCustomParamDescriptor desc = ( MyCustomParamDescriptor ) descriptor . extDescriptors . get ( KEY ); Note KEY is public. This will allow you to use it in unit tests and possibly, other extensions also could use it (for example, @AsyncQuery must know about @Listen extension). That's all, extension could be used in command method: @Query ( \"select from Model\" ) List select ( @MyCustomParam String param ); Look bundled extensions sources for advanced examples. Implementing command method amend extension \u00b6 First of all, you can register custom amend extension globally: @Inject AmendExtensionsService amendExtensions ; ... amendExtensions . addGlobalExtension ( new CommandExtension () {...}); Or you can use custom annotation, for example: @Target ({ METHOD , TYPE }) @Retention ( RUNTIME ) @AmendMethod ( MyCustomAmendExtension . class ) public @interface MyCustomAmend { ... } Amend extensions are searched on method, on type and on root repository type. You can limit usage scope with @Target annotation (e.g. allow usage only on methods). @AmendMethod marks annotation as amend annotation, now it will be resolved. As with parameters, you eaither implement just parsing interface, to apply extension in descriptor creation time, or implement also amend extension interface, to use extension during method call. @Singleton public class MyCustomAmendExtension implements AmendMethodExtension < CommandMethodDescriptor , MyCustomAmend >, CommandExtension < CommandMethodDescriptor > { @Override public void handleAnnotation ( final CommandMethodDescriptor descriptor , final MyCustomAmend annotation ) { ... } ... } Implementation guideline is the same as with params: use public KEY field and custom descriptor object. Extension could be used like this: @Query ( \"select from Model\" ) @MyCustomAmend List select (); See @Timeout as implementation example.","title":"Command implementation"},{"location":"repository/commandinternals/#command-methods-implementation-details","text":"Command method extensions applied to all command extensions ( @Query , @Function , @Script etc.) Tip Read repository internals first for better understanding","title":"Command methods implementation details"},{"location":"repository/commandinternals/#common-command-features","text":"Commands generally support: Positional parameters Named parameters Command string el variables Most commands use CommandMethodDescriptor as descriptor, except @Script which use ScriptCommandMethodDescriptor (to store script language). So when you target CommandMethodDescriptor (in generic), extension will be compatible with all command methods. All command extensions use AbstractCommandExtension as base class. It's very easy to add your own custom command annotation using it (look bundled extensions sources). Command extensions have three execution phases: SqlCommandDescriptor composition OCommandRequest composition (orient command) And command execution Amend extension shoudl implement CommandExtension insterface (to affect execution).","title":"Common command features"},{"location":"repository/commandinternals/#sqlcommanddescriptor-phase","text":"SqlCommandDescriptor contains query, prepared parameters (composed from method arguments) and el variables (also composed fro arguments). Extensions could modify query (for example, @Skip appends \"SKIP\" part to query string. Extensions could add (or modify) query parameters. And extensions could add/modify el variables. Positional parameters is a core feature (its parameters without any extension), anyway they could be modified too (for example, @DynamicParams modifies them). Named parameters covered with bundled extension @Param . It is not mandatory to use it: you can write your own extension to define named parameters. El variables defined with @ElVar extension, but again, its not mandatory - you can use your own extension to define variables.","title":"SqlCommandDescriptor phase"},{"location":"repository/commandinternals/#ocommandrequest-phase","text":"First of all, el variables replaced in query, producing target query string. Then command object created using prepared query. Extensions could modify resulted command object (for example, @Timaout , @Listen ). After all command object wrapped with connection object (using selected RepositoryExecutor) and executed, using composed parameters. Command wrapping is required to bind command to specific connection type. This will affect resulting objects.","title":"OCommandRequest phase"},{"location":"repository/commandinternals/#extensions-lifecycle","text":"Create SqlCommandDescriptor Run extensions to amend descriptor Apply el vars and create OCommandRequest Run extensions to amend request object Wrap command with connection and execute with prepared parameters","title":"Extensions lifecycle"},{"location":"repository/commandinternals/#command-parameters-context","text":"Command extensions use CommandParamsContext during parameters processing. Parameter extensions are called after all parameters processing (to collect all parameters, marked with the same annotation) If you need to modify positional parameters, you can obtain them through paramsContext.getOrdinals() . Usually, there is no need to modify them, because if you need special parameter handling you'll define custom annotation. If your extension defines named parameter you may register it in context: paramsContext.addNamedParam() . After registration, it will be applied automatically. You may omit registration if your parameter must be converted or something like this (in this case you'll use amend extension to manually apply parameter value). If your extension handles el variable you must declare it either as static paramsContext.addStaticElVarValue() if value is the same for all method executions, or declare it as dynamic paramsContext.addDynamicElVarValue() . In case of dynamic el var, you'll need to use amend extension to manually apply value during execution. Registration of el variables is required, because they are strictly checked and if some not declared variable found in query or declared variable not used in query error will be thrown to indicate method definition error. If you need access to method, type, know root repository type or use generics info, use paramsContext.getDescriptorContext() . Note that if parameter type is generified, you will receive resolved generic in extension.","title":"Command parameters context"},{"location":"repository/commandinternals/#implementing-command-parameter-extension","text":"Suppose you want to implement @MyCustomParam parameter extension. Declaring annotation: @Target ( PARAMETER ) @Retention ( RUNTIME ) @MethodParam ( MyCustomParamExtension . class ) public @interface MyCustomParam { ... } If required, define extension options as annotation attributes. @MethodParam marks extension as parameter extension and it will be found and MyCustomParamExtension class obtained from guice context and executed. Now implement extension: @Singleton public class MyCustomParamExtension implements MethodParamExtension < CommandMethodDescriptor , CommandParamsContext , MyCustomParam >{ @Override public void processParameters ( final CommandMethodDescriptor descriptor , final CommandParamsContext context , final List < ParamInfo < MyCustomParam >> paramsInfo ) { ... } } This extension will be called once, during descriptor creation. Here you can validate parameters and, for example, register named parameter or el variable in paramsContext Note We declare MethodParamExtension<CommandMethodDescriptor ...> , this means extension is compatible only with command descriptor and can't be used with delegate (or some other) method extensions. Also, because @Script 's ScriptCommandMethodDescriptor extends CommandMethodDescriptor, this extension is compatible with scripts too. If you need some execution time modification, you'll need to implement amend extension interface: @Singleton public class MyCustomParamExtension implements MethodParamExtension < CommandMethodDescriptor , CommandParamsContext , MyCustomParam >, CommandExtension < CommandMethodDescriptor > { public static final String KEY = MyCustomParamExtension . class . getName (); ... @Override public void amendCommandDescriptor ( final SqlCommandDescriptor sql , final CommandMethodDescriptor descriptor , final Object instance , final Object ... arguments ) { ... } @Override public void amendCommand ( final OCommandRequest query , final CommandMethodDescriptor descriptor , final Object instance , final Object ... arguments ) { ... } By implementing CommandExtension we did our extension compatible with command methods amend extension. Now parameter extension will be registered as amend extension afeter parameters processing. Most likely you'll need some information from parameters processing method inside executino methods. If it's not a simple value (int, string etc), define your value object MyCustomParamDescriptor . Compose descriptor on processing phase and store inside main method descriptor: descriptor . extDescriptors . put ( KEY , yourCustomDescriptor ); Now in execution method you can obtain it and use: MyCustomParamDescriptor desc = ( MyCustomParamDescriptor ) descriptor . extDescriptors . get ( KEY ); Note KEY is public. This will allow you to use it in unit tests and possibly, other extensions also could use it (for example, @AsyncQuery must know about @Listen extension). That's all, extension could be used in command method: @Query ( \"select from Model\" ) List select ( @MyCustomParam String param ); Look bundled extensions sources for advanced examples.","title":"Implementing command parameter extension"},{"location":"repository/commandinternals/#implementing-command-method-amend-extension","text":"First of all, you can register custom amend extension globally: @Inject AmendExtensionsService amendExtensions ; ... amendExtensions . addGlobalExtension ( new CommandExtension () {...}); Or you can use custom annotation, for example: @Target ({ METHOD , TYPE }) @Retention ( RUNTIME ) @AmendMethod ( MyCustomAmendExtension . class ) public @interface MyCustomAmend { ... } Amend extensions are searched on method, on type and on root repository type. You can limit usage scope with @Target annotation (e.g. allow usage only on methods). @AmendMethod marks annotation as amend annotation, now it will be resolved. As with parameters, you eaither implement just parsing interface, to apply extension in descriptor creation time, or implement also amend extension interface, to use extension during method call. @Singleton public class MyCustomAmendExtension implements AmendMethodExtension < CommandMethodDescriptor , MyCustomAmend >, CommandExtension < CommandMethodDescriptor > { @Override public void handleAnnotation ( final CommandMethodDescriptor descriptor , final MyCustomAmend annotation ) { ... } ... } Implementation guideline is the same as with params: use public KEY field and custom descriptor object. Extension could be used like this: @Query ( \"select from Model\" ) @MyCustomAmend List select (); See @Timeout as implementation example.","title":"Implementing command method amend extension"},{"location":"repository/commandmethods/","text":"Command methods \u00b6 The following methods are using orient commands for execution and called command methods. @Query - select/update/insert query @Function - function call @Script - script call (sql, js etc) @AsyncQuery - async query call @LiveQuery - live query subscription Common command options \u00b6 All command methods annotations has two options: returnAs - defines required collection implementation connection - defines required connection Most of the time they are not needed. ReturnAs example: @Query ( value = \"select from Model\" , returnAs = TreeSet . class ) Set < Model > select () Method will return TreeSet as result (for example, we want sorted results). Connection example: @Query ( value = \"select from Model\" , connection = DbType . OBJECT ) List select () Result is not generified, so without hint document connection would be selected for method and result will be List<ODocument> . With connection hint actual result will be List<Model> . Another case, when it might be useful is custom converter. For example, you want to convert results to some DTO object, but your converter converts model objects. If you will not use hint: @Query ( \"select from Model\" ) @ModelDTOConverter List < ModelDTO > select () This will not work, because document connection will be selected and converter expects objects. When we set connection hint ( connection = DbType.OBJECT ), everything will work as planned. Note @ModelDTOConverter does not exist, it's just hypothetical result converter extension you could write, using extension api. Parameters \u00b6 Commands support positional and named parameters: @Query ( \"select from Model where name = ?\" ) List < Model > positional ( String name ) @Query ( \"select from Model where name = :name\" ) List < Model > named ( @Param ( \"name\" ) String name ) Positional may be used as named too: @Query ( \"select from Model where name = :0\" ) List < Model > positional ( String name ) For example, script will not work with '?' positional but works which ':0' named-positional. El variables \u00b6 All commands support el variables. For example: @Query ( \"select from ${type}\" ) List selectAll ( @ElVar ( \"type\" ) String type ); Such variables are inserted into query string before actual execution. In theory may be used even to provide sql parts, but be careful with it. By default you can use generics as el variables: select from ${T} where T is generic of query method declaring class (read more about hierarchies below). Another example is oauth providers connection: suppose you have multiple auth providers and user object has property for each provider id. To avoid writing multiple queries for searching user by provider id, we can do like this: @Query ( \"select from User where ${provider} = ?\" ) Optional < User > findByProvider ( @ElVar ( \"provider\" ) AuthProvider provider , String providerId ); Where AuthProvider is enum: public enum AuthProvider { google , facebook , twitter } Command methods parameter annotations \u00b6 @Param - named parameter @ElVar - query variable value (substituted in string before query execution) @RidElVar - extract rid from provided object, document, vertex, string orid and insert into query @Var - orient command variable ($var), may be used by query during execution @Skip and @Limit - orient pagination @FetchPlan - defines fetch plan for query @Listen - to provide query listener (required for async queries) @DynamicParams - map dynamic count of parameters from array/collection/map Command amend annotations \u00b6 @Timeout - defines query timeout and timeout strategy Amend annotations may be used directly on method, on class (to apply for all methods) or on root repository type (to apply to all inherited mixins). Command amend methods doesn't affect delegate methods (only if you define command amend annotation directly on delegate method it will cause error, because obviously it's impropriate usage) Writing extensions \u00b6 You can write custom extensions","title":"Command methods"},{"location":"repository/commandmethods/#command-methods","text":"The following methods are using orient commands for execution and called command methods. @Query - select/update/insert query @Function - function call @Script - script call (sql, js etc) @AsyncQuery - async query call @LiveQuery - live query subscription","title":"Command methods"},{"location":"repository/commandmethods/#common-command-options","text":"All command methods annotations has two options: returnAs - defines required collection implementation connection - defines required connection Most of the time they are not needed. ReturnAs example: @Query ( value = \"select from Model\" , returnAs = TreeSet . class ) Set < Model > select () Method will return TreeSet as result (for example, we want sorted results). Connection example: @Query ( value = \"select from Model\" , connection = DbType . OBJECT ) List select () Result is not generified, so without hint document connection would be selected for method and result will be List<ODocument> . With connection hint actual result will be List<Model> . Another case, when it might be useful is custom converter. For example, you want to convert results to some DTO object, but your converter converts model objects. If you will not use hint: @Query ( \"select from Model\" ) @ModelDTOConverter List < ModelDTO > select () This will not work, because document connection will be selected and converter expects objects. When we set connection hint ( connection = DbType.OBJECT ), everything will work as planned. Note @ModelDTOConverter does not exist, it's just hypothetical result converter extension you could write, using extension api.","title":"Common command options"},{"location":"repository/commandmethods/#parameters","text":"Commands support positional and named parameters: @Query ( \"select from Model where name = ?\" ) List < Model > positional ( String name ) @Query ( \"select from Model where name = :name\" ) List < Model > named ( @Param ( \"name\" ) String name ) Positional may be used as named too: @Query ( \"select from Model where name = :0\" ) List < Model > positional ( String name ) For example, script will not work with '?' positional but works which ':0' named-positional.","title":"Parameters"},{"location":"repository/commandmethods/#el-variables","text":"All commands support el variables. For example: @Query ( \"select from ${type}\" ) List selectAll ( @ElVar ( \"type\" ) String type ); Such variables are inserted into query string before actual execution. In theory may be used even to provide sql parts, but be careful with it. By default you can use generics as el variables: select from ${T} where T is generic of query method declaring class (read more about hierarchies below). Another example is oauth providers connection: suppose you have multiple auth providers and user object has property for each provider id. To avoid writing multiple queries for searching user by provider id, we can do like this: @Query ( \"select from User where ${provider} = ?\" ) Optional < User > findByProvider ( @ElVar ( \"provider\" ) AuthProvider provider , String providerId ); Where AuthProvider is enum: public enum AuthProvider { google , facebook , twitter }","title":"El variables"},{"location":"repository/commandmethods/#command-methods-parameter-annotations","text":"@Param - named parameter @ElVar - query variable value (substituted in string before query execution) @RidElVar - extract rid from provided object, document, vertex, string orid and insert into query @Var - orient command variable ($var), may be used by query during execution @Skip and @Limit - orient pagination @FetchPlan - defines fetch plan for query @Listen - to provide query listener (required for async queries) @DynamicParams - map dynamic count of parameters from array/collection/map","title":"Command methods parameter annotations"},{"location":"repository/commandmethods/#command-amend-annotations","text":"@Timeout - defines query timeout and timeout strategy Amend annotations may be used directly on method, on class (to apply for all methods) or on root repository type (to apply to all inherited mixins). Command amend methods doesn't affect delegate methods (only if you define command amend annotation directly on delegate method it will cause error, because obviously it's impropriate usage)","title":"Command amend annotations"},{"location":"repository/commandmethods/#writing-extensions","text":"You can write custom extensions","title":"Writing extensions"},{"location":"repository/delegateinternals/","text":"Delegate method implementation \u00b6 @Delegate method delegates execution to external guice bean method. It's processing is a bit different from command methods: when target method found, parameter extensions processed on target method parameters! Amend extensions are searched on repository method, type and root repository type. Delegate methods use DelegateMethodDescriptor . Delegate execution is: Prepare arguments array Process extension to fill/modify arguments Call target method Delegate amend extension interface DelegateExtension allows you to just modify composing arguments array. Parameters context DelegateParamsContext is also simple: supports only ordinal parameters. But important moment is context: paramsContext.getDescriptorContext() return target method context. It's logical, because param extensions works on target method and so require its context. Repository method context is also accessible with paramsContext.getCallerContext() . Implementing delegate parameter extension \u00b6 Note Assuming you already read command methods extension guide , some details omitted. @Target ( PARAMETER ) @Retention ( RUNTIME ) @MethodParam ( CustomParamExtension . class ) public @interface CustomParam { ... } @Singleton public class ConnectionParamExtension implements MethodParamExtension < DelegateMethodDescriptor , DelegateParamsContext , CustomParam >, DelegateExtension < DelegateMethodDescriptor > { @Override public void processParameters ( final DelegateMethodDescriptor descriptor , final DelegateParamsContext context , final List < ParamInfo < CustomParam >> paramsInfo ) { ... } @Override public void amendParameters ( final DelegateMethodDescriptor descriptor , final Object [] targetArgs , final Object instance , final Object ... arguments ) { ... } Note DelegateMethodDescriptor used in generic, which limit extension usage for delegates only. Usually, delegate param extension without amend extension interface makes no sense, because values for extended parameters will not be populated by default (these parameters extends repository method signature, so its simply impossible to populate its values automatically). As with command extensions, use KEY field and custom descriptor to pass values between parsing and execution phases. ParamInfo contains target method parameter position, which you will use to set computed value to arguments array for target method. Implementing delegate amend extensions \u00b6 As with command, amend extension may be registered globally or defined as annotation on repository method. All steps are the same as with command, so will omit description. Delegate amend extension could just modify arguments, and I dont know any good usage example for this (that's why no bundled amend annotations provided for delegates: usually, param extensions are more than enough).","title":"Delegate implementation"},{"location":"repository/delegateinternals/#delegate-method-implementation","text":"@Delegate method delegates execution to external guice bean method. It's processing is a bit different from command methods: when target method found, parameter extensions processed on target method parameters! Amend extensions are searched on repository method, type and root repository type. Delegate methods use DelegateMethodDescriptor . Delegate execution is: Prepare arguments array Process extension to fill/modify arguments Call target method Delegate amend extension interface DelegateExtension allows you to just modify composing arguments array. Parameters context DelegateParamsContext is also simple: supports only ordinal parameters. But important moment is context: paramsContext.getDescriptorContext() return target method context. It's logical, because param extensions works on target method and so require its context. Repository method context is also accessible with paramsContext.getCallerContext() .","title":"Delegate method implementation"},{"location":"repository/delegateinternals/#implementing-delegate-parameter-extension","text":"Note Assuming you already read command methods extension guide , some details omitted. @Target ( PARAMETER ) @Retention ( RUNTIME ) @MethodParam ( CustomParamExtension . class ) public @interface CustomParam { ... } @Singleton public class ConnectionParamExtension implements MethodParamExtension < DelegateMethodDescriptor , DelegateParamsContext , CustomParam >, DelegateExtension < DelegateMethodDescriptor > { @Override public void processParameters ( final DelegateMethodDescriptor descriptor , final DelegateParamsContext context , final List < ParamInfo < CustomParam >> paramsInfo ) { ... } @Override public void amendParameters ( final DelegateMethodDescriptor descriptor , final Object [] targetArgs , final Object instance , final Object ... arguments ) { ... } Note DelegateMethodDescriptor used in generic, which limit extension usage for delegates only. Usually, delegate param extension without amend extension interface makes no sense, because values for extended parameters will not be populated by default (these parameters extends repository method signature, so its simply impossible to populate its values automatically). As with command extensions, use KEY field and custom descriptor to pass values between parsing and execution phases. ParamInfo contains target method parameter position, which you will use to set computed value to arguments array for target method.","title":"Implementing delegate parameter extension"},{"location":"repository/delegateinternals/#implementing-delegate-amend-extensions","text":"As with command, amend extension may be registered globally or defined as annotation on repository method. All steps are the same as with command, so will omit description. Delegate amend extension could just modify arguments, and I dont know any good usage example for this (that's why no bundled amend annotations provided for delegates: usually, param extensions are more than enough).","title":"Implementing delegate amend extensions"},{"location":"repository/delegatemethods/","text":"Delegate methods \u00b6 Delegate methods delegate execution to other guice bean method. @Delegate ( TargetBean . class ) List < Model > selectSomething (); On execution, delegating method will be found in TargetBean and executed. This allows writing custom logic using java api, but still use interface repostory method to call it. So repository interface become single point for all your entity's methods, whereas actual implementation could be decomposed by multiple beans. @Delegate may be declared directly on method or on class to apply for all methods. Delegate method implementation may be generic, using some information from calling repository in runtime (generic values, connection object selected for repository method or repository instance itself to use its methods in bean logic). As with other repository methods, delegate bean method execution result will be converted with default (or custom) converter . Delegate annotation support returnAs and connection parameters, the same way as command annotations. Tip When writing mixin, prefer implementing mixin interface in delegate bean. This will make strong reference between them (easier to find). If extension annotations used, and you can't directly implement method, use abstract class (with @ProvidedBy(DynamicSingletonProvider.class)). This way you will keep connection between interface and implementation and be able to use extended method signature. For example, public interface MyMixin { @Delegate ( OtherBean . class ) void something (); } public abstract class OtherBean implements MyMixin { void something ( @Repository Object repo ); } Here delegation target use custom parameters and so can't mark method as @Override , but overall class implmenets mixin interface, declaring explicit connection between them. Method lookup algorithm \u00b6 @Delegate annotation allows you to define target implementation type with value attribute exact target method name with method attribute (this must be used as last resort, because it introduce weak contract and not refactor-friendly) Method is searched through all target bean methods (including inherited methods). Algorithm: If method name set directly (annotation method attribute), look only methods with this name. If method name not set look all public methods. Check all methods for parameter compatibility. Target method must have compatible parameters at the same order(!) Special parameters (extension annotations) may appear at any position (before/after/between). If more than one method found, repository method name used to reduce results (this should be the most useful hint) Method with special parameters (extension annotations) is prioritized. So if few methods found but only one use extensions - it will be chosen. Next, methods are filtered by most specific parameters (e.g. two methods with the same name but one declares String parameter and other Object; first one will be chosen as more specific). If we still have more than one possibility, error will be thrown. Delegate parameter annotations \u00b6 @Generic - generic type value of caller repository (exact class could be specified where to search generic) @Repository - caller repository instance @Connection - db connection object, selected by repository method","title":"Delegate methods"},{"location":"repository/delegatemethods/#delegate-methods","text":"Delegate methods delegate execution to other guice bean method. @Delegate ( TargetBean . class ) List < Model > selectSomething (); On execution, delegating method will be found in TargetBean and executed. This allows writing custom logic using java api, but still use interface repostory method to call it. So repository interface become single point for all your entity's methods, whereas actual implementation could be decomposed by multiple beans. @Delegate may be declared directly on method or on class to apply for all methods. Delegate method implementation may be generic, using some information from calling repository in runtime (generic values, connection object selected for repository method or repository instance itself to use its methods in bean logic). As with other repository methods, delegate bean method execution result will be converted with default (or custom) converter . Delegate annotation support returnAs and connection parameters, the same way as command annotations. Tip When writing mixin, prefer implementing mixin interface in delegate bean. This will make strong reference between them (easier to find). If extension annotations used, and you can't directly implement method, use abstract class (with @ProvidedBy(DynamicSingletonProvider.class)). This way you will keep connection between interface and implementation and be able to use extended method signature. For example, public interface MyMixin { @Delegate ( OtherBean . class ) void something (); } public abstract class OtherBean implements MyMixin { void something ( @Repository Object repo ); } Here delegation target use custom parameters and so can't mark method as @Override , but overall class implmenets mixin interface, declaring explicit connection between them.","title":"Delegate methods"},{"location":"repository/delegatemethods/#method-lookup-algorithm","text":"@Delegate annotation allows you to define target implementation type with value attribute exact target method name with method attribute (this must be used as last resort, because it introduce weak contract and not refactor-friendly) Method is searched through all target bean methods (including inherited methods). Algorithm: If method name set directly (annotation method attribute), look only methods with this name. If method name not set look all public methods. Check all methods for parameter compatibility. Target method must have compatible parameters at the same order(!) Special parameters (extension annotations) may appear at any position (before/after/between). If more than one method found, repository method name used to reduce results (this should be the most useful hint) Method with special parameters (extension annotations) is prioritized. So if few methods found but only one use extensions - it will be chosen. Next, methods are filtered by most specific parameters (e.g. two methods with the same name but one declares String parameter and other Object; first one will be chosen as more specific). If we still have more than one possibility, error will be thrown.","title":"Method lookup algorithm"},{"location":"repository/delegatemethods/#delegate-parameter-annotations","text":"@Generic - generic type value of caller repository (exact class could be specified where to search generic) @Repository - caller repository instance @Connection - db connection object, selected by repository method","title":"Delegate parameter annotations"},{"location":"repository/internals/","text":"Repository internals \u00b6 Repository methods using guice aop and so they could be used in any place. But it's more natural to use them on interface methods. Support for using interfaces and abstract classes in guice is provided by guice-ext-annotations library. Runtime proxies could be also used (and where used initially) but this way guice aop couldn't be used, which is limitation. Class generation overcomes this limitation making abstract types valid guice beans with aop support. Repositories are build using plugin architecture. Each repository annotation is a plugin and can be replaced if requied. How repositories work \u00b6 Repository method executor RepositoryMethodInterceptor is applied using guice aop: to all methods with annotations, annotated with @RepositoryMethod . It is not allowed to use multiple repository method annotations on the same method. If any repository contains such method guice context startup will fail (checked explicitly). During context startup descriptors not computed! This would slow down startup significantly. Descriptor is always computed on first method call. So if context start successfully it doesn't mean all repository methods are valid. On repository method call, MethodDescriptorFactory either return cached method descriptor or: Calls method extension to create descriptor Extension creates descripotor and initialize required fields (possibly set hints in descriptor) Extension calls SpiService.process with ParamsContext instance in order to resolve all extensions Spi service calls ParamsService to process all parameters and param extensions At the end of params processing params service calls ParamsContext.process which analyze all parameters info (and additional information provided by extensions) and creates method specific parameters context and assigns it to method context Next AmendExtensionsService called to resolve all compatible amend extensions. Parameters extensions (holder in ParamsContext) are also checked is they are amend extensions Sorted list of compatible amend extensions (including global) is assigned to descriptor object At the end ResultService called to find converter extensions Result service compose ResultConversionDescriptor and assigns it to method descriptor After descriptor is created by extension Method return type analyzed to compose result descriptor (descriptor.result filed). Affected by returnCollectionHint hint. Using result analysis, executor instance selected and assigned to descriptor (descriptor.executor). Affected by connectionHint. Method extension assigned to descriptor object (as Provider). Execution: Extension obtained from descriptor and called to perform execution Extension executes all amend extension from descriptor Extension use executor from descriptor if required (e.g. command extension use it to execute query and delegate use it to obtain connection instance in @Connection extension) Extension returns raw execution result Result conversion: Default result converter is called (if not disabled by result extension) to convert result Call result conversion extension if defined Finally result returned Repository extensions \u00b6 Repositories support 4 types of extensions: Method extension - defines repository method logic Repository parameter extension - defines special handling logic for method parameters Amend method extension - extension that influence method behaviour (many parameter extensions are amend extensions also) Result converter extension - extension to extend or modify default result conversion logic Method extension \u00b6 Repository method execution consists of three phases: method descriptor creation, execution and result conversion. Descriptor is created on first call and cached. This is required, because this way first call will be slower, but will be able to perform any heavy computations to validate definition and extensions processing and prepare everything for fast execution on future calls. Method descriptor \u00b6 Repository descriptor object must extend RepositoryMethodDescriptor . Each method could have unique descriptor or some methods could share the same descriptor type. For example, @Query , @Function , @AsyncQuery use the same descriptor type SqlCommandDescriptor and @Script use uxtended ScriptCommandMethodDescriptor . @Delegate use completely different descriptor object DelegateMethodDescriptor . There are two hint fields in RepositoryMethodDescriptor : returnCollectionHint and connectionHint. Extension may set them to affect return collection type (handled by result converter) and guide executor selection. Descriptor object will be passed to all extension, so it defines which data will be visible to all method specific extensions. Internally root descriptor has extDescriptors map to let extensions store any extension specific data. Repository method extension \u00b6 Repository method is defined by annotation, annotated with @RepositoryMethod . Annotation contains actual extension class, which implements RepositoryMethodExtension . Extension is resolved from guice context. Prefer using singletons. Note that extension instance is registered as Provider, so if, for example, prototype scope used, new extension instance will be used for each execution (as a drawback different extension instances will be used for descripotr creation and first execution). Generics are very important ! RepositoryMethodExtension must declare used descriptor object in generic (T). Later this will be used to filter other extensions. Descriptor object also must be generified with supporting amend extensions type (see amend extesnions below). Only extension knows how it would be executed and so only it could define extension interface and properly use it. For example, command and delegate methods are completely different and so use different extensions interface. Method annotation is searched on methods and on type. You can limit exact extension scope when defining annotation target. For example, command extensions applies only to method and delegate could be defined on type. Extension must call SpiService.process method to resolve all amend extension, process parameters and extensions and resolve result converter extensions. Parameters context \u00b6 Method extension defines param context object extending ParamsContext . Params context is used by parameter extensions. It's methods define core parameter types. For example, command extensions support positional and named query arguments and also el varables (in query string). Delegate support only target method parameters. Also, params context in responsible for main descriptor update after all parameter extensions processed: it validates all parameters info and updates descriptor for fast processing on execution. Read more about it in parameters extensions section below. Parameter extension \u00b6 Parameter extensions resolved from parameter annotations. Parameter extension annotation must be annotated with @MethodParam . Annotation defines extension class, which must implement MethodParamExtension . Extension instance is obtained from guice context. Prefer using singleton scope. Again generics are important! During resolution parameter extension checked for compatibility using descriptor type generic. If type defined in extension genric is assignable to current descriptor type - extension is compatible. If some method extensions use descriptors hierarchy, extension may define some middle type in generic to be compatible with all methods. For example, @Script extension use special descriptor which extends CommandMethodDescriptor and all parameter extensions which use CommandMethodDescriptor in generic are compatible with @Script (because declared descriptor type is compatible). All parameters are parsed before calling extension. Extension receive all parameters under extension annotation. This is very handy for validation: for example, some extension requires only one annotated parameter ( @Size , @Limit etc). Param extension may use main descriptor's extDescriptors map to store extension specific data, which will be used during execution. Param extension itself is called only on parameters parsing. If extension need to perform some execution time modifications, it must also implement amend extension interface, specific for repository method. In this case parameter extension is registered as amend extension. If parameter extension in universal and could be applied to multiple method types it must not only declare compatible descriptor in generic, but also implement all extension interfaces (if target methods have different extension interfaces). If parameter extension doesn't implement compatible amend extension interface it simply will not be registered in method amend extensions (the same as if param extension did not implement any amend interface at all). Parameter extension is checked for amend extension compatibility using amend extension type defined in main descriptor generic (RepositoryMethodDescriptor, generic E). Implementation guideline: Define public static String filed KEY as extension class full name. Define extension specific descriptor object. During parameters processing, validate (if possible), fill specific descriptor and save it in main descriptor: descriptor.extDescriptors.put(KEY, specificDescriptor). For validation use MethodDefinitionException.chec() static method to check and throw exception. In amend extension method you can obtain descriptor descriptor.extDescriptors.get(KEY) and use it. During execution (in amend extension methods) use MethodExecutionException.checkExec static method to check and throw exception. Only one parameter extension annotation could be defined on single method parameter. Parameters context contains descriptor context object, which may be used to get parsed generics info and root repository class in extension (note that generics object is set to method declaring type by default). Amend extensions \u00b6 Amend extensions are execution time extensions. They influence method execution by modifying data objects, configuring something etc. Each repository method extension defines its own extension. Such extension interface must extend AmendExecutionExtension . Often amend extensions are registered from parameters extensions. But in some cases, amend extension should be driven by separate annotation. Fro example, @Timeout aextension. Amend extension annotation must be annotated with @AmendMethod , which contains actual extension class. Extension instance is obtained from guice context. Prefer using singleton scope. Amend annotation extension must implement AmendMethodExtension. Generics are important, because descriptor type is used to check extension compatibility. Amend extension annotations are searched on method, on type and on root repository type. If annotation defined both on method and type, more specific method annotation used and type annotation ignored (the same if annotation defined on repository type and method declaring type - declaring type is more specific). If annotation defined directly on method and it's not compatible (by descriptor) exception will be thrown indicating bad usage. Incompatible amend annotations found on type or root type are simply ignored. The logic is simple: you may have many methods in repository which must be annotated and only one which is incompatible. You can simpy annotate type to apply annotation for all methods and incompatible method will ignore this annotation. Amend annotation extension may not implement method specific extension interface, in this case it will be executed on repository creation only. In order to affect execution, repository method specific extension interface must be implemented (same as with parameters). If amend extension implements incompatible method specific amend extension interface it will be ignored. So if amend extension is compatible, but execution extension interface is not - extension is executed during descriptor creation, but not registered as execution amend extension. As with parameter extensions, use extension specific descriptor and save it in main method descriptor. Use MethodExecutionException and MethodExecutionException static methods for validation in annotation processing and execution methods. Amend extension are sorted using @Order annotation. All resolved compatible amend extensions are stored in main method descriptor and must be used by method extensions to process extensions (it is impossible to automate, because extensions are method specific and only method knows how and when to process them). Global amend extension \u00b6 It is possible to register global amend extensions, which will apply to all executed methods (if compatible). Use AmendExtensionsService.addGlobalExtension(ext) . You can also remove global extension later using removeGlobalExtension method. But remember, that compatible amend extensions are stored in the descriptor, which is computed one time and used for all method executions. So if you register global extension after descriptor creation, it will not affect that method. The same with remove: descriptors created while global extension was registered will still use it. Of course, you can always clear descriptors cache using MethodDescriptorFactory.clearCache() . It will destroy all already pre-computed descriptor and on next call new descriptors will be created. Better approach is to register global extension together with application start (when no repository methods were called). Result converter extensions \u00b6 By default, after every repository method execution result is converted with ResultConverter . Default implementation do simple conversions between collection types, convertion from list to single element etc. Default implementation may be changed in guice module. If you want to extend or replace default converter behaviour for single method you can use result converter extension. Extension declared using annotation, annotated with @ResultConverter , which contains actual extension class. Extension instance is resolved from guice context. Prefer using singleton scope. Converter us used as Provider so in case of, for example, prototype scope, new instance will be used for each conversion. Pay attention to applyDefaultConverter annotation parameter. It declares if default converter should be applied. This allows you either extend default behaviour or completely replace it. Note that default converter is executed before extension. Extension is searched on method and method declared type. Only one result converter extension is allowed, but if annotation declared on type and method - method annotation will be used. Extension must implement ResultExtension interface. As with other extensions, main descriptor could be used to store extension specific data (e.g. some annotation parameters). You may use RepositoryMethodDescriptor.result descriptor in converter logic. Result descriptor contains method result analysis info (it is used by default converter). Repository executor \u00b6 RepositoryExecutor abstracts connection specific calls from repository method processing. Executor is selected by method return type: If result is ODocument (or generic) then document connection used If result is model class then object connection used If result id Vertex or Edge then graph connection used Connection object defines type of result types (executing the same query with different connections could return different result objects). User may influence executor selection mechanism by setting required connection type in method annotation. Also, extensions may use descriptor hint to affect executor selection (executor selection performed after descriptor creation and all extensions processing). Default executor implementations may be overridden in RepositoryModule . public class MyRepositoryModule extends RepositoryModule { @Override protected void configureExecutors () { bindExecutor ( CustomDocumentFinderExecutor . class ); bindExecutor ( CustomObjectFinderExecutor . class ); bindExecutor ( CustomGraphFinderExecutor . class ); } } As with connections support, executors are registered according to classpath.","title":"Implementation details"},{"location":"repository/internals/#repository-internals","text":"Repository methods using guice aop and so they could be used in any place. But it's more natural to use them on interface methods. Support for using interfaces and abstract classes in guice is provided by guice-ext-annotations library. Runtime proxies could be also used (and where used initially) but this way guice aop couldn't be used, which is limitation. Class generation overcomes this limitation making abstract types valid guice beans with aop support. Repositories are build using plugin architecture. Each repository annotation is a plugin and can be replaced if requied.","title":"Repository internals"},{"location":"repository/internals/#how-repositories-work","text":"Repository method executor RepositoryMethodInterceptor is applied using guice aop: to all methods with annotations, annotated with @RepositoryMethod . It is not allowed to use multiple repository method annotations on the same method. If any repository contains such method guice context startup will fail (checked explicitly). During context startup descriptors not computed! This would slow down startup significantly. Descriptor is always computed on first method call. So if context start successfully it doesn't mean all repository methods are valid. On repository method call, MethodDescriptorFactory either return cached method descriptor or: Calls method extension to create descriptor Extension creates descripotor and initialize required fields (possibly set hints in descriptor) Extension calls SpiService.process with ParamsContext instance in order to resolve all extensions Spi service calls ParamsService to process all parameters and param extensions At the end of params processing params service calls ParamsContext.process which analyze all parameters info (and additional information provided by extensions) and creates method specific parameters context and assigns it to method context Next AmendExtensionsService called to resolve all compatible amend extensions. Parameters extensions (holder in ParamsContext) are also checked is they are amend extensions Sorted list of compatible amend extensions (including global) is assigned to descriptor object At the end ResultService called to find converter extensions Result service compose ResultConversionDescriptor and assigns it to method descriptor After descriptor is created by extension Method return type analyzed to compose result descriptor (descriptor.result filed). Affected by returnCollectionHint hint. Using result analysis, executor instance selected and assigned to descriptor (descriptor.executor). Affected by connectionHint. Method extension assigned to descriptor object (as Provider). Execution: Extension obtained from descriptor and called to perform execution Extension executes all amend extension from descriptor Extension use executor from descriptor if required (e.g. command extension use it to execute query and delegate use it to obtain connection instance in @Connection extension) Extension returns raw execution result Result conversion: Default result converter is called (if not disabled by result extension) to convert result Call result conversion extension if defined Finally result returned","title":"How repositories work"},{"location":"repository/internals/#repository-extensions","text":"Repositories support 4 types of extensions: Method extension - defines repository method logic Repository parameter extension - defines special handling logic for method parameters Amend method extension - extension that influence method behaviour (many parameter extensions are amend extensions also) Result converter extension - extension to extend or modify default result conversion logic","title":"Repository extensions"},{"location":"repository/internals/#method-extension","text":"Repository method execution consists of three phases: method descriptor creation, execution and result conversion. Descriptor is created on first call and cached. This is required, because this way first call will be slower, but will be able to perform any heavy computations to validate definition and extensions processing and prepare everything for fast execution on future calls.","title":"Method extension"},{"location":"repository/internals/#method-descriptor","text":"Repository descriptor object must extend RepositoryMethodDescriptor . Each method could have unique descriptor or some methods could share the same descriptor type. For example, @Query , @Function , @AsyncQuery use the same descriptor type SqlCommandDescriptor and @Script use uxtended ScriptCommandMethodDescriptor . @Delegate use completely different descriptor object DelegateMethodDescriptor . There are two hint fields in RepositoryMethodDescriptor : returnCollectionHint and connectionHint. Extension may set them to affect return collection type (handled by result converter) and guide executor selection. Descriptor object will be passed to all extension, so it defines which data will be visible to all method specific extensions. Internally root descriptor has extDescriptors map to let extensions store any extension specific data.","title":"Method descriptor"},{"location":"repository/internals/#repository-method-extension","text":"Repository method is defined by annotation, annotated with @RepositoryMethod . Annotation contains actual extension class, which implements RepositoryMethodExtension . Extension is resolved from guice context. Prefer using singletons. Note that extension instance is registered as Provider, so if, for example, prototype scope used, new extension instance will be used for each execution (as a drawback different extension instances will be used for descripotr creation and first execution). Generics are very important ! RepositoryMethodExtension must declare used descriptor object in generic (T). Later this will be used to filter other extensions. Descriptor object also must be generified with supporting amend extensions type (see amend extesnions below). Only extension knows how it would be executed and so only it could define extension interface and properly use it. For example, command and delegate methods are completely different and so use different extensions interface. Method annotation is searched on methods and on type. You can limit exact extension scope when defining annotation target. For example, command extensions applies only to method and delegate could be defined on type. Extension must call SpiService.process method to resolve all amend extension, process parameters and extensions and resolve result converter extensions.","title":"Repository method extension"},{"location":"repository/internals/#parameters-context","text":"Method extension defines param context object extending ParamsContext . Params context is used by parameter extensions. It's methods define core parameter types. For example, command extensions support positional and named query arguments and also el varables (in query string). Delegate support only target method parameters. Also, params context in responsible for main descriptor update after all parameter extensions processed: it validates all parameters info and updates descriptor for fast processing on execution. Read more about it in parameters extensions section below.","title":"Parameters context"},{"location":"repository/internals/#parameter-extension","text":"Parameter extensions resolved from parameter annotations. Parameter extension annotation must be annotated with @MethodParam . Annotation defines extension class, which must implement MethodParamExtension . Extension instance is obtained from guice context. Prefer using singleton scope. Again generics are important! During resolution parameter extension checked for compatibility using descriptor type generic. If type defined in extension genric is assignable to current descriptor type - extension is compatible. If some method extensions use descriptors hierarchy, extension may define some middle type in generic to be compatible with all methods. For example, @Script extension use special descriptor which extends CommandMethodDescriptor and all parameter extensions which use CommandMethodDescriptor in generic are compatible with @Script (because declared descriptor type is compatible). All parameters are parsed before calling extension. Extension receive all parameters under extension annotation. This is very handy for validation: for example, some extension requires only one annotated parameter ( @Size , @Limit etc). Param extension may use main descriptor's extDescriptors map to store extension specific data, which will be used during execution. Param extension itself is called only on parameters parsing. If extension need to perform some execution time modifications, it must also implement amend extension interface, specific for repository method. In this case parameter extension is registered as amend extension. If parameter extension in universal and could be applied to multiple method types it must not only declare compatible descriptor in generic, but also implement all extension interfaces (if target methods have different extension interfaces). If parameter extension doesn't implement compatible amend extension interface it simply will not be registered in method amend extensions (the same as if param extension did not implement any amend interface at all). Parameter extension is checked for amend extension compatibility using amend extension type defined in main descriptor generic (RepositoryMethodDescriptor, generic E). Implementation guideline: Define public static String filed KEY as extension class full name. Define extension specific descriptor object. During parameters processing, validate (if possible), fill specific descriptor and save it in main descriptor: descriptor.extDescriptors.put(KEY, specificDescriptor). For validation use MethodDefinitionException.chec() static method to check and throw exception. In amend extension method you can obtain descriptor descriptor.extDescriptors.get(KEY) and use it. During execution (in amend extension methods) use MethodExecutionException.checkExec static method to check and throw exception. Only one parameter extension annotation could be defined on single method parameter. Parameters context contains descriptor context object, which may be used to get parsed generics info and root repository class in extension (note that generics object is set to method declaring type by default).","title":"Parameter extension"},{"location":"repository/internals/#amend-extensions","text":"Amend extensions are execution time extensions. They influence method execution by modifying data objects, configuring something etc. Each repository method extension defines its own extension. Such extension interface must extend AmendExecutionExtension . Often amend extensions are registered from parameters extensions. But in some cases, amend extension should be driven by separate annotation. Fro example, @Timeout aextension. Amend extension annotation must be annotated with @AmendMethod , which contains actual extension class. Extension instance is obtained from guice context. Prefer using singleton scope. Amend annotation extension must implement AmendMethodExtension. Generics are important, because descriptor type is used to check extension compatibility. Amend extension annotations are searched on method, on type and on root repository type. If annotation defined both on method and type, more specific method annotation used and type annotation ignored (the same if annotation defined on repository type and method declaring type - declaring type is more specific). If annotation defined directly on method and it's not compatible (by descriptor) exception will be thrown indicating bad usage. Incompatible amend annotations found on type or root type are simply ignored. The logic is simple: you may have many methods in repository which must be annotated and only one which is incompatible. You can simpy annotate type to apply annotation for all methods and incompatible method will ignore this annotation. Amend annotation extension may not implement method specific extension interface, in this case it will be executed on repository creation only. In order to affect execution, repository method specific extension interface must be implemented (same as with parameters). If amend extension implements incompatible method specific amend extension interface it will be ignored. So if amend extension is compatible, but execution extension interface is not - extension is executed during descriptor creation, but not registered as execution amend extension. As with parameter extensions, use extension specific descriptor and save it in main method descriptor. Use MethodExecutionException and MethodExecutionException static methods for validation in annotation processing and execution methods. Amend extension are sorted using @Order annotation. All resolved compatible amend extensions are stored in main method descriptor and must be used by method extensions to process extensions (it is impossible to automate, because extensions are method specific and only method knows how and when to process them).","title":"Amend extensions"},{"location":"repository/internals/#global-amend-extension","text":"It is possible to register global amend extensions, which will apply to all executed methods (if compatible). Use AmendExtensionsService.addGlobalExtension(ext) . You can also remove global extension later using removeGlobalExtension method. But remember, that compatible amend extensions are stored in the descriptor, which is computed one time and used for all method executions. So if you register global extension after descriptor creation, it will not affect that method. The same with remove: descriptors created while global extension was registered will still use it. Of course, you can always clear descriptors cache using MethodDescriptorFactory.clearCache() . It will destroy all already pre-computed descriptor and on next call new descriptors will be created. Better approach is to register global extension together with application start (when no repository methods were called).","title":"Global amend extension"},{"location":"repository/internals/#result-converter-extensions","text":"By default, after every repository method execution result is converted with ResultConverter . Default implementation do simple conversions between collection types, convertion from list to single element etc. Default implementation may be changed in guice module. If you want to extend or replace default converter behaviour for single method you can use result converter extension. Extension declared using annotation, annotated with @ResultConverter , which contains actual extension class. Extension instance is resolved from guice context. Prefer using singleton scope. Converter us used as Provider so in case of, for example, prototype scope, new instance will be used for each conversion. Pay attention to applyDefaultConverter annotation parameter. It declares if default converter should be applied. This allows you either extend default behaviour or completely replace it. Note that default converter is executed before extension. Extension is searched on method and method declared type. Only one result converter extension is allowed, but if annotation declared on type and method - method annotation will be used. Extension must implement ResultExtension interface. As with other extensions, main descriptor could be used to store extension specific data (e.g. some annotation parameters). You may use RepositoryMethodDescriptor.result descriptor in converter logic. Result descriptor contains method result analysis info (it is used by default converter).","title":"Result converter extensions"},{"location":"repository/internals/#repository-executor","text":"RepositoryExecutor abstracts connection specific calls from repository method processing. Executor is selected by method return type: If result is ODocument (or generic) then document connection used If result is model class then object connection used If result id Vertex or Edge then graph connection used Connection object defines type of result types (executing the same query with different connections could return different result objects). User may influence executor selection mechanism by setting required connection type in method annotation. Also, extensions may use descriptor hint to affect executor selection (executor selection performed after descriptor creation and all extensions processing). Default executor implementations may be overridden in RepositoryModule . public class MyRepositoryModule extends RepositoryModule { @Override protected void configureExecutors () { bindExecutor ( CustomDocumentFinderExecutor . class ); bindExecutor ( CustomObjectFinderExecutor . class ); bindExecutor ( CustomGraphFinderExecutor . class ); } } As with connections support, executors are registered according to classpath.","title":"Repository executor"},{"location":"repository/mixins/","text":"Repository mixins \u00b6 Mixins are reusable parts, which you can use in repositories. Interfaces are perfect for writing mixins, because both interface and simple class can implement multiple interfaces and so can use any number of mixins. Java generics plays major role in mixins: as you read before exact method return types are important for proper connection selection. Also, mixins plays parametrization role for commands or for delegates. Generics resolution is implemented as separate lib generics-resolver . Command mixins \u00b6 All commands support el variables and mixin class generic names may be used as variables: public interface SelectMixin < T > { @Query ( \"select from ${T}\" ) List < T > selectAll (); } Note Neither @Transactional nor @ProvidedBy annotations are not required on mixin, because mixin is not a repository itself, it simply interface. Now when mixin will be used in repository, actual type could be recognized and used: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends SelectMixin < Model > {} When method selectAll called from repository, generic resolved and used as variable \"Model\" in query and return type will be treated as List<Model> , allowing correctly select object connection (suppose its registered model type). Depth of hierarchy doesn't matter for generics resolution. So if you want, you can compose few mixins into new one and use it in repositories, instead of implementing all mixins in each repository: public interface RepositoryBaseMixin < T > extends Mixin1 < T >, Mixin2 < T > {} When object model not used \u00b6 Suppose you don't want to use object mapping and don't have mapped entities. You may still use generics for types resolution: create empty classes, named the same as your model scheme entities. Use such generics just for queries parametrization. public class ModelName { // empty pojo, used only to specify model name as generic } public interface MyMixin < T > { @Query ( \"select from ${T}\" ) ODocument query (); } public interface Repository extends MyMixin < ModelName > { } Extracting common logic \u00b6 Imagine you have few different repositories for different entities. Some of them have name property. Normally you will have to write select by name query in each repository (can't be moved to some base class, because not all entities contains name). You can write generic mixin: public interface NamedEntityMixin < T > { @Query ( query = \"select from ${T} where name=?\" ) T findByName ( String name ); } Now some repositories could simply implement this interface. Such things could potentially greatly improve code reuse in repositories. Delegate mixins \u00b6 Delegates provide generalization mechanism for custom logic. Usually, such cases are handled by abstract classes (AbstrctDao or something like this). Comparing to simple bean method call, delegate: Provides calling repository method context (selected connection, resolved generics etc) Adds support for annotation driven extensions (amend extensions) Applies result conversion The simplest case is implementing base crud operations for repostiory as delegate mixin: @Delegate ( ObjectCrudDelegate . class ) public interface ObjectCrud < T > { T get ( String id ); T create (); } @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class ObjectCrudDelegate < T > implements ObjectCrud < T > { private final Provider < OObjectDatabaseTx > dbProvider ; @Override public T get ( final String id ) { return dbProvider . get (). load ( new ORecordId ( id )); } public T create ( @Generic ( \"T\" ) final Class < T > type ) { return dbProvider . get (). newInstance ( type ); } } Now it could be used to easily apply common operation for repository: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectCrud < Model > {} Bundled mixins \u00b6 DocumentCrud - crud operations for document repositories ObjectCrud - crud operations for object repositories ObjectVertexCrud - object crud for using with vertex objects (annotated with @VertexType) EdgesSupport - general support for edge objects (annotated with @EdgeType) EdgeTypeSupport - support for exact edge object type Pagination - pagination support for object or document repositories","title":"Mixins"},{"location":"repository/mixins/#repository-mixins","text":"Mixins are reusable parts, which you can use in repositories. Interfaces are perfect for writing mixins, because both interface and simple class can implement multiple interfaces and so can use any number of mixins. Java generics plays major role in mixins: as you read before exact method return types are important for proper connection selection. Also, mixins plays parametrization role for commands or for delegates. Generics resolution is implemented as separate lib generics-resolver .","title":"Repository mixins"},{"location":"repository/mixins/#command-mixins","text":"All commands support el variables and mixin class generic names may be used as variables: public interface SelectMixin < T > { @Query ( \"select from ${T}\" ) List < T > selectAll (); } Note Neither @Transactional nor @ProvidedBy annotations are not required on mixin, because mixin is not a repository itself, it simply interface. Now when mixin will be used in repository, actual type could be recognized and used: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends SelectMixin < Model > {} When method selectAll called from repository, generic resolved and used as variable \"Model\" in query and return type will be treated as List<Model> , allowing correctly select object connection (suppose its registered model type). Depth of hierarchy doesn't matter for generics resolution. So if you want, you can compose few mixins into new one and use it in repositories, instead of implementing all mixins in each repository: public interface RepositoryBaseMixin < T > extends Mixin1 < T >, Mixin2 < T > {}","title":"Command mixins"},{"location":"repository/mixins/#when-object-model-not-used","text":"Suppose you don't want to use object mapping and don't have mapped entities. You may still use generics for types resolution: create empty classes, named the same as your model scheme entities. Use such generics just for queries parametrization. public class ModelName { // empty pojo, used only to specify model name as generic } public interface MyMixin < T > { @Query ( \"select from ${T}\" ) ODocument query (); } public interface Repository extends MyMixin < ModelName > { }","title":"When object model not used"},{"location":"repository/mixins/#extracting-common-logic","text":"Imagine you have few different repositories for different entities. Some of them have name property. Normally you will have to write select by name query in each repository (can't be moved to some base class, because not all entities contains name). You can write generic mixin: public interface NamedEntityMixin < T > { @Query ( query = \"select from ${T} where name=?\" ) T findByName ( String name ); } Now some repositories could simply implement this interface. Such things could potentially greatly improve code reuse in repositories.","title":"Extracting common logic"},{"location":"repository/mixins/#delegate-mixins","text":"Delegates provide generalization mechanism for custom logic. Usually, such cases are handled by abstract classes (AbstrctDao or something like this). Comparing to simple bean method call, delegate: Provides calling repository method context (selected connection, resolved generics etc) Adds support for annotation driven extensions (amend extensions) Applies result conversion The simplest case is implementing base crud operations for repostiory as delegate mixin: @Delegate ( ObjectCrudDelegate . class ) public interface ObjectCrud < T > { T get ( String id ); T create (); } @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class ObjectCrudDelegate < T > implements ObjectCrud < T > { private final Provider < OObjectDatabaseTx > dbProvider ; @Override public T get ( final String id ) { return dbProvider . get (). load ( new ORecordId ( id )); } public T create ( @Generic ( \"T\" ) final Class < T > type ) { return dbProvider . get (). newInstance ( type ); } } Now it could be used to easily apply common operation for repository: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectCrud < Model > {}","title":"Delegate mixins"},{"location":"repository/mixins/#bundled-mixins","text":"DocumentCrud - crud operations for document repositories ObjectCrud - crud operations for object repositories ObjectVertexCrud - object crud for using with vertex objects (annotated with @VertexType) EdgesSupport - general support for edge objects (annotated with @EdgeType) EdgeTypeSupport - support for exact edge object type Pagination - pagination support for object or document repositories","title":"Bundled mixins"},{"location":"repository/overview/","text":"Repositories \u00b6 Repository annotations simplify writing dao or repository objects. Repositories are very close to spring-data repositories and following description will follow this approach. But repository methods may be used in any way (like dao or as additional methods for beans). Repositories mainly cover query definitions (removing all boilerplate code). If you need something like spring-data specifications, you can use orientqb Example repository query method: public interface MyRepository { @Query ( \"select from Model where name=? and nick=?\" ) List < Model > find ( String name , String nick ); } Repositories implementation is based on extensions (every annotation you'll see is an extension). Custom extensions supported, so you can change almost everything. Setup \u00b6 To use repository features register repository module in guice context: install ( new RepositoryModule ()); Guice abstract types support \u00b6 Repository methods defined with annotations, so interface and abstract methods are ideal candidates to use them. Guice doesn't allow using abstract types, but it's possible with a bit of magic . Abstract types (abstract class or interface containing repository methods) could be registered directly in guice module: bind ( MyInterfaceRepository . class ). to ( DynamicClassGenerator . generate ( MyInterfaceRepository . class )). in ( Singleton . class ) Or dynamic resolution could be used (guice JIT resolution): @ProvidedBy ( DynamicSingletonProvider . class ) public interface MyRepository When some bean require this dao as dependency, guice will call provider, which will generate proper class for guice. (dynamic resolution completely replaces classpath scanning: only actually used repositories will be created) Note, this will automatically make bean singleton, which should be desirable in most cases. If you need custom scope use DynamicClassProvider with @ScopeAnnotation annotation (see details in guice-ext-annotations ) Note Intellij IDEA will warn you that ProvidedBy annotation is incorrectly typed, but it's ok, because provider is too generic. There is nothing I can do with it and it's the best (the simplest) way I know (without explicit classpath scanning, which is redundant). Important Guice will control instance creation, so guice AOP features will completely work! @Transactional annotation may be used (generally not the best idea to limit transaction to repository method, but in some cases could be suitable). You can think of repository interface or abstract class as of usual guice bean (no limitations). Repository methods are applied using aop (that's why they could be used everywhere). Repositories overview \u00b6 There 2 types of repository methods: Commands - orient data manipulation calls (queries, commands, scripts etc) and build around orient command objects Delegates - methods delegate execution to some other beans (useful for generic logic) Method annotation Description @Query select/update/insert query @Function orient function call @Script script call (sql, js etc) @AsyncQuery asynchronous query call @LiveQuery orient live query subscription call @Delegate delegate call to other bean method Defining repository \u00b6 @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository { @Query ( \"select from Model\" ) List < Model > selectAll (); @Query ( \"update Model set name = ? where name = ?\" ) int updateName ( String newName , String oldName ); @Query ( \"insert into Model (name) values(:name)\" ) Model create ( @Param ( \"name\" ) String name ); } Note Repository methods could be used to supplement existing bean, but suggest to use pure interface repositories. @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class MyDao { @Query ( \"select from Model\" ) public abstract List < Model > selectAll (); // normal method public void doSomething () { ... } } Note @Transactional is not required (annotation usage depends on your service architecture, but repository method must be used inside transaction). Usage examples \u00b6 Function call: @Function ( \"function1\" ) List < Model > function (); Positional parameters: @Query ( \"select from Model where name=? and nick=?\" ) List < Model > parametersPositional ( String name , String nick ) Named parameters: @Query ( \"select from Model where name=:name and nick=:nick\" ) List < Model > parametersNamed ( @Param ( \"name\" ) String name , @Param ( \"nick\" ) String nick ) Pagination : @Query ( \"select from Model where name=? and nick=?\" ) List < Model > parametersPaged ( String name , String nick , @Skip int skip , @Limit int limit ) El variable : @Query ( \"select from Model where ${prop}=?\" ) List < Model > findBy ( @ElVar ( \"prop\" ) String prop , String value ) Fetch plan parameter: @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan ( \"*:0\" ) String plan ); Sql script: @Script ( \"begin\" + \"let account = create vertex Account set name = :name\" + \"let city = select from City where name = :city\" + \"let edge = create edge Lives from $account to $city\" + \"commit retry 100\" + \"return $edge\" ) Edge linkCity ( @Param ( \"name\" ) String name , @Param ( \"city\" ) String city ) Js script: @Script ( language = \"javascript\" , value = \"for( i = 0; i < 1000; i++ ){\" + \"db.command('insert into Model(name) values (\\\"test'+i+'\\\")');\" + \"}\" ) void jsScript () Async query: @AsyncQuery ( \"select from Model\" ) void select ( @Listen OCommandResultListener listener ) Type safe listener (with conversion): @AsyncQuery ( \"select from Model\" ) void select ( @Listen AsyncQueryListener < Model > listener ) Or with projection: @AsyncQuery ( \"select name from Model\" ) void select ( @Listen AsyncQueryListener < String > listener ) Dynamic parameters: @Query ( ' select from Model where $ { cond } ' ) List < ODocument > findWhere ( @ElVar ( \"cond\" ) String cond , @DynamicParams Object ... params ); Non blocking (listener execute in different thread): @AsyncQuery ( value = \"select from Model\" , blocking = false ) Future < List < Model >> select ( @Listen AsyncQueryListener < Model > listener ) Delegate example: public class SomeBean { public List getAll () { ... } } @Delegate ( SomeBean . class ) List getAll (); Live query: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen OLiveResultListener listener ) Type safe listener (with conversion): @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen QueryResultListener < Model > listener ) Or vertex conversion: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen QueryResultListener < Vertex > listener ) Unsubscription (usual command call): @Query ( \"live unsubscribe ${token}\" ) void unsubscribe ( @ElVar ( \"token\" ) int token ) Read more about method usage: Command methods Delegate methods Tip For more examples see repository definition examples Writing extensions: Extending commands Extending delegates Return types \u00b6 You can use Iterable , Collection , List , Set , any collection implementation, array, single element or Iterator as return type. Conversion between types will be applied automatically . @Query ( \"select from Model\" ) List < Model > selectAll (); @Query ( \"select from Model\" ) Set < Model > selectAll (); @Query ( \"select from Model\" ) Model [] selectAll (); @Query ( \"select from Model\" ) Iterable < Model > selectAll (); @Query ( \"select from Model\" ) Iterator < Model > selectAll (); If you define single result, when query produce multiple results, first result would be automatically taken: @Query ( \"select from Model limit 1\" ) Model selectAll (); Note Limit is not required, but preferred, as soon as you don't need other results Projection \u00b6 In some cases simple value is preferred, for example: @Query ( \" select count ( @rid ) from Model ) int count (); Orient returns ODocument from query with single field (count). Default result converter could recognize when document or vertex contain just one property and return only simple value. Another case is when you select single field: @Query ( \"select name from Model\" ) String [] selectNames () Read more about projection Result type definition \u00b6 It is very important to always define exact return type. Connection type defines type of result object: document connection always return ODocument , object return mapped objects (but ODocument for field calls) and graph - Vertex and Edge . Result type is used internally to detect connection type for query. For example, if you write: @Query ( \"select from Model\" ) List selectAll (); You will actually receive List<ODocument> , because without generic it's impossible to detect required return type and document connection used for query. For example, in this case graph connection would be selected: @Query ( \"select from Model\" ) List < Vertex > selectAll (); Result conversion \u00b6 Every repository method result is converted with default converter (as described above). You can use more specific result conversion extension, for example: @Query ( \"select from Model\" ) @NoConversion List < Model > selectAll (); NoConversion disables conversion mechanism and you receive result object as is. Read more about converter mechanism and writing custom converters . Mixins \u00b6 Java support multiple inheritance for interfaces and you can inherit multiple interfaces in classes. So interfaces are ideal for writing small reusable parts (mixins). Command mixins \u00b6 El variables in commands support references to class generics, so you can use it for generic repository logic: public interface MyMixin < T > { @Query ( \"select from ${T}\" ) List < T > selectAll () } @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends MyMixin < Model > {} When you call mixin method from repository instance repository . selectAll () Generic value Model will be used for command select from Model and return type will be resolved as List<Model> , which will allow to select proper connection (object if Model is mapped entity). You may use as many generics as you need. Any repository hierarchy depth will be correctly resolved, so you can even use composition mixins, which wil simply combine commonly used mixins: public interface RepositoryBase < T > extends Mixin1 < T >, Mixin2 < T > {} Note You don't need to set @ProvidedBy annotation on mixins, because it's just interfaces and they are not used as repository instances. Delegate mixins \u00b6 Delegates are also support generalization through extensions: public class DelegateBean { public List selectAll ( @Generic ( \"T\" ) Class model ) { } } public interface MyMixin < T > { @Delegate ( DelegateBean . class ) List < T > selectAll () } When delegate bean called from mixin, it will receive generic value (of calling mixin) as parameter. Read more about mixins usage Bundled crud mixins \u00b6 Crud mixins are the most common thing: commonly these methods are implemented in AbstractDao or something like this. DocumentCrud mixin provides base crud methods for document repository. public interface MyEntityDao extends DocumentCrud < MyEntity > {} Set mixin generic value only if you have reference entity class. Generic affects only getAll and create methods: if generic not set you will not be able to use only this method. ObjectCrud mixin provides base crud methods for object repository: public interface MyEntityRepository extends ObjectCrud < MyEntity > {} Now MyEntityRepository has all basic crud methods (create, get, delete etc). Pagination provides simple pagination for your entity or document (but document should have reference type, at least to specify schema type name (may be empty class)) public interface MyEntityRepository extends ObjectCrud < MyEntity >, Pagination < MyEntity , MyEntity > {} ... // return page Page page = repository . getPage ( 1 , 20 ); In order to use pagination mixin, crud mixin is not required (used in example just to mention one more time that mixins could be combined). Pagination mixin is the most complex one and good place to inspire how to write more complex reusable logic . ObjectVertexCrud , EdgesSupport and EdgeTypeSupport mixins allows using graph features from object api. @vertexType public class Model {} @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} @Inject ModelRepository repository ; ... Model from = repository . save ( new Model (..)); Model to = repository . save ( new Model (..)); ModelConnection edge = repository . createEdge ( from , to ); Validation \u00b6 You can use guice-validator to apply runtime validation (jsr 303) for repository methods: @Query ( \"select from Model where name = ?\" ) @Size ( min = 1 ) List < Model > select ( @NotNull String name ) Now this query throw ConstraintViolationException if null provided as parameter or no results returned. Important Register validator module before guice-persist-orient modules! This way validation will be checked before @Transactional or repository methods logic.","title":"Overview"},{"location":"repository/overview/#repositories","text":"Repository annotations simplify writing dao or repository objects. Repositories are very close to spring-data repositories and following description will follow this approach. But repository methods may be used in any way (like dao or as additional methods for beans). Repositories mainly cover query definitions (removing all boilerplate code). If you need something like spring-data specifications, you can use orientqb Example repository query method: public interface MyRepository { @Query ( \"select from Model where name=? and nick=?\" ) List < Model > find ( String name , String nick ); } Repositories implementation is based on extensions (every annotation you'll see is an extension). Custom extensions supported, so you can change almost everything.","title":"Repositories"},{"location":"repository/overview/#setup","text":"To use repository features register repository module in guice context: install ( new RepositoryModule ());","title":"Setup"},{"location":"repository/overview/#guice-abstract-types-support","text":"Repository methods defined with annotations, so interface and abstract methods are ideal candidates to use them. Guice doesn't allow using abstract types, but it's possible with a bit of magic . Abstract types (abstract class or interface containing repository methods) could be registered directly in guice module: bind ( MyInterfaceRepository . class ). to ( DynamicClassGenerator . generate ( MyInterfaceRepository . class )). in ( Singleton . class ) Or dynamic resolution could be used (guice JIT resolution): @ProvidedBy ( DynamicSingletonProvider . class ) public interface MyRepository When some bean require this dao as dependency, guice will call provider, which will generate proper class for guice. (dynamic resolution completely replaces classpath scanning: only actually used repositories will be created) Note, this will automatically make bean singleton, which should be desirable in most cases. If you need custom scope use DynamicClassProvider with @ScopeAnnotation annotation (see details in guice-ext-annotations ) Note Intellij IDEA will warn you that ProvidedBy annotation is incorrectly typed, but it's ok, because provider is too generic. There is nothing I can do with it and it's the best (the simplest) way I know (without explicit classpath scanning, which is redundant). Important Guice will control instance creation, so guice AOP features will completely work! @Transactional annotation may be used (generally not the best idea to limit transaction to repository method, but in some cases could be suitable). You can think of repository interface or abstract class as of usual guice bean (no limitations). Repository methods are applied using aop (that's why they could be used everywhere).","title":"Guice abstract types support"},{"location":"repository/overview/#repositories-overview","text":"There 2 types of repository methods: Commands - orient data manipulation calls (queries, commands, scripts etc) and build around orient command objects Delegates - methods delegate execution to some other beans (useful for generic logic) Method annotation Description @Query select/update/insert query @Function orient function call @Script script call (sql, js etc) @AsyncQuery asynchronous query call @LiveQuery orient live query subscription call @Delegate delegate call to other bean method","title":"Repositories overview"},{"location":"repository/overview/#defining-repository","text":"@Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository { @Query ( \"select from Model\" ) List < Model > selectAll (); @Query ( \"update Model set name = ? where name = ?\" ) int updateName ( String newName , String oldName ); @Query ( \"insert into Model (name) values(:name)\" ) Model create ( @Param ( \"name\" ) String name ); } Note Repository methods could be used to supplement existing bean, but suggest to use pure interface repositories. @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class MyDao { @Query ( \"select from Model\" ) public abstract List < Model > selectAll (); // normal method public void doSomething () { ... } } Note @Transactional is not required (annotation usage depends on your service architecture, but repository method must be used inside transaction).","title":"Defining repository"},{"location":"repository/overview/#usage-examples","text":"Function call: @Function ( \"function1\" ) List < Model > function (); Positional parameters: @Query ( \"select from Model where name=? and nick=?\" ) List < Model > parametersPositional ( String name , String nick ) Named parameters: @Query ( \"select from Model where name=:name and nick=:nick\" ) List < Model > parametersNamed ( @Param ( \"name\" ) String name , @Param ( \"nick\" ) String nick ) Pagination : @Query ( \"select from Model where name=? and nick=?\" ) List < Model > parametersPaged ( String name , String nick , @Skip int skip , @Limit int limit ) El variable : @Query ( \"select from Model where ${prop}=?\" ) List < Model > findBy ( @ElVar ( \"prop\" ) String prop , String value ) Fetch plan parameter: @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan ( \"*:0\" ) String plan ); Sql script: @Script ( \"begin\" + \"let account = create vertex Account set name = :name\" + \"let city = select from City where name = :city\" + \"let edge = create edge Lives from $account to $city\" + \"commit retry 100\" + \"return $edge\" ) Edge linkCity ( @Param ( \"name\" ) String name , @Param ( \"city\" ) String city ) Js script: @Script ( language = \"javascript\" , value = \"for( i = 0; i < 1000; i++ ){\" + \"db.command('insert into Model(name) values (\\\"test'+i+'\\\")');\" + \"}\" ) void jsScript () Async query: @AsyncQuery ( \"select from Model\" ) void select ( @Listen OCommandResultListener listener ) Type safe listener (with conversion): @AsyncQuery ( \"select from Model\" ) void select ( @Listen AsyncQueryListener < Model > listener ) Or with projection: @AsyncQuery ( \"select name from Model\" ) void select ( @Listen AsyncQueryListener < String > listener ) Dynamic parameters: @Query ( ' select from Model where $ { cond } ' ) List < ODocument > findWhere ( @ElVar ( \"cond\" ) String cond , @DynamicParams Object ... params ); Non blocking (listener execute in different thread): @AsyncQuery ( value = \"select from Model\" , blocking = false ) Future < List < Model >> select ( @Listen AsyncQueryListener < Model > listener ) Delegate example: public class SomeBean { public List getAll () { ... } } @Delegate ( SomeBean . class ) List getAll (); Live query: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen OLiveResultListener listener ) Type safe listener (with conversion): @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen QueryResultListener < Model > listener ) Or vertex conversion: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen QueryResultListener < Vertex > listener ) Unsubscription (usual command call): @Query ( \"live unsubscribe ${token}\" ) void unsubscribe ( @ElVar ( \"token\" ) int token ) Read more about method usage: Command methods Delegate methods Tip For more examples see repository definition examples Writing extensions: Extending commands Extending delegates","title":"Usage examples"},{"location":"repository/overview/#return-types","text":"You can use Iterable , Collection , List , Set , any collection implementation, array, single element or Iterator as return type. Conversion between types will be applied automatically . @Query ( \"select from Model\" ) List < Model > selectAll (); @Query ( \"select from Model\" ) Set < Model > selectAll (); @Query ( \"select from Model\" ) Model [] selectAll (); @Query ( \"select from Model\" ) Iterable < Model > selectAll (); @Query ( \"select from Model\" ) Iterator < Model > selectAll (); If you define single result, when query produce multiple results, first result would be automatically taken: @Query ( \"select from Model limit 1\" ) Model selectAll (); Note Limit is not required, but preferred, as soon as you don't need other results","title":"Return types"},{"location":"repository/overview/#projection","text":"In some cases simple value is preferred, for example: @Query ( \" select count ( @rid ) from Model ) int count (); Orient returns ODocument from query with single field (count). Default result converter could recognize when document or vertex contain just one property and return only simple value. Another case is when you select single field: @Query ( \"select name from Model\" ) String [] selectNames () Read more about projection","title":"Projection"},{"location":"repository/overview/#result-type-definition","text":"It is very important to always define exact return type. Connection type defines type of result object: document connection always return ODocument , object return mapped objects (but ODocument for field calls) and graph - Vertex and Edge . Result type is used internally to detect connection type for query. For example, if you write: @Query ( \"select from Model\" ) List selectAll (); You will actually receive List<ODocument> , because without generic it's impossible to detect required return type and document connection used for query. For example, in this case graph connection would be selected: @Query ( \"select from Model\" ) List < Vertex > selectAll ();","title":"Result type definition"},{"location":"repository/overview/#result-conversion","text":"Every repository method result is converted with default converter (as described above). You can use more specific result conversion extension, for example: @Query ( \"select from Model\" ) @NoConversion List < Model > selectAll (); NoConversion disables conversion mechanism and you receive result object as is. Read more about converter mechanism and writing custom converters .","title":"Result conversion"},{"location":"repository/overview/#mixins","text":"Java support multiple inheritance for interfaces and you can inherit multiple interfaces in classes. So interfaces are ideal for writing small reusable parts (mixins).","title":"Mixins"},{"location":"repository/overview/#command-mixins","text":"El variables in commands support references to class generics, so you can use it for generic repository logic: public interface MyMixin < T > { @Query ( \"select from ${T}\" ) List < T > selectAll () } @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends MyMixin < Model > {} When you call mixin method from repository instance repository . selectAll () Generic value Model will be used for command select from Model and return type will be resolved as List<Model> , which will allow to select proper connection (object if Model is mapped entity). You may use as many generics as you need. Any repository hierarchy depth will be correctly resolved, so you can even use composition mixins, which wil simply combine commonly used mixins: public interface RepositoryBase < T > extends Mixin1 < T >, Mixin2 < T > {} Note You don't need to set @ProvidedBy annotation on mixins, because it's just interfaces and they are not used as repository instances.","title":"Command mixins"},{"location":"repository/overview/#delegate-mixins","text":"Delegates are also support generalization through extensions: public class DelegateBean { public List selectAll ( @Generic ( \"T\" ) Class model ) { } } public interface MyMixin < T > { @Delegate ( DelegateBean . class ) List < T > selectAll () } When delegate bean called from mixin, it will receive generic value (of calling mixin) as parameter. Read more about mixins usage","title":"Delegate mixins"},{"location":"repository/overview/#bundled-crud-mixins","text":"Crud mixins are the most common thing: commonly these methods are implemented in AbstractDao or something like this. DocumentCrud mixin provides base crud methods for document repository. public interface MyEntityDao extends DocumentCrud < MyEntity > {} Set mixin generic value only if you have reference entity class. Generic affects only getAll and create methods: if generic not set you will not be able to use only this method. ObjectCrud mixin provides base crud methods for object repository: public interface MyEntityRepository extends ObjectCrud < MyEntity > {} Now MyEntityRepository has all basic crud methods (create, get, delete etc). Pagination provides simple pagination for your entity or document (but document should have reference type, at least to specify schema type name (may be empty class)) public interface MyEntityRepository extends ObjectCrud < MyEntity >, Pagination < MyEntity , MyEntity > {} ... // return page Page page = repository . getPage ( 1 , 20 ); In order to use pagination mixin, crud mixin is not required (used in example just to mention one more time that mixins could be combined). Pagination mixin is the most complex one and good place to inspire how to write more complex reusable logic . ObjectVertexCrud , EdgesSupport and EdgeTypeSupport mixins allows using graph features from object api. @vertexType public class Model {} @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} @Inject ModelRepository repository ; ... Model from = repository . save ( new Model (..)); Model to = repository . save ( new Model (..)); ModelConnection edge = repository . createEdge ( from , to );","title":"Bundled crud mixins"},{"location":"repository/overview/#validation","text":"You can use guice-validator to apply runtime validation (jsr 303) for repository methods: @Query ( \"select from Model where name = ?\" ) @Size ( min = 1 ) List < Model > select ( @NotNull String name ) Now this query throw ConstraintViolationException if null provided as parameter or no results returned. Important Register validator module before guice-persist-orient modules! This way validation will be checked before @Transactional or repository methods logic.","title":"Validation"},{"location":"repository/result/","text":"Result handling \u00b6 Connection type detection \u00b6 It is very important to define complete return type, because connection type is detected from method return type. If you specify generic for returned collection (or iterator) or use typed array (not Object[] ) or in case of single element, connection type will be detected like this: If returned class is registered with object entity manager, object connection will be used If ODocument class returned - document connection used If Vertex or Edge classes returned - graph connection Connection type directly affects produced objects: the same query will return different result objects, executed with different connections. But, for example, even if you try to select not object itself, but fields you will get ODocument , even in object connection (kind of result set in jdbc). For such case document connection will be selected (according to return type). Return types \u00b6 You can use: Iterable , Collection , List , Set , any collection implementation, array, single element or Iterator as return type. Single elements (single object return) may be wrapped with Optional (guava ( com.google.common.base.Optional ) or jdk8 ( java.util.Optional )). Collections should not be wrapped with optional, because repository method should never return null for collection or array. Query execution result will be converted in accordance with specified return type. Note Examples below use command methods, but conversion mechanism is applied to all kinds of methods including delegates . For example: @Query ( \"select from Model\" ) Model selectAll () Returns List<Model> , but converter will take just first element (or null if empty) and return just it. Here first result of returned list is wrapped with optional by converter: @Query ( \"select from Model\" ) Optional < Model > selectAll () The same for array (returned list will be converted to array): @Query ( \"select from Model\" ) Model [] selectAll () Sometimes it may be desirable to change default returned collection implementation, e.g. to sort elements: @Query ( \"select from Model\" , returnAs = TreeSet . class ) Set < Model > selectAll () TreeSet collection will be returned. The same result will be if set method return type to TreeSet (but it's not best practice to define implementation as return type). Result projection \u00b6 In orient, when you query for some aggregated function (like count) or selecting just one field, ODocument or Vertex objects will be returned (for document/object and graph connections). This is usually not the desired behavior. Projection is unwrapping from document or vertex if it contains just one property. Unwrapping is triggered by return type, e.g. @Query ( \"select count(@rid) from Model\" ) int getCount (); Here return type is int, but actual query will return ODocument . Result converter will detect this, look that document contains just one field (count) and return just this field value. Note that actual field value could be long or double, conversion to int will also be performed automatically. If return type would be ODocument - no conversion will occur. When we need just one field from multiple rows: @Query ( \"select name from Model\" ) String [] getNamesArray (); Query returns collection of ODocument , but result converter will look return type and unwrap documents returning simple array. Projection detection implemented without possible check overhead and so projection may be used with collections too: @Query ( \"select name from Model\" ) List < String > getNamesArray (); For graph connection this will also work: @Query ( value = \"select name from Model\" , connection = DbType . GRAPH ) String [] getNamesArray (); This time orient will return Vertex instances and result converter will look if vertex contains just one property and unwrap single value. Special case: by default, result converter took first collection element if single result required. So projection may be used like this: @Query ( \"select name from Model\" ) String getNamesArray (); Here collection reduced to one element and single element projected to string value. Default converter override \u00b6 Default converter logic may be overridden in guice module, by simply registering new implementation: bind ( ResultConverter . class ). to ( CustomResultConverter . class ) Result extensions \u00b6 Out of the box two extensions provided: @NoConversion - disables any conversion @DetachResult - detaches objects (in object connection proxies will be returned, which will not work outside of transaction).","title":"Result conversion"},{"location":"repository/result/#result-handling","text":"","title":"Result handling"},{"location":"repository/result/#connection-type-detection","text":"It is very important to define complete return type, because connection type is detected from method return type. If you specify generic for returned collection (or iterator) or use typed array (not Object[] ) or in case of single element, connection type will be detected like this: If returned class is registered with object entity manager, object connection will be used If ODocument class returned - document connection used If Vertex or Edge classes returned - graph connection Connection type directly affects produced objects: the same query will return different result objects, executed with different connections. But, for example, even if you try to select not object itself, but fields you will get ODocument , even in object connection (kind of result set in jdbc). For such case document connection will be selected (according to return type).","title":"Connection type detection"},{"location":"repository/result/#return-types","text":"You can use: Iterable , Collection , List , Set , any collection implementation, array, single element or Iterator as return type. Single elements (single object return) may be wrapped with Optional (guava ( com.google.common.base.Optional ) or jdk8 ( java.util.Optional )). Collections should not be wrapped with optional, because repository method should never return null for collection or array. Query execution result will be converted in accordance with specified return type. Note Examples below use command methods, but conversion mechanism is applied to all kinds of methods including delegates . For example: @Query ( \"select from Model\" ) Model selectAll () Returns List<Model> , but converter will take just first element (or null if empty) and return just it. Here first result of returned list is wrapped with optional by converter: @Query ( \"select from Model\" ) Optional < Model > selectAll () The same for array (returned list will be converted to array): @Query ( \"select from Model\" ) Model [] selectAll () Sometimes it may be desirable to change default returned collection implementation, e.g. to sort elements: @Query ( \"select from Model\" , returnAs = TreeSet . class ) Set < Model > selectAll () TreeSet collection will be returned. The same result will be if set method return type to TreeSet (but it's not best practice to define implementation as return type).","title":"Return types"},{"location":"repository/result/#result-projection","text":"In orient, when you query for some aggregated function (like count) or selecting just one field, ODocument or Vertex objects will be returned (for document/object and graph connections). This is usually not the desired behavior. Projection is unwrapping from document or vertex if it contains just one property. Unwrapping is triggered by return type, e.g. @Query ( \"select count(@rid) from Model\" ) int getCount (); Here return type is int, but actual query will return ODocument . Result converter will detect this, look that document contains just one field (count) and return just this field value. Note that actual field value could be long or double, conversion to int will also be performed automatically. If return type would be ODocument - no conversion will occur. When we need just one field from multiple rows: @Query ( \"select name from Model\" ) String [] getNamesArray (); Query returns collection of ODocument , but result converter will look return type and unwrap documents returning simple array. Projection detection implemented without possible check overhead and so projection may be used with collections too: @Query ( \"select name from Model\" ) List < String > getNamesArray (); For graph connection this will also work: @Query ( value = \"select name from Model\" , connection = DbType . GRAPH ) String [] getNamesArray (); This time orient will return Vertex instances and result converter will look if vertex contains just one property and unwrap single value. Special case: by default, result converter took first collection element if single result required. So projection may be used like this: @Query ( \"select name from Model\" ) String getNamesArray (); Here collection reduced to one element and single element projected to string value.","title":"Result projection"},{"location":"repository/result/#default-converter-override","text":"Default converter logic may be overridden in guice module, by simply registering new implementation: bind ( ResultConverter . class ). to ( CustomResultConverter . class )","title":"Default converter override"},{"location":"repository/result/#result-extensions","text":"Out of the box two extensions provided: @NoConversion - disables any conversion @DetachResult - detaches objects (in object connection proxies will be returned, which will not work outside of transaction).","title":"Result extensions"},{"location":"repository/command/asyncquery/","text":"@AsyncQuery \u00b6 Command method extension Executes query asynchronously . By default, async query execution is blocking: method is blocking while listener is called (and listener is executed at the same thread). Such query is useful for dynamic filtering: results are analyzed one by one and you can manually stop further results processing. Example: @AsyncQuery ( \"select from Model\" ) void select ( @Listen OCommandResultListener listener ) Returned result will be passed to the provided listener (always as ODocument ). Listener \u00b6 Special listener type could be used to automatically convert the provided document (the same way as repository return result is converted): @AsyncQuery ( \"select from Model\" ) void select ( @Listen AsyncQueryListener < Model > listener ) Projection will also work: @AsyncQuery ( \"select name from Model\" ) void selectProjection ( @Listen AsyncQueryListener < String > listener ) And even conversion to graph api: @AsyncQuery ( \"select from VertexModel\" ) void selectVertex ( @Listen AsyncQueryListener < Vertex > listener ) Non blocking \u00b6 Non blocking async query is executed truly asynchronously: listener called in a separate thread. Non blocking query may return future. @AsyncQuery ( value = \"select from Model\" , blocking = false ) Future < List < Model >> selectNonBlock ( @Listen AsyncQueryListener < Model > listener ) Future may be used to wait for the result: // most likely get will be called somewhere later in code and not directly after async method call List < Model > result = selectNonBlock (). get () Listener execution is wrapped with external transacton, so guice can use the same connection instance as orient in current thread. But it is highly recommended to avoid database operations inside listener because listener must execute as fast as possible (orient recommendation). Internally OSQLAsynchQuery or OSQLNonBlockingQuery used accordingly.","title":"@AsyncQuery"},{"location":"repository/command/asyncquery/#asyncquery","text":"Command method extension Executes query asynchronously . By default, async query execution is blocking: method is blocking while listener is called (and listener is executed at the same thread). Such query is useful for dynamic filtering: results are analyzed one by one and you can manually stop further results processing. Example: @AsyncQuery ( \"select from Model\" ) void select ( @Listen OCommandResultListener listener ) Returned result will be passed to the provided listener (always as ODocument ).","title":"@AsyncQuery"},{"location":"repository/command/asyncquery/#listener","text":"Special listener type could be used to automatically convert the provided document (the same way as repository return result is converted): @AsyncQuery ( \"select from Model\" ) void select ( @Listen AsyncQueryListener < Model > listener ) Projection will also work: @AsyncQuery ( \"select name from Model\" ) void selectProjection ( @Listen AsyncQueryListener < String > listener ) And even conversion to graph api: @AsyncQuery ( \"select from VertexModel\" ) void selectVertex ( @Listen AsyncQueryListener < Vertex > listener )","title":"Listener"},{"location":"repository/command/asyncquery/#non-blocking","text":"Non blocking async query is executed truly asynchronously: listener called in a separate thread. Non blocking query may return future. @AsyncQuery ( value = \"select from Model\" , blocking = false ) Future < List < Model >> selectNonBlock ( @Listen AsyncQueryListener < Model > listener ) Future may be used to wait for the result: // most likely get will be called somewhere later in code and not directly after async method call List < Model > result = selectNonBlock (). get () Listener execution is wrapped with external transacton, so guice can use the same connection instance as orient in current thread. But it is highly recommended to avoid database operations inside listener because listener must execute as fast as possible (orient recommendation). Internally OSQLAsynchQuery or OSQLNonBlockingQuery used accordingly.","title":"Non blocking"},{"location":"repository/command/function/","text":"@Function \u00b6 Command method extension Function methods execute function . For example, suppose we create a function like this: CREATE FUNCTION function1 \"select from Model\" LANGUAGE SQL Now we can call it like this: @Function ( \"function1\" ) List < Model > select ( String name ) Internally OCommandFunction used.","title":"@Function"},{"location":"repository/command/function/#function","text":"Command method extension Function methods execute function . For example, suppose we create a function like this: CREATE FUNCTION function1 \"select from Model\" LANGUAGE SQL Now we can call it like this: @Function ( \"function1\" ) List < Model > select ( String name ) Internally OCommandFunction used.","title":"@Function"},{"location":"repository/command/livequery/","text":"@LiveQuery \u00b6 Command method extension Subscribe listener to orient live query . Live query may use row orient listener interface: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen OLiveResultListener listener ) Note Live query must start with \"live\", but this is optional as annotation already declares query as live. Anyway, you can write \"live select from Model\" if you want. Subscription call will return subscription token, which may be used to unsubscribe query: @Query ( \"live unsubscribe ${token}\" ) void unsubscribe ( @ElVar ( \"token\" ) int token ) Special live result listener may be used with automatic conversions support (much like repository method result conversions): @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen LiveQueryListener < Model > listener ) Graph api could also be used: @LiveQuery ( \"select from VertexModel\" ) int subscribeVertex ( @Listen LiveQueryListener < Vertex > listener ) Of course, pure document is allowed too. But note, that projections will not work here as live query always return entity. Important Listener execution is wrapped with external transaction, so guice can use the same connection instance as orient in current thread. OLiveQuery used for query execution.","title":"@LiveQuery"},{"location":"repository/command/livequery/#livequery","text":"Command method extension Subscribe listener to orient live query . Live query may use row orient listener interface: @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen OLiveResultListener listener ) Note Live query must start with \"live\", but this is optional as annotation already declares query as live. Anyway, you can write \"live select from Model\" if you want. Subscription call will return subscription token, which may be used to unsubscribe query: @Query ( \"live unsubscribe ${token}\" ) void unsubscribe ( @ElVar ( \"token\" ) int token ) Special live result listener may be used with automatic conversions support (much like repository method result conversions): @LiveQuery ( \"select from Model\" ) int subscribe ( @Listen LiveQueryListener < Model > listener ) Graph api could also be used: @LiveQuery ( \"select from VertexModel\" ) int subscribeVertex ( @Listen LiveQueryListener < Vertex > listener ) Of course, pure document is allowed too. But note, that projections will not work here as live query always return entity. Important Listener execution is wrapped with external transaction, so guice can use the same connection instance as orient in current thread. OLiveQuery used for query execution.","title":"@LiveQuery"},{"location":"repository/command/query/","text":"@Query \u00b6 Command method extension Query methods used for queries (select/update/insert). Select query: @Query ( \"select from Model where name=?\" ) List < Model > select ( String name ) Update query: @Query ( \"update Model set name = ? where name = ?\" ) int update ( String to , String from ) Update query return type could be void , int , long , Integer and Long . Insert query: @Query ( \"insert into Model (name) values (?)\" ) Model insert ( String name ) Internally OSQLSynchQuery used for selects and OCommandSQL for updates and inserts. Documentation links: SQL functions methods fields attributes default variables traverse query indexes","title":"@Query"},{"location":"repository/command/query/#query","text":"Command method extension Query methods used for queries (select/update/insert). Select query: @Query ( \"select from Model where name=?\" ) List < Model > select ( String name ) Update query: @Query ( \"update Model set name = ? where name = ?\" ) int update ( String to , String from ) Update query return type could be void , int , long , Integer and Long . Insert query: @Query ( \"insert into Model (name) values (?)\" ) Model insert ( String name ) Internally OSQLSynchQuery used for selects and OCommandSQL for updates and inserts. Documentation links: SQL functions methods fields attributes default variables traverse query indexes","title":"@Query"},{"location":"repository/command/script/","text":"@Script \u00b6 Command method extension Allows you to write small scripts in sql , javascript or any other scripting language. For example: @Script ( \"begin\" + \"let account = create vertex Account set name = :name\" + \"let city = select from City where name = :city\" + \"let edge = create edge Lives from $account to $city\" + \"commit retry 100\" + \"return $edge\" ) Edge linkCity ( @Param ( \"name\" ) String name , @Param ( \"city\" ) String city ) By default SQL language used for commands. Example of javascript command: @Script ( language = \"javascript\" , value = \"for( i = 0; i < 1000; i++ ){\" + \"db.command('insert into Model(name) values (\\\"test'+i+'\\\")');\" + \"}\" ) void jsScript () Note that in some cases script allows you to avoid OConcurrentModificationException : @Script ( \"begin\" + \"update Model set name = :0\" + \"commit\" ) void update ( String name ) This may be not the best way in all cases, but it works (due to implementation specifics simple query may fail in concurrent cases ). Also, note as positional parameter used as named. Script doesn't work with positional parameters, but it works like this. Internally OCommandScript used.","title":"@Script"},{"location":"repository/command/script/#script","text":"Command method extension Allows you to write small scripts in sql , javascript or any other scripting language. For example: @Script ( \"begin\" + \"let account = create vertex Account set name = :name\" + \"let city = select from City where name = :city\" + \"let edge = create edge Lives from $account to $city\" + \"commit retry 100\" + \"return $edge\" ) Edge linkCity ( @Param ( \"name\" ) String name , @Param ( \"city\" ) String city ) By default SQL language used for commands. Example of javascript command: @Script ( language = \"javascript\" , value = \"for( i = 0; i < 1000; i++ ){\" + \"db.command('insert into Model(name) values (\\\"test'+i+'\\\")');\" + \"}\" ) void jsScript () Note that in some cases script allows you to avoid OConcurrentModificationException : @Script ( \"begin\" + \"update Model set name = :0\" + \"commit\" ) void update ( String name ) This may be not the best way in all cases, but it works (due to implementation specifics simple query may fail in concurrent cases ). Also, note as positional parameter used as named. Script doesn't work with positional parameters, but it works like this. Internally OCommandScript used.","title":"@Script"},{"location":"repository/command/amend/timeout/","text":"@Timeout \u00b6 Command method amend extension Sets command execution timeout and timeout strategy (throw exception or return empty result). @Query ( \"select from Model\" ) @Timeout ( 200 ) List < Model > all () If query will not execute in 200 milliseconds, exception will be thrown (by default exception timeout startegy used). @Query ( \"select from Model\" ) @Timeout ( value = 200 , strategy = OCommandContext . TIMEOUT_STRATEGY . RETURN ) List < Model > all () Will return empty (or incomplete) result if query executes longer than 200 milliseconds. Internally timeout set using OCommandRequest.setTimeout() method.","title":"@Timeout"},{"location":"repository/command/amend/timeout/#timeout","text":"Command method amend extension Sets command execution timeout and timeout strategy (throw exception or return empty result). @Query ( \"select from Model\" ) @Timeout ( 200 ) List < Model > all () If query will not execute in 200 milliseconds, exception will be thrown (by default exception timeout startegy used). @Query ( \"select from Model\" ) @Timeout ( value = 200 , strategy = OCommandContext . TIMEOUT_STRATEGY . RETURN ) List < Model > all () Will return empty (or incomplete) result if query executes longer than 200 milliseconds. Internally timeout set using OCommandRequest.setTimeout() method.","title":"@Timeout"},{"location":"repository/command/param/dynamic/","text":"@DynamicParams \u00b6 Command method param extension Marks parameter as dynamic command parameters provider. For positional parameters, parameter type must be List , array or vararg. @Query ( \"select from Model where name=? and nick=?\" ) List < ODocument > positionalList ( @DynamicParams List < String > params ) For named parameters use Map . @Query ( \"select from Model where name=:name and nick=:nick\" ) List < ODocument > namedMap ( @DynamicParams Map < String , String > params ); Dynamic parameters may be used with static definitions @Query ( \"select from Model where name=? and nick=?\" ) List < ODocument > mixPositional ( String name , @DynamicParams String ... params ); Dynamic parameters may be used when it's more comfortable (for any reason) to provide prepared parameters object instead of static parameters binding in method. And, of course, when number of parameters is not strict. @Query ( ' select from Model where $ { cond } ' ) List < ODocument > findWhere ( @ElVar ( \"cond\" ) String cond , @DynamicParams Object ... params );","title":"@DynamicParams"},{"location":"repository/command/param/dynamic/#dynamicparams","text":"Command method param extension Marks parameter as dynamic command parameters provider. For positional parameters, parameter type must be List , array or vararg. @Query ( \"select from Model where name=? and nick=?\" ) List < ODocument > positionalList ( @DynamicParams List < String > params ) For named parameters use Map . @Query ( \"select from Model where name=:name and nick=:nick\" ) List < ODocument > namedMap ( @DynamicParams Map < String , String > params ); Dynamic parameters may be used with static definitions @Query ( \"select from Model where name=? and nick=?\" ) List < ODocument > mixPositional ( String name , @DynamicParams String ... params ); Dynamic parameters may be used when it's more comfortable (for any reason) to provide prepared parameters object instead of static parameters binding in method. And, of course, when number of parameters is not strict. @Query ( ' select from Model where $ { cond } ' ) List < ODocument > findWhere ( @ElVar ( \"cond\" ) String cond , @DynamicParams Object ... params );","title":"@DynamicParams"},{"location":"repository/command/param/elvar/","text":"@ElVar \u00b6 Command method param extension Marks parameter as el variable (variables are substituted in query before execution). @Query ( \"select from Model where ${prop} = ?\" ) List < Model > findBy ( @ElVar ( \"prop\" ) String prop , String value ); Any type could be used for variable. Value is converted to string using object.toString . Null value converted to empty string (\"\"). If Class used as variable then only class name will be used, for example: @Query ( \"select from ${model}\" ) List < Model > findAll ( @ElVar ( \"model\" ) Class model ); It is safe to use Class , Enum , Number (int, long etc), Character types, because they not allow sql injection. But when string or raw object used as value, you can define a list of allowed values to avoid injection: @Query ( \"select from Model where ${prop} = ?\" ) List < Model > findAll ( @ElVar ( value = \"prop\" , allowedValues = { \"name\" , \"nick\" }) String prop , String value ); Now if provided value is not \"name\" or \"nick\" exception will be thrown. If you use String variable without list of allowed values, warning will be shown in log (possible injection). If you 100% sure that it's safe, you can disable warning: @Query ( \"select from Model where ${cond}\" ) List < Model > findWhen ( @ElVar ( value = \"cond\" , safe = true ) String cond ); ... repository . findWhen ( \"name='luke' and nick='light'\" ) Also, safe marker documents method safety (kind of \"yes, I'm sure\").","title":"@ElVar"},{"location":"repository/command/param/elvar/#elvar","text":"Command method param extension Marks parameter as el variable (variables are substituted in query before execution). @Query ( \"select from Model where ${prop} = ?\" ) List < Model > findBy ( @ElVar ( \"prop\" ) String prop , String value ); Any type could be used for variable. Value is converted to string using object.toString . Null value converted to empty string (\"\"). If Class used as variable then only class name will be used, for example: @Query ( \"select from ${model}\" ) List < Model > findAll ( @ElVar ( \"model\" ) Class model ); It is safe to use Class , Enum , Number (int, long etc), Character types, because they not allow sql injection. But when string or raw object used as value, you can define a list of allowed values to avoid injection: @Query ( \"select from Model where ${prop} = ?\" ) List < Model > findAll ( @ElVar ( value = \"prop\" , allowedValues = { \"name\" , \"nick\" }) String prop , String value ); Now if provided value is not \"name\" or \"nick\" exception will be thrown. If you use String variable without list of allowed values, warning will be shown in log (possible injection). If you 100% sure that it's safe, you can disable warning: @Query ( \"select from Model where ${cond}\" ) List < Model > findWhen ( @ElVar ( value = \"cond\" , safe = true ) String cond ); ... repository . findWhen ( \"name='luke' and nick='light'\" ) Also, safe marker documents method safety (kind of \"yes, I'm sure\").","title":"@ElVar"},{"location":"repository/command/param/fetchplan/","text":"@FetchPlan \u00b6 Command method param extension Annotates parameter as fetch plan value. This is useful for universal queries to use different fetch plans with different calls. @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan String plan ); Only String parameter type may be used. Default fetch plan may be specified: @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan ( \"*:0\" ) String plan ); If null value provided as fetch plan and no default set, then no fetch plan will be set.","title":"@FetchPlan"},{"location":"repository/command/param/fetchplan/#fetchplan","text":"Command method param extension Annotates parameter as fetch plan value. This is useful for universal queries to use different fetch plans with different calls. @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan String plan ); Only String parameter type may be used. Default fetch plan may be specified: @Query ( \"select from Model\" ) List < Model > selectAll ( @FetchPlan ( \"*:0\" ) String plan ); If null value provided as fetch plan and no default set, then no fetch plan will be set.","title":"@FetchPlan"},{"location":"repository/command/param/listen/","text":"@Listen \u00b6 Command method param extension Marks parameter as command listener. Must be used together with @AsyncQuery or @LiveQuery (exact annotation defines which listener interfaces may be used). Listener will be wrapped with an external transaction, so listener code could access orient connection instance, used for listener from guice (normal connection access).","title":"@Listen"},{"location":"repository/command/param/listen/#listen","text":"Command method param extension Marks parameter as command listener. Must be used together with @AsyncQuery or @LiveQuery (exact annotation defines which listener interfaces may be used). Listener will be wrapped with an external transaction, so listener code could access orient connection instance, used for listener from guice (normal connection access).","title":"@Listen"},{"location":"repository/command/param/pagination/","text":"@Skip and @Limit \u00b6 Command method param extension Annotates pagination parameters (of course, may be used separately). @Query ( \"select from Model\" ) List < Model > getAll ( @Skip int skip , @Limit int limit ); Parameter type may be any Number type ( Integer, Long` etc) See bundled Pagination mixin as usage example.","title":"@Skip & @Limit"},{"location":"repository/command/param/pagination/#skip-and-limit","text":"Command method param extension Annotates pagination parameters (of course, may be used separately). @Query ( \"select from Model\" ) List < Model > getAll ( @Skip int skip , @Limit int limit ); Parameter type may be any Number type ( Integer, Long` etc) See bundled Pagination mixin as usage example.","title":"@Skip and @Limit"},{"location":"repository/command/param/param/","text":"@Param \u00b6 Command method param extension Marks named parameter query parameter. Parameter may be of any type, supported by orient. For example, if ODocument passed, orient will use it as @rid . @Query ( \"select from Model where name = :name\" ) List < Model > findByName ( @Param ( \"name\" ) String name ); Tip You are not restricted to use only this annotation: you may write your own extension annotation (e.g. to add some additional validations).","title":"@Param"},{"location":"repository/command/param/param/#param","text":"Command method param extension Marks named parameter query parameter. Parameter may be of any type, supported by orient. For example, if ODocument passed, orient will use it as @rid . @Query ( \"select from Model where name = :name\" ) List < Model > findByName ( @Param ( \"name\" ) String name ); Tip You are not restricted to use only this annotation: you may write your own extension annotation (e.g. to add some additional validations).","title":"@Param"},{"location":"repository/command/param/ridelvar/","text":"@RidElVar \u00b6 Command method param extension A special el variable to extract rid from provided object, document, vertex, ORID (object or string) and set as el variable. It is implemented as el variable and not as parameter because current orient sql parser works not so well in some cases. For example, query like create edge from ? to ? will not work with parameters (named too) and the only way to make it work is to embed rids directly into query create edge from #12:1 to #12:10 . @Query ( ' select from ( traverse out from $ { id }) ' ) List < Model > string ( @RidElVar ( \"id\" ) String id ) @Query ( ' create edge MyEdge from $ { from } to $ { to } ' ) void createEdge ( @RidElVar ( \"from\" ) Object from , @RidElVar ( \"to\" ) Object to ) Note From the first example it looks like @RidElVar could be replaced with simple @ElVar , but it's not: @ElVar will complain on string parameter because it's not safe for injection. @RidElVar always validate that provided string is valid rid (e.g. #12:11) and fail if string is not (guards from injection). You may use any supported type as variable type: ODocument , object model type, ORID , String , Vertex , Edge . By using exact type you can restrict method contract. Or use Object to accept all possible values (simplify usage when multiple apis used). Also, may be used for collections, arrays (or varargs). Such types will be inserted as \"[rid1, rid2, rid3]\" into query. @Query ( \"select from (traverse out from ${ids})\" ) public List doSmth ( @RidElVar ( \"ids\" ) List < ODocument > ids ) @Query ( \"select from (traverse out from ${ids})\" ) public List doSmth ( @RidElVar ( \"ids\" ) Vertex ... ids ) Objects inside collection may be of any supported type (even different objects).","title":"@RidElVar"},{"location":"repository/command/param/ridelvar/#ridelvar","text":"Command method param extension A special el variable to extract rid from provided object, document, vertex, ORID (object or string) and set as el variable. It is implemented as el variable and not as parameter because current orient sql parser works not so well in some cases. For example, query like create edge from ? to ? will not work with parameters (named too) and the only way to make it work is to embed rids directly into query create edge from #12:1 to #12:10 . @Query ( ' select from ( traverse out from $ { id }) ' ) List < Model > string ( @RidElVar ( \"id\" ) String id ) @Query ( ' create edge MyEdge from $ { from } to $ { to } ' ) void createEdge ( @RidElVar ( \"from\" ) Object from , @RidElVar ( \"to\" ) Object to ) Note From the first example it looks like @RidElVar could be replaced with simple @ElVar , but it's not: @ElVar will complain on string parameter because it's not safe for injection. @RidElVar always validate that provided string is valid rid (e.g. #12:11) and fail if string is not (guards from injection). You may use any supported type as variable type: ODocument , object model type, ORID , String , Vertex , Edge . By using exact type you can restrict method contract. Or use Object to accept all possible values (simplify usage when multiple apis used). Also, may be used for collections, arrays (or varargs). Such types will be inserted as \"[rid1, rid2, rid3]\" into query. @Query ( \"select from (traverse out from ${ids})\" ) public List doSmth ( @RidElVar ( \"ids\" ) List < ODocument > ids ) @Query ( \"select from (traverse out from ${ids})\" ) public List doSmth ( @RidElVar ( \"ids\" ) Vertex ... ids ) Objects inside collection may be of any supported type (even different objects).","title":"@RidElVar"},{"location":"repository/command/param/var/","text":"@Var \u00b6 Command method param extension Marks parameter as command variable . In contrast to el vars , these variables are used during query execution: For example, @Query ( ' select name from Model where name in $tst ' ) String [] findByName ( @Var ( \"tst\" ) List tst ); Note This is not the best example (could be easily rewritten with sql parameter), but it just demonstrates usage.","title":"@Var"},{"location":"repository/command/param/var/#var","text":"Command method param extension Marks parameter as command variable . In contrast to el vars , these variables are used during query execution: For example, @Query ( ' select name from Model where name in $tst ' ) String [] findByName ( @Var ( \"tst\" ) List tst ); Note This is not the best example (could be easily rewritten with sql parameter), but it just demonstrates usage.","title":"@Var"},{"location":"repository/delegate/delegate/","text":"@Delegate method \u00b6 Delegate method extension Delegate methods delegate execution to other guice bean method. @Delegate ( TargetBean . class ) List < Model > selectSomething ();","title":"@Delegate"},{"location":"repository/delegate/delegate/#delegate-method","text":"Delegate method extension Delegate methods delegate execution to other guice bean method. @Delegate ( TargetBean . class ) List < Model > selectSomething ();","title":"@Delegate method"},{"location":"repository/delegate/param/connection/","text":"@Connection \u00b6 Delegate method param extension Used to reference connection object, selected for repository method . May be used to avoid writing redundant providers injection and use direct connection from method argument. List doSomething ( @Connection OObjectDatabaseTx db ) {...} Also, may be used for object/document mixins : object and document connections share common abstraction ( ODatabaseInternal ) which may be used to write generic logic for both connections. List doSomething ( @Connection ODatabaseInternal db ) {...} Even Object may be used as type, to accept any connection type and, for example, branch logic inside method according to connection object type: List doSomething ( @Connection Object db ) {...}","title":"@Connection"},{"location":"repository/delegate/param/connection/#connection","text":"Delegate method param extension Used to reference connection object, selected for repository method . May be used to avoid writing redundant providers injection and use direct connection from method argument. List doSomething ( @Connection OObjectDatabaseTx db ) {...} Also, may be used for object/document mixins : object and document connections share common abstraction ( ODatabaseInternal ) which may be used to write generic logic for both connections. List doSomething ( @Connection ODatabaseInternal db ) {...} Even Object may be used as type, to accept any connection type and, for example, branch logic inside method according to connection object type: List doSomething ( @Connection Object db ) {...}","title":"@Connection"},{"location":"repository/delegate/param/generic/","text":"@Generic \u00b6 Delegate method param extension Used to reference caller repository method generic. For example, we have mixin definition: public interface SomeMixin < T > { @Delegate ( SomeMixinDelegate . class ) List < T > findAll () } @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class SomeMixinDeleagate implements SomeMixin { public List < Model > findAll ( @Generic ( \"T\" ) Class model ) { ... } } Now when we use mixin in repository: @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends SomeMixin < Model > {} When we call mixin method ( findAll ) on repository, it will delegate to bean method with Model.class as parameter (resolved generic). By default, generic is resolved from mixin method definition class ( SomeMixin in example above). In more complex cases you may need to know generic from some other type (and you sure this type is present in calling repository hierarchy). To do it specify type in annotation: List findAll ( @Generic ( value = \"T\" , genericHolder = SomeOtherMixin . class ) Class model ) {...} See ObjectCrud and DocumentCrud mixins for usage examples.","title":"@Generic"},{"location":"repository/delegate/param/generic/#generic","text":"Delegate method param extension Used to reference caller repository method generic. For example, we have mixin definition: public interface SomeMixin < T > { @Delegate ( SomeMixinDelegate . class ) List < T > findAll () } @ProvidedBy ( DynamicSingletonProvider . class ) public abstract class SomeMixinDeleagate implements SomeMixin { public List < Model > findAll ( @Generic ( \"T\" ) Class model ) { ... } } Now when we use mixin in repository: @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends SomeMixin < Model > {} When we call mixin method ( findAll ) on repository, it will delegate to bean method with Model.class as parameter (resolved generic). By default, generic is resolved from mixin method definition class ( SomeMixin in example above). In more complex cases you may need to know generic from some other type (and you sure this type is present in calling repository hierarchy). To do it specify type in annotation: List findAll ( @Generic ( value = \"T\" , genericHolder = SomeOtherMixin . class ) Class model ) {...} See ObjectCrud and DocumentCrud mixins for usage examples.","title":"@Generic"},{"location":"repository/delegate/param/repository/","text":"@Repository \u00b6 Delegate method param extension Used to reference calling repository instance. For example, if you sure that calling repository will contain some mixin (e.g. base mixin used for all repositories) and you need to use its methods. void doSomething ( @Repository ObjectCrud repository ){...} Good example is Pagination mixin (see how PageSupportDelegate reference Pagination mixin, which defines pagination queries and use them to compose page object).","title":"@Repository"},{"location":"repository/delegate/param/repository/#repository","text":"Delegate method param extension Used to reference calling repository instance. For example, if you sure that calling repository will contain some mixin (e.g. base mixin used for all repositories) and you need to use its methods. void doSomething ( @Repository ObjectCrud repository ){...} Good example is Pagination mixin (see how PageSupportDelegate reference Pagination mixin, which defines pagination queries and use them to compose page object).","title":"@Repository"},{"location":"repository/mixin/doccrud/","text":"DocumentCrud \u00b6 Provide basic crud operations for document connection. Usage: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends DocumentCrud < Model > {} It relies on model class to resolve model type, but, even empty class may be used (just to define scheme class name).","title":"DocumentCrud"},{"location":"repository/mixin/doccrud/#documentcrud","text":"Provide basic crud operations for document connection. Usage: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends DocumentCrud < Model > {} It relies on model class to resolve model type, but, even empty class may be used (just to define scheme class name).","title":"DocumentCrud"},{"location":"repository/mixin/edges/","text":"EdgesSupport \u00b6 Provide basic operations for edge objects: objects annotated with @EdgeType or simply extends E in scheme. This mixin mixes Object and Graph apis to let you correctly work with graph edges through object api. It is very convenient to use edge objects even if they have no properties: it's more type safe and you can use hierarchy of edge types for polymorphic queries. For example, if you have BaseConnection and SpecificConnection extends BaseConnection then querying for BaseConnection type edges will return everything and when required we can query only for SpecificConnection to get more specific results (you can see a lot of examples in orient docs with querying edges by base class E ). This works the same way as with normal objects (vertexes) providing very powerful ability for design. Mixin intended to be used as supplement to ObjectVertexCrud (to add edge functions for vertex repository). Note EdgesSupport may be used directly (injected as bean). This is because its very generic itself. Edges creation \u00b6 To create new edge we always need two objects (from and to vertexes). You can use objects, vertexes, documents or simply string id's. @Inject EdgesSupport edges ; ... MyEdgeType edge = edges . createEdge ( MyEdgeType . class , from , to ) Here new edge of class MyEdgeType is created between from and to vertexes. Api returns object instance of edge, which may be used for property updates or some other need. If edge contains properties, you can create edge from object or document instance: MyEdgeType edge = edges . createEdge ( from , to , new MyEdgeType (...)); Orient graph api is hiddent, but you can always convert edge object to orient edge and back: use edgeToObject and objectToEdge methods. Working with edge \u00b6 In orient, edges are stored as normal objects (they just have special meaning). So you can operate on edge using any api (document, object and graph). But always remove edges with graph api to grant consistency. Edge creation methods return created edge as object (it's an edge record loaded with object api). This is useful for edge properties updates: MyEdgeType edge = edges . createEdge ( MyEdgeType . class , form , to ); edge . setName ( \"some name\" ); edges . updateEdge ( edge ); Method updateEdge is generic and accepts not just object pojo but also OrientEdge instance. Searching edge \u00b6 You can find edge of type by nodes: MyEdgeType edge = edges . findEdge ( MyEdgeType . class , from , to ) Or ignoring direction: MyEdgeType edge = edges . findEdgeBetween ( MyEdgeType . class , node1 , node2 ) As with creation, object, document, vertex or rid may be used as node parameters. Note Api returns only first edge! There may be other edges. For example, create method is not checking existing edge between nodes, so you can create many edges (even of the same class) between same nodes. You can always make your own methods with sql (or maybe custom delegate logic) to implement more specific search cases. Removing edges \u00b6 Edge may be removed directly edges . deleteEdge ( edge ); Using object, document, orient edge or rid. Or you can remove all edges of type (possibly more then one!) between nodes (but only in one direction!): int cnt = edges . deleteEdge ( MyEdgeType . class , from , to );","title":"EdgesSupport"},{"location":"repository/mixin/edges/#edgessupport","text":"Provide basic operations for edge objects: objects annotated with @EdgeType or simply extends E in scheme. This mixin mixes Object and Graph apis to let you correctly work with graph edges through object api. It is very convenient to use edge objects even if they have no properties: it's more type safe and you can use hierarchy of edge types for polymorphic queries. For example, if you have BaseConnection and SpecificConnection extends BaseConnection then querying for BaseConnection type edges will return everything and when required we can query only for SpecificConnection to get more specific results (you can see a lot of examples in orient docs with querying edges by base class E ). This works the same way as with normal objects (vertexes) providing very powerful ability for design. Mixin intended to be used as supplement to ObjectVertexCrud (to add edge functions for vertex repository). Note EdgesSupport may be used directly (injected as bean). This is because its very generic itself.","title":"EdgesSupport"},{"location":"repository/mixin/edges/#edges-creation","text":"To create new edge we always need two objects (from and to vertexes). You can use objects, vertexes, documents or simply string id's. @Inject EdgesSupport edges ; ... MyEdgeType edge = edges . createEdge ( MyEdgeType . class , from , to ) Here new edge of class MyEdgeType is created between from and to vertexes. Api returns object instance of edge, which may be used for property updates or some other need. If edge contains properties, you can create edge from object or document instance: MyEdgeType edge = edges . createEdge ( from , to , new MyEdgeType (...)); Orient graph api is hiddent, but you can always convert edge object to orient edge and back: use edgeToObject and objectToEdge methods.","title":"Edges creation"},{"location":"repository/mixin/edges/#working-with-edge","text":"In orient, edges are stored as normal objects (they just have special meaning). So you can operate on edge using any api (document, object and graph). But always remove edges with graph api to grant consistency. Edge creation methods return created edge as object (it's an edge record loaded with object api). This is useful for edge properties updates: MyEdgeType edge = edges . createEdge ( MyEdgeType . class , form , to ); edge . setName ( \"some name\" ); edges . updateEdge ( edge ); Method updateEdge is generic and accepts not just object pojo but also OrientEdge instance.","title":"Working with edge"},{"location":"repository/mixin/edges/#searching-edge","text":"You can find edge of type by nodes: MyEdgeType edge = edges . findEdge ( MyEdgeType . class , from , to ) Or ignoring direction: MyEdgeType edge = edges . findEdgeBetween ( MyEdgeType . class , node1 , node2 ) As with creation, object, document, vertex or rid may be used as node parameters. Note Api returns only first edge! There may be other edges. For example, create method is not checking existing edge between nodes, so you can create many edges (even of the same class) between same nodes. You can always make your own methods with sql (or maybe custom delegate logic) to implement more specific search cases.","title":"Searching edge"},{"location":"repository/mixin/edges/#removing-edges","text":"Edge may be removed directly edges . deleteEdge ( edge ); Using object, document, orient edge or rid. Or you can remove all edges of type (possibly more then one!) between nodes (but only in one direction!): int cnt = edges . deleteEdge ( MyEdgeType . class , from , to );","title":"Removing edges"},{"location":"repository/mixin/edgetype/","text":"EdgeTypeSupport \u00b6 Very similar to EdgesSupprt mixin, but for one concrete edge type. Also, you can restrict from/to types using generics. It also supposed to be used to supplement ObjectVertexCrud . @VertexType public class Model {} @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} It uses EdgesSupport as bean internally and may serve as an example of how to implement more specific edge mixins.","title":"EdgeTypeSupport"},{"location":"repository/mixin/edgetype/#edgetypesupport","text":"Very similar to EdgesSupprt mixin, but for one concrete edge type. Also, you can restrict from/to types using generics. It also supposed to be used to supplement ObjectVertexCrud . @VertexType public class Model {} @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} It uses EdgesSupport as bean internally and may serve as an example of how to implement more specific edge mixins.","title":"EdgeTypeSupport"},{"location":"repository/mixin/objcrud/","text":"ObjectCrud \u00b6 Provide basic crud operations for object connection. Usage: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectCrud < Model > {} You can use objectToDocument and documentToObject methods for conversion to/from documents. Note Don't use it with vertex objects (annotated with @VertexType ). Use ObjectVertexCrud instead.","title":"ObjectCrud"},{"location":"repository/mixin/objcrud/#objectcrud","text":"Provide basic crud operations for object connection. Usage: @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectCrud < Model > {} You can use objectToDocument and documentToObject methods for conversion to/from documents. Note Don't use it with vertex objects (annotated with @VertexType ). Use ObjectVertexCrud instead.","title":"ObjectCrud"},{"location":"repository/mixin/objvcrud/","text":"ObjectVertexCrud \u00b6 Provide basic crud operations for vertex objects: objects annotated with @VertexType or simply extends V in scheme. This mixin mixes Object and Graph apis to let you correctly work with graph vertexes through object api. It has the same api as ObjectCrud (internally they both extend the same BaseObjectCrud mixin). Warning It is important to use this specific version because it uses graph api for remove: if object api directly used, graph consistency is not checked and so edges leading to/from this vertex are not removed. It also contains special methods for conversion between object and graph api: vertexToObject and objectToVertex . @VertexType public class Model {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model > {} You can use it together with EdgesSupport or EdgeTypeSupport to add relevant edges operations into repository. For example, suppose we want to always connect Model objects with ModelConnection edge type: @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} Now we can operate on objects and connect them with the same repository: @Inject ModelRepository repository ; ... Model from = repository . save ( new Model (..)); Model to = repository . save ( new Model (..)); ModelConnection edge = repository . createEdge ( from , to ); // we may update edge object properties (if it contains it) edge . setComment ( \"important connection\" ); repository . updateEdge ( edge );","title":"ObjectVertexCrud"},{"location":"repository/mixin/objvcrud/#objectvertexcrud","text":"Provide basic crud operations for vertex objects: objects annotated with @VertexType or simply extends V in scheme. This mixin mixes Object and Graph apis to let you correctly work with graph vertexes through object api. It has the same api as ObjectCrud (internally they both extend the same BaseObjectCrud mixin). Warning It is important to use this specific version because it uses graph api for remove: if object api directly used, graph consistency is not checked and so edges leading to/from this vertex are not removed. It also contains special methods for conversion between object and graph api: vertexToObject and objectToVertex . @VertexType public class Model {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model > {} You can use it together with EdgesSupport or EdgeTypeSupport to add relevant edges operations into repository. For example, suppose we want to always connect Model objects with ModelConnection edge type: @EdgeType public class ModelConnection {} @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface ModelRepository extends ObjectVertexCrud < Model >, EdgeTypeSupport < ModelConnection , Model , Model > {} Now we can operate on objects and connect them with the same repository: @Inject ModelRepository repository ; ... Model from = repository . save ( new Model (..)); Model to = repository . save ( new Model (..)); ModelConnection edge = repository . createEdge ( from , to ); // we may update edge object properties (if it contains it) edge . setComment ( \"important connection\" ); repository . updateEdge ( edge );","title":"ObjectVertexCrud"},{"location":"repository/mixin/pagination/","text":"Pagination \u00b6 Pagination mixin provides simple pagination for your object entity or document (but document should have reference type, at least to specify schema type name (may be empty class)). @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface MyEntityRepository extends ObjectCrud < MyEntity >, Pagination < MyEntity , MyEntity > {} ... // return page Page page = repository . getPage ( 1 , 20 ); Pagination provides 3 methods: getPage - receive composed page object getAll - paginated data selection getCount - count of all entities Implementation \u00b6 Pagination implementation is a very good example mixin: Base class PageSupport is delegate (to PageSupportDelegate ), which incapsulates Page object logic. Pagination interface extends it ( Pagination<M, R> extends PageSupport<R> ) and defines query methods (for actual data and entore count). PageSupportDelegate use reference to repository to call these methods: public Page getPage ( @Repository final Pagination repository , final int page , final int pageSize ) Assuming Pagination interface will be always used and so delegate could be sure about repository type (implementing just PageSupport in repository would make no sense).","title":"Pagination"},{"location":"repository/mixin/pagination/#pagination","text":"Pagination mixin provides simple pagination for your object entity or document (but document should have reference type, at least to specify schema type name (may be empty class)). @Transactional @ProvidedBy ( DynamicSingletonProvider . class ) public interface MyEntityRepository extends ObjectCrud < MyEntity >, Pagination < MyEntity , MyEntity > {} ... // return page Page page = repository . getPage ( 1 , 20 ); Pagination provides 3 methods: getPage - receive composed page object getAll - paginated data selection getCount - count of all entities","title":"Pagination"},{"location":"repository/mixin/pagination/#implementation","text":"Pagination implementation is a very good example mixin: Base class PageSupport is delegate (to PageSupportDelegate ), which incapsulates Page object logic. Pagination interface extends it ( Pagination<M, R> extends PageSupport<R> ) and defines query methods (for actual data and entore count). PageSupportDelegate use reference to repository to call these methods: public Page getPage ( @Repository final Pagination repository , final int page , final int pageSize ) Assuming Pagination interface will be always used and so delegate could be sure about repository type (implementing just PageSupport in repository would make no sense).","title":"Implementation"},{"location":"repository/result/detach/","text":"@DetachResult \u00b6 Results detaching may be used only with object connection (will be always the case when expected result is model class (or collection of model classes)). @Query ( \"select from Model\" ) @DetachResult List < Model > selectAll () This may be important if you use small transaction scopes, e.g. if method above represent transaction scope, then if we will call it without detach converter, then any attempt to access list object field will fail: returned proxies doesn't work without transaction. Note Used detach method will completely unproxy entire object tree. If for example, you use remote connection with fetch plan, then detach will load entire graph during detaching. In most cases detach should be not needed, because most likely entire business logic will be covered with transaction. You can use this extension as reference for writing your own conversion extension .","title":"@DetachResult"},{"location":"repository/result/detach/#detachresult","text":"Results detaching may be used only with object connection (will be always the case when expected result is model class (or collection of model classes)). @Query ( \"select from Model\" ) @DetachResult List < Model > selectAll () This may be important if you use small transaction scopes, e.g. if method above represent transaction scope, then if we will call it without detach converter, then any attempt to access list object field will fail: returned proxies doesn't work without transaction. Note Used detach method will completely unproxy entire object tree. If for example, you use remote connection with fetch plan, then detach will load entire graph during detaching. In most cases detach should be not needed, because most likely entire business logic will be covered with transaction. You can use this extension as reference for writing your own conversion extension .","title":"@DetachResult"},{"location":"repository/result/noconvert/","text":"@NoConversion \u00b6 Disables any result conversion . Note By default special converter applied globaly handles many cases like collection reducing to single element, projections etc. For example: @Query ( \"select from Model\" ) @NoConversion Model selectAll () This query will fail to execute, because of class cast exception: returned List<Model> can't be casted to Model .","title":"@NoConversion"},{"location":"repository/result/noconvert/#noconversion","text":"Disables any result conversion . Note By default special converter applied globaly handles many cases like collection reducing to single element, projections etc. For example: @Query ( \"select from Model\" ) @NoConversion Model selectAll () This query will fail to execute, because of class cast exception: returned List<Model> can't be casted to Model .","title":"@NoConversion"}]}